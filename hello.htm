<!DOCTYPE html>
<html lang="en" data-rh="lang"><head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8"><title>Understanding Direct Preference Optimization | by Matthew Gunton | Towards Data Science</title><meta data-rh="true" charset="utf-8"><meta data-rh="true" name="viewport" content="width=device-width,minimum-scale=1,initial-scale=1,maximum-scale=1"><meta data-rh="true" name="theme-color" content="#000000"><meta data-rh="true" name="twitter:app:name:iphone" content="Medium"><meta data-rh="true" name="twitter:app:id:iphone" content="828256236"><meta data-rh="true" property="al:ios:app_name" content="Medium"><meta data-rh="true" property="al:ios:app_store_id" content="828256236"><meta data-rh="true" property="al:android:package" content="com.medium.reader"><meta data-rh="true" property="fb:app_id" content="542599432471018"><meta data-rh="true" property="og:site_name" content="Medium"><meta data-rh="true" property="og:type" content="article"><meta data-rh="true" property="article:published_time" content="2024-02-23T22:47:51.171Z"><meta data-rh="true" name="title" content="Understanding Direct Preference Optimization | by Matthew Gunton | Towards Data Science"><meta data-rh="true" property="og:title" content="Understanding Direct Preference Optimization"><meta data-rh="true" property="al:android:url" content="medium://p/a4bbd2d85841"><meta data-rh="true" property="al:ios:url" content="medium://p/a4bbd2d85841"><meta data-rh="true" property="al:android:app_name" content="Medium"><meta data-rh="true" name="description" content="This blog post was inspired by a discussion I recently had with some friends about the Direct Preference Optimization (DPO) paper. The discussion was lively and went over many important topics in…"><meta data-rh="true" property="og:description" content="This blog post will look at the “Direct Preference Optimization:
Your Language Model is Secretly a Reward Model” paper and its findings."><meta data-rh="true" property="og:url" content="https://towardsdatascience.com/understanding-the-implications-of-direct-preference-optimization-a4bbd2d85841"><meta data-rh="true" property="al:web:url" content="https://towardsdatascience.com/understanding-the-implications-of-direct-preference-optimization-a4bbd2d85841"><meta data-rh="true" property="og:image" content="https://miro.medium.com/v2/resize:fit:1024/1*L5Fx8l3DZ5LxZVSwBzlEdg.png"><meta data-rh="true" property="article:author" content="https://medium.com/@mgunton7"><meta data-rh="true" name="author" content="Matthew Gunton"><meta data-rh="true" name="robots" content="index,noarchive,follow,max-image-preview:large"><meta data-rh="true" name="referrer" content="unsafe-url"><meta data-rh="true" property="twitter:title" content="Understanding Direct Preference Optimization"><meta data-rh="true" name="twitter:site" content="@TDataScience"><meta data-rh="true" name="twitter:app:url:iphone" content="medium://p/a4bbd2d85841"><meta data-rh="true" property="twitter:description" content="This blog post will look at the “Direct Preference Optimization:
Your Language Model is Secretly a Reward Model” paper and its findings."><meta data-rh="true" name="twitter:image:src" content="https://miro.medium.com/v2/resize:fit:1024/1*L5Fx8l3DZ5LxZVSwBzlEdg.png"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" name="twitter:label1" content="Reading time"><meta data-rh="true" name="twitter:data1" content="8 min read"><link data-rh="true" rel="search" type="application/opensearchdescription+xml" title="Medium" href="https://towardsdatascience.com/osd.xml"><link data-rh="true" rel="preconnect" href="https://glyph.medium.com/" crossorigin=""><link data-rh="true" id="glyph_preload_link" rel="preload" as="style" type="text/css" href="hello_files/unbound.css"><link data-rh="true" id="glyph_link" rel="stylesheet" type="text/css" href="hello_files/unbound.css"><link data-rh="true" rel="author" href="https://medium.com/@mgunton7"><link data-rh="true" rel="canonical" href="https://towardsdatascience.com/understanding-the-implications-of-direct-preference-optimization-a4bbd2d85841"><link data-rh="true" rel="alternate" href="android-app://com.medium.reader/https/medium.com/p/a4bbd2d85841"><style type="text/css" data-fela-rehydration="531" data-fela-type="STATIC">html{box-sizing:border-box;-webkit-text-size-adjust:100%}*, *:before, *:after{box-sizing:inherit}body{margin:0;padding:0;text-rendering:optimizeLegibility;-webkit-font-smoothing:antialiased;color:rgba(0,0,0,0.8);position:relative;min-height:100vh}h1, h2, h3, h4, h5, h6, dl, dd, ol, ul, menu, figure, blockquote, p, pre, form{margin:0}menu, ol, ul{padding:0;list-style:none;list-style-image:none}main{display:block}a{color:inherit;text-decoration:none}a, button, input{-webkit-tap-highlight-color:transparent}img, svg{vertical-align:middle}button{background:transparent;overflow:visible}button, input, optgroup, select, textarea{margin:0}:root{--reach-tabs:1;--reach-menu-button:1}#speechify-root{font-family:Sohne, sans-serif}div[data-popper-reference-hidden="true"]{visibility:hidden;pointer-events:none}.grecaptcha-badge{visibility:hidden}
/*XCode style (c) Angel Garcia <angelgarcia.mail@gmail.com>*/.hljs {background: #fff;color: black;
}/* Gray DOCTYPE selectors like WebKit */
.xml .hljs-meta {color: #c0c0c0;
}.hljs-comment,
.hljs-quote {color: #007400;
}.hljs-tag,
.hljs-attribute,
.hljs-keyword,
.hljs-selector-tag,
.hljs-literal,
.hljs-name {color: #aa0d91;
}.hljs-variable,
.hljs-template-variable {color: #3F6E74;
}.hljs-code,
.hljs-string,
.hljs-meta .hljs-string {color: #c41a16;
}.hljs-regexp,
.hljs-link {color: #0E0EFF;
}.hljs-title,
.hljs-symbol,
.hljs-bullet,
.hljs-number {color: #1c00cf;
}.hljs-section,
.hljs-meta {color: #643820;
}.hljs-title.class_,
.hljs-class .hljs-title,
.hljs-type,
.hljs-built_in,
.hljs-params {color: #5c2699;
}.hljs-attr {color: #836C28;
}.hljs-subst {color: #000;
}.hljs-formula {background-color: #eee;font-style: italic;
}.hljs-addition {background-color: #baeeba;
}.hljs-deletion {background-color: #ffc8bd;
}.hljs-selector-id,
.hljs-selector-class {color: #9b703f;
}.hljs-doctag,
.hljs-strong {font-weight: bold;
}.hljs-emphasis {font-style: italic;
}
</style><style type="text/css" data-fela-rehydration="531" data-fela-type="KEYFRAME">@-webkit-keyframes k1{0%{opacity:0.8}50%{opacity:0.5}100%{opacity:0.8}}@-moz-keyframes k1{0%{opacity:0.8}50%{opacity:0.5}100%{opacity:0.8}}@keyframes k1{0%{opacity:0.8}50%{opacity:0.5}100%{opacity:0.8}}</style><style type="text/css" data-fela-rehydration="531" data-fela-type="RULE">.a{font-family:medium-content-sans-serif-font, -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Open Sans", "Helvetica Neue", sans-serif}.b{font-weight:400}.c{background-color:rgba(255, 255, 255, 1)}.l{display:block}.m{position:sticky}.n{top:0}.o{z-index:500}.p{padding:0 24px}.q{align-items:center}.r{border-bottom:solid 1px #F2F2F2}.y{height:41px}.z{line-height:20px}.ab{display:flex}.ac{height:57px}.ae{flex:1 0 auto}.af{color:inherit}.ag{fill:inherit}.ah{font-size:inherit}.ai{border:inherit}.aj{font-family:inherit}.ak{letter-spacing:inherit}.al{font-weight:inherit}.am{padding:0}.an{margin:0}.ao{cursor:pointer}.ap:disabled{cursor:not-allowed}.aq:disabled{color:#6B6B6B}.ar:disabled{fill:#6B6B6B}.au{width:auto}.av path{fill:#242424}.aw{height:25px}.ax{margin-left:16px}.ay{border:none}.az{border-radius:20px}.ba{width:240px}.bb{background:#F9F9F9}.bc path{fill:#6B6B6B}.be{outline:none}.bf{font-family:sohne, "Helvetica Neue", Helvetica, Arial, sans-serif}.bg{font-size:14px}.bh{width:100%}.bi{padding:10px 20px 10px 0}.bj{background-color:transparent}.bk{color:#242424}.bl::placeholder{color:#6B6B6B}.bm{display:inline-block}.bn{margin-left:12px}.bo{margin-right:12px}.bp{border-radius:4px}.bq{margin-left:24px}.br{height:24px}.bx{background-color:#F9F9F9}.by{border-radius:50%}.bz{height:32px}.ca{width:32px}.cb{justify-content:center}.ch{max-width:680px}.ci{min-width:0}.cj{animation:k1 1.2s ease-in-out infinite}.ck{height:100vh}.cl{margin-bottom:16px}.cm{margin-top:48px}.cn{align-items:flex-start}.co{flex-direction:column}.cp{justify-content:space-between}.cq{margin-bottom:24px}.cw{width:80%}.cx{background-color:#F2F2F2}.dd{height:44px}.de{width:44px}.df{margin:auto 0}.dg{margin-bottom:4px}.dh{height:16px}.di{width:120px}.dj{width:80px}.dp{margin-bottom:8px}.dq{width:96%}.dr{width:98%}.ds{width:81%}.dt{margin-left:8px}.du{color:#6B6B6B}.dv{font-size:13px}.dw{height:100%}.ep{color:#FFFFFF}.eq{fill:#FFFFFF}.er{background:rgba(102, 138, 170, 1)}.es{border-color:rgba(102, 138, 170, 1)}.ew:disabled{cursor:inherit !important}.ex:disabled{opacity:0.3}.ey:disabled:hover{background:rgba(102, 138, 170, 1)}.ez:disabled:hover{border-color:rgba(102, 138, 170, 1)}.fa{border-radius:99em}.fb{border-width:1px}.fc{border-style:solid}.fd{box-sizing:border-box}.fe{text-decoration:none}.ff{text-align:center}.fi{margin-right:32px}.fj{position:relative}.fk{fill:#6B6B6B}.fn{background:transparent}.fo svg{margin-left:4px}.fp svg{fill:#6B6B6B}.fr{box-shadow:inset 0 0 0 1px rgba(0, 0, 0, 0.05)}.fs{position:absolute}.fz{margin:0 24px}.gd{background:rgba(255, 255, 255, 1)}.ge{border:1px solid #F2F2F2}.gf{box-shadow:0 1px 4px #F2F2F2}.gg{max-height:100vh}.gh{overflow-y:auto}.gi{left:0}.gj{top:calc(100vh + 100px)}.gk{bottom:calc(100vh + 100px)}.gl{width:10px}.gm{pointer-events:none}.gn{word-break:break-word}.go{word-wrap:break-word}.gp:after{display:block}.gq:after{content:""}.gr:after{clear:both}.gs{line-height:1.23}.gt{letter-spacing:0}.gu{font-style:normal}.gv{font-weight:700}.hq{margin-bottom:-0.27em}.hr{line-height:1.394}.im{align-items:baseline}.in{width:48px}.io{height:48px}.ip{border:2px solid rgba(255, 255, 255, 1)}.iq{z-index:0}.ir{box-shadow:none}.is{border:1px solid rgba(0, 0, 0, 0.05)}.it{margin-left:-12px}.iu{width:28px}.iv{height:28px}.iw{z-index:1}.ix{width:24px}.iy{margin-bottom:2px}.iz{flex-wrap:nowrap}.ja{font-size:16px}.jb{line-height:24px}.jd{margin:0 8px}.je{display:inline}.jf{color:rgba(102, 138, 170, 1)}.jg{fill:rgba(102, 138, 170, 1)}.jj{flex:0 0 auto}.jm{flex-wrap:wrap}.jp{white-space:pre-wrap}.jq{margin-right:4px}.jr{overflow:hidden}.js{max-height:20px}.jt{text-overflow:ellipsis}.ju{display:-webkit-box}.jv{-webkit-line-clamp:1}.jw{-webkit-box-orient:vertical}.jx{word-break:break-all}.jz{padding-left:8px}.ka{padding-right:8px}.lb> *{flex-shrink:0}.lc{overflow-x:scroll}.ld::-webkit-scrollbar{display:none}.le{scrollbar-width:none}.lf{-ms-overflow-style:none}.lg{width:74px}.lh{flex-direction:row}.li{z-index:2}.ll{-webkit-user-select:none}.lm{border:0}.ln{fill:rgba(117, 117, 117, 1)}.lq{outline:0}.lr{user-select:none}.ls> svg{pointer-events:none}.mb{cursor:progress}.mc{margin-left:4px}.md{margin-top:0px}.me{opacity:1}.mf{padding:4px 0}.mi{width:16px}.mk{display:inline-flex}.mq{max-width:100%}.mr{padding:8px 2px}.ms svg{color:#6B6B6B}.nj{margin-left:auto}.nk{margin-right:auto}.nl{max-width:1024px}.nr{clear:both}.nt{cursor:zoom-in}.nu{z-index:auto}.nw{height:auto}.nx{margin-top:10px}.ny{max-width:728px}.ob{line-height:1.58}.oc{letter-spacing:-0.004em}.od{font-family:source-serif-pro, Georgia, Cambria, "Times New Roman", Times, serif}.ow{margin-bottom:-0.46em}.ox{font-style:italic}.oy{margin-top:32px}.oz{margin-bottom:14px}.pa{padding-top:24px}.pb{padding-bottom:10px}.pc{background-color:#000000}.pd{height:3px}.pe{width:3px}.pf{margin-right:20px}.pg{line-height:1.12}.ph{letter-spacing:-0.022em}.pi{font-weight:600}.qb{margin-bottom:-0.28em}.qh{text-decoration:underline}.qn{max-width:1078px}.qo{max-width:1608px}.qp{max-width:1758px}.qq{max-width:1774px}.qr{max-width:648px}.qs{max-width:1664px}.qt{max-width:1612px}.qu{max-width:1602px}.qv{max-width:1620px}.qw{max-width:1610px}.qx{max-width:1658px}.qy{margin-bottom:26px}.qz{margin-top:6px}.ra{margin-top:8px}.rb{margin-right:8px}.rc{padding:8px 16px}.rd{border-radius:100px}.re{transition:background 300ms ease}.rg{white-space:nowrap}.rh{border-top:none}.rn{height:52px}.ro{max-height:52px}.rp{box-sizing:content-box}.rq{position:static}.rs{max-width:155px}.sd{align-items:flex-end}.se{width:76px}.sf{height:76px}.sg{border:2px solid #F9F9F9}.sh{height:72px}.si{width:72px}.sj{margin-left:-16px}.sk{width:36px}.sl{height:36px}.sm{stroke:#F2F2F2}.sn{color:#F2F2F2}.so{fill:#F2F2F2}.sp{background:#F2F2F2}.sq{border-color:#F2F2F2}.sw{font-weight:500}.sx{font-size:24px}.sy{line-height:30px}.sz{letter-spacing:-0.016em}.ta{margin-top:16px}.tb{height:0px}.tc{border-bottom:solid 1px #E5E5E5}.ti{margin-top:72px}.tj{padding:24px 0}.tk{margin-bottom:0px}.tl{margin-right:16px}.as:hover:not(:disabled){color:rgba(25, 25, 25, 1)}.at:hover:not(:disabled){fill:rgba(25, 25, 25, 1)}.et:hover{background:rgba(90, 118, 144, 1)}.eu:hover{border-color:rgba(90, 118, 144, 1)}.ev:hover{cursor:pointer}.fl:hover{color:#242424}.fm:hover{fill:#242424}.fq:hover svg{fill:#242424}.ft:hover{background-color:rgba(0, 0, 0, 0.1)}.jc:hover{text-decoration:underline}.jh:hover:not(:disabled){color:rgba(90, 118, 144, 1)}.ji:hover:not(:disabled){fill:rgba(90, 118, 144, 1)}.lp:hover{fill:rgba(8, 8, 8, 1)}.mg:hover{fill:#000000}.mh:hover p{color:#000000}.mj:hover{color:#000000}.mt:hover svg{color:#000000}.rf:hover{background-color:#F2F2F2}.sr:hover{background:#F2F2F2}.ss:hover{border-color:#F2F2F2}.st:hover{cursor:wait}.su:hover{color:#F2F2F2}.sv:hover{fill:#F2F2F2}.bd:focus-within path{fill:#242424}.lo:focus{fill:rgba(8, 8, 8, 1)}.mu:focus svg{color:#000000}.nv:focus{transform:scale(1.01)}.lt:active{border-style:none}</style><style type="text/css" data-fela-rehydration="531" data-fela-type="RULE" media="all and (min-width: 1080px)">.d{display:none}.bw{width:64px}.cg{margin:0 64px}.cv{height:48px}.dc{margin-bottom:52px}.do{margin-bottom:48px}.ef{font-size:14px}.eg{line-height:20px}.em{font-size:13px}.eo{padding:5px 12px}.fh{display:flex}.fy{margin-bottom:68px}.gc{max-width:680px}.hm{font-size:42px}.hn{margin-top:1.19em}.ho{line-height:52px}.hp{letter-spacing:-0.011em}.ie{font-size:22px}.if{margin-top:0.92em}.ig{line-height:28px}.il{align-items:center}.kn{border-top:solid 1px #F2F2F2}.ko{border-bottom:solid 1px #F2F2F2}.kp{margin:32px 0 0}.kq{padding:3px 8px}.kz> *{margin-right:24px}.la> :last-child{margin-right:0}.ma{margin-top:0px}.mp{margin:0}.nq{margin-top:56px}.os{font-size:20px}.ot{margin-top:2.14em}.ou{line-height:32px}.ov{letter-spacing:-0.003em}.px{font-size:24px}.py{margin-top:1.25em}.pz{line-height:30px}.qa{letter-spacing:-0.016em}.qg{margin-top:0.94em}.qm{margin-top:1.95em}.rm{margin-bottom:88px}.rx{display:inline-block}.sc{padding-top:72px}.th{margin-top:40px}</style><style type="text/css" data-fela-rehydration="531" data-fela-type="RULE" media="all and (max-width: 1079.98px)">.e{display:none}.lz{margin-top:0px}.nz{margin-left:auto}.oa{text-align:center}.rw{display:inline-block}</style><style type="text/css" data-fela-rehydration="531" data-fela-type="RULE" media="all and (max-width: 903.98px)">.f{display:none}.ly{margin-top:0px}.rv{display:inline-block}</style><style type="text/css" data-fela-rehydration="531" data-fela-type="RULE" media="all and (max-width: 727.98px)">.g{display:none}.lw{margin-top:0px}.lx{margin-right:0px}.ru{display:inline-block}</style><style type="text/css" data-fela-rehydration="531" data-fela-type="RULE" media="all and (max-width: 551.98px)">.h{display:none}.s{display:flex}.t{justify-content:space-between}.bs{width:24px}.cc{margin:0 24px}.cr{height:40px}.cy{margin-bottom:44px}.dk{margin-bottom:32px}.dx{font-size:13px}.dy{line-height:20px}.eh{padding:0px 8px 1px}.fu{margin-bottom:4px}.gw{font-size:32px}.gx{margin-top:1.01em}.gy{line-height:38px}.gz{letter-spacing:-0.014em}.hs{font-size:18px}.ht{margin-top:0.79em}.hu{line-height:24px}.ih{align-items:flex-start}.jk{flex-direction:column}.jn{margin-bottom:2px}.kb{margin:24px -24px 0}.kc{padding:0}.kr> *{margin-right:8px}.ks> :last-child{margin-right:24px}.lj{margin-left:0px}.lu{margin-top:0px}.lv{margin-right:0px}.ml{margin:0}.mv{border:1px solid #F2F2F2}.mw{border-radius:99em}.mx{padding:0px 16px 0px 12px}.my{height:38px}.mz{align-items:center}.nb svg{margin-right:8px}.nm{margin-top:40px}.oe{margin-top:1.56em}.of{line-height:28px}.og{letter-spacing:-0.003em}.pj{font-size:20px}.pk{margin-top:0.93em}.pl{letter-spacing:0}.qc{margin-top:0.67em}.qi{margin-top:1.2em}.ri{margin-bottom:80px}.rt{display:inline-block}.ry{padding-top:48px}.td{margin-top:32px}.na:hover{border-color:#E5E5E5}</style><style type="text/css" data-fela-rehydration="531" data-fela-type="RULE" media="all and (min-width: 904px) and (max-width: 1079.98px)">.i{display:none}.bv{width:64px}.cf{margin:0 64px}.cu{height:48px}.db{margin-bottom:52px}.dn{margin-bottom:48px}.ed{font-size:14px}.ee{line-height:20px}.ek{font-size:13px}.el{padding:5px 12px}.fg{display:flex}.fx{margin-bottom:68px}.gb{max-width:680px}.hi{font-size:42px}.hj{margin-top:1.19em}.hk{line-height:52px}.hl{letter-spacing:-0.011em}.ib{font-size:22px}.ic{margin-top:0.92em}.id{line-height:28px}.ik{align-items:center}.kj{border-top:solid 1px #F2F2F2}.kk{border-bottom:solid 1px #F2F2F2}.kl{margin:32px 0 0}.km{padding:3px 8px}.kx> *{margin-right:24px}.ky> :last-child{margin-right:0}.mo{margin:0}.np{margin-top:56px}.oo{font-size:20px}.op{margin-top:2.14em}.oq{line-height:32px}.or{letter-spacing:-0.003em}.pt{font-size:24px}.pu{margin-top:1.25em}.pv{line-height:30px}.pw{letter-spacing:-0.016em}.qf{margin-top:0.94em}.ql{margin-top:1.95em}.rl{margin-bottom:88px}.sb{padding-top:72px}.tg{margin-top:40px}</style><style type="text/css" data-fela-rehydration="531" data-fela-type="RULE" media="all and (min-width: 728px) and (max-width: 903.98px)">.j{display:none}.w{display:flex}.x{justify-content:space-between}.bu{width:64px}.ce{margin:0 48px}.ct{height:48px}.da{margin-bottom:52px}.dm{margin-bottom:48px}.eb{font-size:13px}.ec{line-height:20px}.ej{padding:0px 8px 1px}.fw{margin-bottom:68px}.ga{max-width:680px}.he{font-size:42px}.hf{margin-top:1.19em}.hg{line-height:52px}.hh{letter-spacing:-0.011em}.hy{font-size:22px}.hz{margin-top:0.92em}.ia{line-height:28px}.ij{align-items:center}.kf{border-top:solid 1px #F2F2F2}.kg{border-bottom:solid 1px #F2F2F2}.kh{margin:32px 0 0}.ki{padding:3px 8px}.kv> *{margin-right:24px}.kw> :last-child{margin-right:0}.mn{margin:0}.no{margin-top:56px}.ok{font-size:20px}.ol{margin-top:2.14em}.om{line-height:32px}.on{letter-spacing:-0.003em}.pp{font-size:24px}.pq{margin-top:1.25em}.pr{line-height:30px}.ps{letter-spacing:-0.016em}.qe{margin-top:0.94em}.qk{margin-top:1.95em}.rk{margin-bottom:88px}.sa{padding-top:72px}.tf{margin-top:40px}</style><style type="text/css" data-fela-rehydration="531" data-fela-type="RULE" media="all and (min-width: 552px) and (max-width: 727.98px)">.k{display:none}.u{display:flex}.v{justify-content:space-between}.bt{width:24px}.cd{margin:0 24px}.cs{height:40px}.cz{margin-bottom:44px}.dl{margin-bottom:32px}.dz{font-size:13px}.ea{line-height:20px}.ei{padding:0px 8px 1px}.fv{margin-bottom:4px}.ha{font-size:32px}.hb{margin-top:1.01em}.hc{line-height:38px}.hd{letter-spacing:-0.014em}.hv{font-size:18px}.hw{margin-top:0.79em}.hx{line-height:24px}.ii{align-items:flex-start}.jl{flex-direction:column}.jo{margin-bottom:2px}.kd{margin:24px 0 0}.ke{padding:0}.kt> *{margin-right:8px}.ku> :last-child{margin-right:8px}.lk{margin-left:0px}.mm{margin:0}.nc{border:1px solid #F2F2F2}.nd{border-radius:99em}.ne{padding:0px 16px 0px 12px}.nf{height:38px}.ng{align-items:center}.ni svg{margin-right:8px}.nn{margin-top:40px}.oh{margin-top:1.56em}.oi{line-height:28px}.oj{letter-spacing:-0.003em}.pm{font-size:20px}.pn{margin-top:0.93em}.po{letter-spacing:0}.qd{margin-top:0.67em}.qj{margin-top:1.2em}.rj{margin-bottom:80px}.rz{padding-top:48px}.te{margin-top:32px}.nh:hover{border-color:#E5E5E5}</style><style type="text/css" data-fela-rehydration="531" data-fela-type="RULE" media="print">.rr{display:none}</style><style type="text/css" data-fela-rehydration="531" data-fela-type="RULE" media="(orientation: landscape) and (max-width: 903.98px)">.jy{max-height:none}</style><style type="text/css" data-fela-rehydration="531" data-fela-type="RULE" media="(prefers-reduced-motion: no-preference)">.ns{transition:transform 300ms cubic-bezier(0.2, 0, 0.2, 1)}</style><link rel="icon" href="https://miro.medium.com/v2/resize:fill:128:128/1*VzTUkfeGymHP4Bvav-T-lA.png" data-rh="true"><link rel="apple-touch-icon" sizes="152x152" href="https://miro.medium.com/v2/resize:fill:152:152/10fd5c419ac61637245384e7099e131627900034828f4f386bdaa47a74eae156" data-rh="true"><link rel="apple-touch-icon" sizes="120x120" href="https://miro.medium.com/v2/resize:fill:120:120/10fd5c419ac61637245384e7099e131627900034828f4f386bdaa47a74eae156" data-rh="true"><link rel="apple-touch-icon" sizes="76x76" href="https://miro.medium.com/v2/resize:fill:76:76/10fd5c419ac61637245384e7099e131627900034828f4f386bdaa47a74eae156" data-rh="true"><link rel="apple-touch-icon" sizes="60x60" href="https://miro.medium.com/v2/resize:fill:60:60/10fd5c419ac61637245384e7099e131627900034828f4f386bdaa47a74eae156" data-rh="true"><link rel="mask-icon" href="https://miro.medium.com/v2/resize:fill:500:500/7*GAOKVe--MXbEJmV9230oOQ.png" color="#171717" data-rh="true"><script type="text/javascript" async="" charset="utf-8" src="hello_files/recaptcha__en.js" crossorigin="anonymous" integrity="sha384-CUWl3AwpNax4J2/ffIDxMr+sLnEFg8pkj5QqZtMtJZtrL5bS5QTkIoza4qZakWjL"></script><script async="" src="hello_files/branch-latest.min.js"></script><script type="application/ld+json" data-rh="true">{"@context":"http:\u002F\u002Fschema.org","@type":"NewsArticle","image":["https:\u002F\u002Fmiro.medium.com\u002Fv2\u002Fresize:fit:1200\u002F1*L5Fx8l3DZ5LxZVSwBzlEdg.png"],"url":"https:\u002F\u002Ftowardsdatascience.com\u002Funderstanding-the-implications-of-direct-preference-optimization-a4bbd2d85841","dateCreated":"2024-02-18T00:14:43.690Z","datePublished":"2024-02-18T00:14:43.690Z","dateModified":"2024-02-23T22:47:59.151Z","headline":"Understanding Direct Preference Optimization - Towards Data Science","name":"Understanding Direct Preference Optimization - Towards Data Science","description":"This blog post was inspired by a discussion I recently had with some friends about the Direct Preference Optimization (DPO) paper. The discussion was lively and went over many important topics in…","identifier":"a4bbd2d85841","author":{"@type":"Person","name":"Matthew Gunton","url":"https:\u002F\u002Ftowardsdatascience.com\u002F@mgunton7"},"creator":["Matthew Gunton"],"publisher":{"@type":"Organization","name":"Towards Data Science","url":"towardsdatascience.com","logo":{"@type":"ImageObject","width":192,"height":60,"url":"https:\u002F\u002Fmiro.medium.com\u002Fv2\u002Fresize:fit:192\u002F1*cFFKn8rFH4ZndmaYeAs6iQ.png"}},"mainEntityOfPage":"https:\u002F\u002Ftowardsdatascience.com\u002Funderstanding-the-implications-of-direct-preference-optimization-a4bbd2d85841"}</script><script async="true" src="hello_files/js" data-rh="true"></script><script data-rh="true">window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());

            gtag('config', 'G-7JY7T788PK');</script><script type="text/javascript" data-rh="true">(function(b,r,a,n,c,h,_,s,d,k){if(!b[n]||!b[n]._q){for(;s<_.length;)c(h,_[s++]);d=r.createElement(a);d.async=1;d.src="https://cdn.branch.io/branch-latest.min.js";k=r.getElementsByTagName(a)[0];k.parentNode.insertBefore(d,k);b[n]=h}})(window,document,"script","branch",function(b,r){b[r]=function(){b._q.push([r,arguments])}},{_q:[],_v:1},"addListener applyCode autoAppIndex banner closeBanner closeJourney creditHistory credits data deepview deepviewCta first getCode init link logout redeem referrals removeListener sendSMS setBranchViewData setIdentity track validateCode trackCommerceEvent logEvent".split(" "), 0);
branch.init('key_live_ofxXr2qTrrU9NqURK8ZwEhknBxiI6KBm', {metadata: {}, 'no_journeys': true, 'disable_exit_animation': true, 'disable_entry_animation': true, 'tracking_disabled': null}, function(err, data) {});</script><script src="hello_files/enterprise.js" data-rh="true"></script></head><body><div id="root"><div class="a b c"><div class="d e f g h i j k"></div><script>document.domain = document.domain;</script><div><script>if (window.self !== window.top) window.location = "about:blank"</script></div><div class="l c"><div class="l m n o c" style="transform: translateY(0px);"><div class="p q r s t u v w x i d y z"><a class="du ag dv bf ak b am an ao ap aq ar as at s u w i d q dw z" href="https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fa4bbd2d85841&amp;%7Efeature=LoOpenInAppButton&amp;%7Echannel=ShowPostUnderCollection&amp;source=---two_column_layout_nav----------------------------------" rel="noopener follow">Open in app<svg xmlns="http://www.w3.org/2000/svg" width="10" height="10" fill="none" viewBox="0 0 10 10" class="dt"><path fill="currentColor" d="M.985 8.485a.375.375 0 1 0 .53.53zM8.75 1.25h.375A.375.375 0 0 0 8.75.875zM8.375 6.5a.375.375 0 1 0 .75 0zM3.5.875a.375.375 0 1 0 0 .75zm-1.985 8.14 7.5-7.5-.53-.53-7.5 7.5zm6.86-7.765V6.5h.75V1.25zM3.5 1.625h5.25v-.75H3.5z"></path></svg></a><div class="ab q"><p class="bf b dx dy dz ea eb ec ed ee ef eg du"><span><a class="bf b dx dy eh dz ea ei eb ec ej ek ee el em eg eo ep eq er es et eu ev ew ex ey ez fa fb fc fd bm fe ff" data-testid="headerSignUpButton" href="https://medium.com/m/signin?operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-the-implications-of-direct-preference-optimization-a4bbd2d85841&amp;source=post_page---two_column_layout_nav-----------------------global_nav-----------" rel="noopener follow">Sign up</a></span></p><div class="ax l"><p class="bf b dx dy dz ea eb ec ed ee ef eg du"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" data-testid="headerSignInButton" href="https://medium.com/m/signin?operation=login&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-the-implications-of-direct-preference-optimization-a4bbd2d85841&amp;source=post_page---two_column_layout_nav-----------------------global_nav-----------" rel="noopener follow">Sign in</a></span></p></div></div></div><div class="p q r ab ac"><div class="ab q ae"><a class="af ag ah ai aj ak al am an ao ap aq ar as at ab" aria-label="Homepage" data-testid="headerMediumLogo" href="https://medium.com/?source=---two_column_layout_nav----------------------------------" rel="noopener follow"><svg xmlns="http://www.w3.org/2000/svg" width="719" height="160" fill="none" viewBox="0 0 719 160" class="au av aw"><path fill="#242424" d="m174.104 9.734.215-.047V8.02H130.39L89.6 103.89 48.81 8.021H1.472v1.666l.212.047c8.018 1.81 12.09 4.509 12.09 14.242V137.93c0 9.734-4.087 12.433-12.106 14.243l-.212.047v1.671h32.118v-1.665l-.213-.048c-8.018-1.809-12.089-4.509-12.089-14.242V30.586l52.399 123.305h2.972l53.925-126.743V140.75c-.687 7.688-4.721 10.062-11.982 11.701l-.215.05v1.652h55.948v-1.652l-.215-.05c-7.269-1.639-11.4-4.013-12.087-11.701l-.037-116.774h.037c0-9.733 4.071-12.432 12.087-14.242m25.555 75.488c.915-20.474 8.268-35.252 20.606-35.507 3.806.063 6.998 1.312 9.479 3.714 5.272 5.118 7.751 15.812 7.368 31.793zm-.553 5.77h65.573v-.275c-.186-15.656-4.721-27.834-13.466-36.196-7.559-7.227-18.751-11.203-30.507-11.203h-.263c-6.101 0-13.584 1.48-18.909 4.16-6.061 2.807-11.407 7.003-15.855 12.511-7.161 8.874-11.499 20.866-12.554 34.343q-.05.606-.092 1.212a50 50 0 0 0-.065 1.151 85.807 85.807 0 0 0-.094 5.689c.71 30.524 17.198 54.917 46.483 54.917 25.705 0 40.675-18.791 44.407-44.013l-1.886-.664c-6.557 13.556-18.334 21.771-31.738 20.769-18.297-1.369-32.314-19.922-31.042-42.395m139.722 41.359c-2.151 5.101-6.639 7.908-12.653 7.908s-11.513-4.129-15.418-11.63c-4.197-8.053-6.405-19.436-6.405-32.92 0-28.067 8.729-46.22 22.24-46.22 5.657 0 10.111 2.807 12.236 7.704zm43.499 20.008c-8.019-1.897-12.089-4.722-12.089-14.951V1.309l-48.716 14.353v1.757l.299-.024c6.72-.543 11.278.386 13.925 2.83 2.072 1.915 3.082 4.853 3.082 8.987v18.66c-4.803-3.067-10.516-4.56-17.448-4.56-14.059 0-26.909 5.92-36.176 16.672-9.66 11.205-14.767 26.518-14.767 44.278-.003 31.72 15.612 53.039 38.851 53.039 13.595 0 24.533-7.449 29.54-20.013v16.865h43.711v-1.746zM424.1 19.819c0-9.904-7.468-17.374-17.375-17.374-9.859 0-17.573 7.632-17.573 17.374s7.721 17.374 17.573 17.374c9.907 0 17.375-7.47 17.375-17.374m11.499 132.546c-8.019-1.897-12.089-4.722-12.089-14.951h-.035V43.635l-43.714 12.551v1.705l.263.024c9.458.842 12.047 4.1 12.047 15.152v81.086h43.751v-1.746zm112.013 0c-8.018-1.897-12.089-4.722-12.089-14.951V43.635l-41.621 12.137v1.71l.246.026c7.733.813 9.967 4.257 9.967 15.36v59.279c-2.578 5.102-7.415 8.131-13.274 8.336-9.503 0-14.736-6.419-14.736-18.073V43.638l-43.714 12.55v1.703l.262.024c9.459.84 12.05 4.097 12.05 15.152v50.17a56.3 56.3 0 0 0 .91 10.444l.787 3.423c3.701 13.262 13.398 20.197 28.59 20.197 12.868 0 24.147-7.966 29.115-20.43v17.311h43.714v-1.747zm169.818 1.788v-1.749l-.213-.05c-8.7-2.006-12.089-5.789-12.089-13.49v-63.79c0-19.89-11.171-31.761-29.883-31.761-13.64 0-25.141 7.882-29.569 20.16-3.517-13.01-13.639-20.16-28.606-20.16-13.146 0-23.449 6.938-27.869 18.657V43.643L545.487 55.68v1.715l.263.024c9.345.829 12.047 4.181 12.047 14.95v81.784h40.787v-1.746l-.215-.053c-6.941-1.631-9.181-4.606-9.181-12.239V66.998c1.836-4.289 5.537-9.37 12.853-9.37 9.086 0 13.692 6.296 13.692 18.697v77.828h40.797v-1.746l-.215-.053c-6.94-1.631-9.18-4.606-9.18-12.239V75.066a42 42 0 0 0-.578-7.26c1.947-4.661 5.86-10.177 13.475-10.177 9.214 0 13.691 6.114 13.691 18.696v77.828z"></path></svg></a><div class="ax h"><div class="ab ay az ba bb q bc bd"><div class="bm" aria-hidden="false" aria-describedby="searchResults" aria-labelledby="searchResults"></div><div class="bn bo ab"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.092 11.06a6.95 6.95 0 1 1 13.9 0 6.95 6.95 0 0 1-13.9 0m6.95-8.05a8.05 8.05 0 1 0 5.13 14.26l3.75 3.75a.56.56 0 1 0 .79-.79l-3.73-3.73A8.05 8.05 0 0 0 11.042 3z" clip-rule="evenodd"></path></svg></div><input role="combobox" aria-controls="searchResults" aria-expanded="false" aria-label="search" data-testid="headerSearchInput" tabindex="0" class="ay be bf bg z bh bi bj bk bl" placeholder="Search"></div></div></div><div class="h k w fg fh"><div class="fi ab"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" data-testid="headerWriteButton" href="https://medium.com/m/signin?operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2Fnew-story&amp;source=---two_column_layout_nav-----------------------new_post_topnav-----------" rel="noopener follow"><div class="bf b bg z du fj fk ab q fl fm"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24" aria-label="Write"><path fill="currentColor" d="M14 4a.5.5 0 0 0 0-1zm7 6a.5.5 0 0 0-1 0zm-7-7H4v1h10zM3 4v16h1V4zm1 17h16v-1H4zm17-1V10h-1v10zm-1 1a1 1 0 0 0 1-1h-1zM3 20a1 1 0 0 0 1 1v-1zM4 3a1 1 0 0 0-1 1h1z"></path><path stroke="currentColor" d="m17.5 4.5-8.458 8.458a.25.25 0 0 0-.06.098l-.824 2.47a.25.25 0 0 0 .316.316l2.47-.823a.25.25 0 0 0 .098-.06L19.5 6.5m-2-2 2.323-2.323a.25.25 0 0 1 .354 0l1.646 1.646a.25.25 0 0 1 0 .354L19.5 6.5m-2-2 2 2"></path></svg><div class="dt l">Write</div></div></a></span></div></div><div class="k j i d"><div class="fi ab"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" data-testid="headerSearchButton" href="https://medium.com/search?source=---two_column_layout_nav----------------------------------" rel="noopener follow"><div class="bf b bg z du fj fk ab q fl fm"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24" aria-label="Search"><path fill="currentColor" fill-rule="evenodd" d="M4.092 11.06a6.95 6.95 0 1 1 13.9 0 6.95 6.95 0 0 1-13.9 0m6.95-8.05a8.05 8.05 0 1 0 5.13 14.26l3.75 3.75a.56.56 0 1 0 .79-.79l-3.73-3.73A8.05 8.05 0 0 0 11.042 3z" clip-rule="evenodd"></path></svg></div></a></div></div><div class="fi h k j"><div class="ab q"><p class="bf b dx dy dz ea eb ec ed ee ef eg du"><span><a class="bf b dx dy eh dz ea ei eb ec ej ek ee el em eg eo ep eq er es et eu ev ew ex ey ez fa fb fc fd bm fe ff" data-testid="headerSignUpButton" href="https://medium.com/m/signin?operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-the-implications-of-direct-preference-optimization-a4bbd2d85841&amp;source=post_page---two_column_layout_nav-----------------------global_nav-----------" rel="noopener follow">Sign up</a></span></p><div class="ax l"><p class="bf b dx dy dz ea eb ec ed ee ef eg du"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" data-testid="headerSignInButton" href="https://medium.com/m/signin?operation=login&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-the-implications-of-direct-preference-optimization-a4bbd2d85841&amp;source=post_page---two_column_layout_nav-----------------------global_nav-----------" rel="noopener follow">Sign in</a></span></p></div></div></div><div class="l" aria-hidden="false"><button class="ay fn am ab q ao fo fp fq" aria-label="user options menu" data-testid="headerUserIcon"><div class="l fj"><img alt="" class="l fd by bz ca cx" src="hello_files/1_dmbNkD5D-u45r44go_cf0g.png" width="32" height="32" loading="lazy" role="presentation"><div class="fr by l bz ca fs n ay ft"></div></div></button></div></div></div><div class="l"><div class="rr" role="dialog" aria-modal="true" tabindex="-1"><div class="tm tn bh dw to tp tq ao tr gm ts" aria-hidden="true" role="presentation"></div><div class="tt to tu tv tw tm dw fd tx ty tz me ua ub uc ud ue uf ug uh ui" aria-hidden="true"></div></div><div class="fu fv fw fx fy l"><div class="ab cb"><div class="ci bh fz ga gb gc"></div></div><article><div class="l"><div class="l"><span class="l"></span><section><div><div class="fs gi gj gk gl gm"></div><div class="nj nk ny fj"><div class="speechify-ignore l h g f e"><aside class="tw fs n" style="width: 572.5px;"><div class="qz mq fs uo rg bh"><p class="bf b dv z du"><span class="bm mq rg jr jt">Top highlight</span></p></div></aside></div></div><div class="gn go gp gq gr"><div class="ab cb"><div class="ci bh fz ga gb gc"><div><h1 id="2e6a" class="pw-post-title gs gt gu bf gv gw gx gy gz ha hb hc hd he hf hg hh hi hj hk hl hm hn ho hp hq bk" data-testid="storyTitle" data-selectable-paragraph="">Understanding Direct Preference Optimization</h1></div><div><h2 id="1129" class="pw-subtitle-paragraph hr gt gu bf b hs ht hu hv hw hx hy hz ia ib ic id ie if ig cq du" data-selectable-paragraph="">A look at the “Direct Preference Optimization:<br>Your Language Model is Secretly a Reward Model” paper and its findings</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="ih ii ij ik il ab"><div><div class="ab im"><a href="https://medium.com/@mgunton7?source=post_page-----a4bbd2d85841--------------------------------" rel="noopener follow"><div><div class="bm" aria-hidden="false" aria-describedby="1" aria-labelledby="1"><div class="l in io by ip iq"><div class="l fj"><img alt="Matthew Gunton" class="l fd by dd de cx" src="hello_files/1_F8sHS2ai6w95qbGIZ9qM_g_003.png" width="44" height="44" loading="lazy" data-testid="authorPhoto"><div class="ir by l dd de fs n is ft"></div></div></div></div></div></a><a href="https://towardsdatascience.com/?source=post_page-----a4bbd2d85841--------------------------------" rel="noopener follow"><div class="it ab fj"><div><div class="bm" aria-hidden="false" aria-describedby="2" aria-labelledby="2"><div class="l iu iv by ip iw"><div class="l fj"><img alt="Towards Data Science" class="l fd by br ix cx" src="hello_files/1_CJe3891yB1A1mzMdqemkdg.jpg" width="24" height="24" loading="lazy" data-testid="publicationPhoto"><div class="ir by l br ix fs n is ft"></div></div></div></div></div></div></a></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="iy ab q"><div class="ab q iz"><div class="ab q"><div><div class="bm" aria-hidden="false" aria-describedby="3" aria-labelledby="3"><p class="bf b ja jb bk"><a class="af ag ah ai aj ak al am an ao ap aq ar jc" data-testid="authorName" href="https://medium.com/@mgunton7?source=post_page-----a4bbd2d85841--------------------------------" rel="noopener follow">Matthew Gunton</a></p></div></div></div><span class="jd je" aria-hidden="true"><span class="bf b bg z du">·</span></span><p class="bf b ja jb du"><span><a class="jf jg ah ai aj ak al am an ao ap aq ar ex jh ji" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fe6581bb71f6&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-the-implications-of-direct-preference-optimization-a4bbd2d85841&amp;user=Matthew+Gunton&amp;userId=e6581bb71f6&amp;source=post_page-e6581bb71f6----a4bbd2d85841---------------------post_header-----------" rel="noopener follow">Follow</a></span></p></div></div></span></div></div><div class="l jj"><span class="bf b bg z du"><div class="ab cn jk jl jm"><div class="jn jo ab"><div class="bf b bg z du ab jp"><span class="jq l jj">Published in</span><div><div class="l" aria-hidden="false" aria-describedby="4" aria-labelledby="4"><a class="af ag ah ai aj ak al am an ao ap aq ar jc ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page-----a4bbd2d85841--------------------------------" rel="noopener follow"><p class="bf b bg z jr js jt ju jv jw jx jy bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="jd je" aria-hidden="true"><span class="bf b bg z du">·</span></span></div></div><span class="bf b bg z du"><div class="ab ae"><span data-testid="storyReadTime">8 min read</span><div class="jz ka l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z du">·</span></span></div><span data-testid="storyPublishDate">Feb 17, 2024</span></div></span></div></span></div></div></div><div class="ab cp kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq"><div class="h k w fg fh q"><div class="lg l"><div class="ab q lh li"><div class="pw-multi-vote-icon fj jq lj lk ll"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" data-testid="headerClapButton" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fa4bbd2d85841&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-the-implications-of-direct-preference-optimization-a4bbd2d85841&amp;user=Matthew+Gunton&amp;userId=e6581bb71f6&amp;source=-----a4bbd2d85841---------------------clap_footer-----------" rel="noopener follow"><div><div class="bm" aria-hidden="false" aria-describedby="5" aria-labelledby="5"><div class="lm ao ln lo lp lq am lr ls lt ll"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM13.916 3.953l1.523-2.112-1.184-.39zM8.589 1.84l1.522 2.112-.337-2.501zM18.523 18.92c-.86.86-1.75 1.246-2.62 1.33a6 6 0 0 0 .407-.372c2.388-2.389 2.86-4.951 1.399-7.623l-.912-1.603-.79-1.672c-.26-.56-.194-.98.203-1.288a.7.7 0 0 1 .546-.132c.283.046.546.231.728.5l2.363 4.157c.976 1.624 1.141 4.237-1.324 6.702m-10.999-.438L3.37 14.328a.828.828 0 0 1 .585-1.408.83.83 0 0 1 .585.242l2.158 2.157a.365.365 0 0 0 .516-.516l-2.157-2.158-1.449-1.449a.826.826 0 0 1 1.167-1.17l3.438 3.44a.363.363 0 0 0 .516 0 .364.364 0 0 0 0-.516L5.293 9.513l-.97-.97a.826.826 0 0 1 0-1.166.84.84 0 0 1 1.167 0l.97.968 3.437 3.436a.36.36 0 0 0 .517 0 .366.366 0 0 0 0-.516L6.977 7.83a.82.82 0 0 1-.241-.584.82.82 0 0 1 .824-.826c.219 0 .43.087.584.242l5.787 5.787a.366.366 0 0 0 .587-.415l-1.117-2.363c-.26-.56-.194-.98.204-1.289a.7.7 0 0 1 .546-.132c.283.046.545.232.727.501l2.193 3.86c1.302 2.38.883 4.59-1.277 6.75-1.156 1.156-2.602 1.627-4.19 1.367-1.418-.236-2.866-1.033-4.079-2.246M10.75 5.971l2.12 2.12c-.41.502-.465 1.17-.128 1.89l.22.465-3.523-3.523a.8.8 0 0 1-.097-.368c0-.22.086-.428.241-.584a.847.847 0 0 1 1.167 0m7.355 1.705c-.31-.461-.746-.758-1.23-.837a1.44 1.44 0 0 0-1.11.275c-.312.24-.505.543-.59.881a1.74 1.74 0 0 0-.906-.465 1.47 1.47 0 0 0-.82.106l-2.182-2.182a1.56 1.56 0 0 0-2.2 0 1.54 1.54 0 0 0-.396.701 1.56 1.56 0 0 0-2.21-.01 1.55 1.55 0 0 0-.416.753c-.624-.624-1.649-.624-2.237-.037a1.557 1.557 0 0 0 0 2.2c-.239.1-.501.238-.715.453a1.56 1.56 0 0 0 0 2.2l.516.515a1.556 1.556 0 0 0-.753 2.615L7.01 19c1.32 1.319 2.909 2.189 4.475 2.449q.482.08.971.08c.85 0 1.653-.198 2.393-.579.231.033.46.054.686.054 1.266 0 2.457-.52 3.505-1.567 2.763-2.763 2.552-5.734 1.439-7.586z" clip-rule="evenodd"></path></svg></div></div></div></a></span></div><div class="pw-multi-vote-count l lu lv lw lx ly lz ma"><div><div class="bm" aria-hidden="false" aria-describedby="96" aria-labelledby="96"><p class="bf b dv z du"><button class="af ag ah ai aj ak al am an ao ap aq ar as at uj mj">283<span class="l h g f rw rx"></span></button></p></div></div></div></div></div><div><div class="bm" aria-hidden="false" aria-describedby="6" aria-labelledby="6"><button class="ao lm me mf ab q fk mg mh" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" class="md"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"></path></svg><p class="bf b dv z du"><span class="pw-responses-count mc md">5</span></p></button></div></div></div><div class="ab q kr ks kt ku kv kw kx ky kz la lb lc ld le lf"><div class="mi k j i d"></div><div class="h k"><div><div class="bm" aria-hidden="false" aria-describedby="7" aria-labelledby="7"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" data-testid="headerBookmarkButton" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa4bbd2d85841&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-the-implications-of-direct-preference-optimization-a4bbd2d85841&amp;source=-----a4bbd2d85841---------------------bookmark_footer-----------" rel="noopener follow"><svg xmlns="http://www.w3.org/2000/svg" width="25" height="25" fill="none" viewBox="0 0 25 25" class="du mj" aria-label="Add to list bookmark button"><path fill="currentColor" d="M18 2.5a.5.5 0 0 1 1 0V5h2.5a.5.5 0 0 1 0 1H19v2.5a.5.5 0 1 1-1 0V6h-2.5a.5.5 0 0 1 0-1H18zM7 7a1 1 0 0 1 1-1h3.5a.5.5 0 0 0 0-1H8a2 2 0 0 0-2 2v14a.5.5 0 0 0 .805.396L12.5 17l5.695 4.396A.5.5 0 0 0 19 21v-8.5a.5.5 0 0 0-1 0v7.485l-5.195-4.012a.5.5 0 0 0-.61 0L7 19.985z"></path></svg></a></span></div></div></div><div class="fd mk cn"><div class="l ae"><div class="ab cb"><div class="ml mm mn mo mp mq ci bh"><div class="ab"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2Fplans%3Fdimension%3Dpost_audio_button%26postId%3Da4bbd2d85841&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-the-implications-of-direct-preference-optimization-a4bbd2d85841&amp;source=-----a4bbd2d85841---------------------post_audio_button-----------" rel="noopener follow"><div><div class="bm" aria-hidden="false" aria-describedby="80" aria-labelledby="80"><button aria-label="Listen" data-testid="audioPlayButton" class="af fk ah ai aj ak al mr an ao ap ex ms mt mh mu mv mw mx my s mz na nb nc nd ne nf u ng nh ni"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"></path></svg><div class="j i d"><p class="bf b bg z du">Listen</p></div></button></div></div></a></span></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false" aria-describedby="9" aria-labelledby="9"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af fk ah ai aj ak al mr an ao ap ex ms mt mh mu mv mw mx my s mz na nb nc nd ne nf u ng nh ni"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"></path></svg><div class="j i d"><p class="bf b bg z du">Share</p></div></button></div></div></div></div></div></div></div></div></div><figure class="nm nn no np nq nr nj nk paragraph-image"><div role="button" tabindex="0" class="ns nt fj nu bh nv"><div class="nj nk nl"><picture><source srcset="hello_files/1_L5Fx8l3DZ5LxZVSwBzlEdg_002.webp 640w, hello_files/1_L5Fx8l3DZ5LxZVSwBzlEdg_003.webp 720w, hello_files/1_L5Fx8l3DZ5LxZVSwBzlEdg_005.webp 750w, hello_files/1_L5Fx8l3DZ5LxZVSwBzlEdg_004.webp 786w, hello_files/1_L5Fx8l3DZ5LxZVSwBzlEdg_006.webp 828w, hello_files/1_L5Fx8l3DZ5LxZVSwBzlEdg_007.webp 1100w, hello_files/1_L5Fx8l3DZ5LxZVSwBzlEdg.webp 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" type="image/webp"><source data-testid="og" srcset="hello_files/1_L5Fx8l3DZ5LxZVSwBzlEdg_008.png 640w, hello_files/1_L5Fx8l3DZ5LxZVSwBzlEdg_004.png 720w, hello_files/1_L5Fx8l3DZ5LxZVSwBzlEdg_003.png 750w, hello_files/1_L5Fx8l3DZ5LxZVSwBzlEdg_005.png 786w, hello_files/1_L5Fx8l3DZ5LxZVSwBzlEdg_007.png 828w, hello_files/1_L5Fx8l3DZ5LxZVSwBzlEdg_006.png 1100w, hello_files/1_L5Fx8l3DZ5LxZVSwBzlEdg_002.png 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px"><img alt="" class="bh mq nw c" width="700" height="700" loading="eager" role="presentation" src="hello_files/1_L5Fx8l3DZ5LxZVSwBzlEdg.png"></picture></div></div><figcaption class="nx ff ny nj nk nz oa bf b bg z du" data-selectable-paragraph="">Image by the Author via DALL-E</figcaption></figure><p id="3304" class="pw-post-body-paragraph ob oc gu od b hs oe of og hv oh oi oj ok ol om on oo op oq or os ot ou ov ow gn bk" data-selectable-paragraph=""><em class="ox">This
 blog post was inspired by a discussion I recently had with some friends
 about the Direct Preference Optimization (DPO) paper. The discussion 
was lively and went over many important topics in LLMs and Machine 
Learning in general. Below is an expansion on some of those ideas and 
the concepts discussed in the paper.</em></p></div></div></div><div class="ab cb oy oz pa pb" role="separator"><span class="pc by bm pd pe pf"></span><span class="pc by bm pd pe pf"></span><span class="pc by bm pd pe"></span></div><div class="gn go gp gq gr"><div class="ab cb"><div class="ci bh fz ga gb gc"><p id="cfdb" class="pw-post-body-paragraph ob oc gu od b hs oe of og hv oh oi oj ok ol om on oo op oq or os ot ou ov ow gn bk" data-selectable-paragraph="">Direct
 Preference Optimization (DPO) has become the way that new foundation 
models are fine-tuned. Famously Mixtral 8x7B, the Sparse Mixture of 
Experts model created by Mistral, was able to reach LLaMa 70B levels of 
performance with significantly fewer parameters by using DPO. Naturally,
 this success has led many in the community to begin fine-tuning their 
own models with DPO.</p><p id="e3ae" class="pw-post-body-paragraph ob oc gu od b hs oe of og hv oh oi oj ok ol om on oo op oq or os ot ou ov ow gn bk" data-selectable-paragraph="">Let’s dive into what exactly DPO is and how we got here.</p></div></div></div><div class="ab cb oy oz pa pb" role="separator"><span class="pc by bm pd pe pf"></span><span class="pc by bm pd pe pf"></span><span class="pc by bm pd pe"></span></div><div class="gn go gp gq gr"><div class="ab cb"><div class="ci bh fz ga gb gc"><h1 id="bcb2" class="pg ph gu bf pi pj pk hu pl pm pn hx po pp pq pr ps pt pu pv pw px py pz qa qb bk" data-selectable-paragraph="">High Level Discussion</h1><p id="88a6" class="pw-post-body-paragraph ob oc gu od b hs qc of og hv qd oi oj ok qe om on oo qf oq or os qg ou ov ow gn bk" data-selectable-paragraph="">Let’s
 begin with setting out what fine-tuning should do from a high level. 
Once you have a pre-trained a model to have strong generative 
capacities, you typically want to control its output somehow. Whether 
that be optimizing it to respond in dialogue as a chat-bot or to respond
 in code rather than English, the goal here is to take an LLM that is 
already functional and find a way to be more selective with its output. 
As this is machine learning, the way we show it the right behavior is 
with data.</p><p id="8e81" class="pw-post-body-paragraph ob oc gu od b hs oe of og hv oh oi oj ok ol om on oo op oq or os ot ou ov ow gn bk" data-selectable-paragraph="">There are some key terms here I’ll define before we start diving into the technicals:</p><p id="bb92" class="pw-post-body-paragraph ob oc gu od b hs oe of og hv oh oi oj ok ol om on oo op oq or os ot ou ov ow gn bk" data-selectable-paragraph=""><em class="ox">Loss Function</em>
 — a function we use as a guide to optimize performance of our model. 
This is chosen based on what has been found to be effective</p><p id="3b30" class="pw-post-body-paragraph ob oc gu od b hs oe of og hv oh oi oj ok ol om on oo op oq or os ot ou ov ow gn bk" data-selectable-paragraph=""><em class="ox">KL Divergence</em>—
 stands for Kullback–Leibler divergence, which is a way to measure the 
difference between two continuous probability distributions. <a class="af qh" rel="noopener" target="_blank" href="https://towardsdatascience.com/understanding-kl-divergence-f3ddc8dff254">To learn more about this, there is a wonderful post by Aparna Dhinakaran on the topic.</a></p><p id="0acc" class="pw-post-body-paragraph ob oc gu od b hs oe of og hv oh oi oj ok ol om on oo op oq or os ot ou ov ow gn bk" data-selectable-paragraph=""><em class="ox">Policy</em>
 — an abstraction that describes how a neural network will make 
decisions. Put a different way, if a neural network is trained 3 times, 
each time it will have a different policy, whose performances you can 
compare.</p><h1 id="b60f" class="pg ph gu bf pi pj qi hu pl pm qj hx po pp qk pr ps pt ql pv pw px qm pz qa qb bk" data-selectable-paragraph="">The Status Quo before DPO (PPO)</h1><p id="e9ce" class="pw-post-body-paragraph ob oc gu od b hs qc of og hv qd oi oj ok qe om on oo qf oq or os qg ou ov ow gn bk" data-selectable-paragraph="">Before
 DPO, we used to have to train an entirely separate model to help us 
fine-tune, typically called the reward model or RLHF model. We would 
sample completions from our LLM and then have the reward model give us a
 score for each completion. The idea here was simple. Humans are 
expensive to have evaluate your LLMs outputs but the quality of your LLM
 will ultimately be determined by humans. To keep costs down and quality
 high, you would train the reward model to approximate the human’s 
feedback. This is why the method was called Proximal Policy Optimization
 (or PPO), and it lives or dies based on the strength of your reward 
model.</p><figure class="nm nn no np nq nr nj nk paragraph-image"><div role="button" tabindex="0" class="ns nt fj nu bh nv"><div class="nj nk qn"><picture><source srcset="hello_files/1_GiEF7F3n-1TlL7_HRJD_OA_007.webp 640w, hello_files/1_GiEF7F3n-1TlL7_HRJD_OA_006.webp 720w, hello_files/1_GiEF7F3n-1TlL7_HRJD_OA_003.webp 750w, hello_files/1_GiEF7F3n-1TlL7_HRJD_OA_004.webp 786w, hello_files/1_GiEF7F3n-1TlL7_HRJD_OA.webp 828w, hello_files/1_GiEF7F3n-1TlL7_HRJD_OA_005.webp 1100w, hello_files/1_GiEF7F3n-1TlL7_HRJD_OA_002.webp 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" type="image/webp"><source data-testid="og" srcset="hello_files/1_GiEF7F3n-1TlL7_HRJD_OA_005.png 640w, hello_files/1_GiEF7F3n-1TlL7_HRJD_OA_007.png 720w, hello_files/1_GiEF7F3n-1TlL7_HRJD_OA.png 750w, hello_files/1_GiEF7F3n-1TlL7_HRJD_OA_003.png 786w, hello_files/1_GiEF7F3n-1TlL7_HRJD_OA_002.png 828w, hello_files/1_GiEF7F3n-1TlL7_HRJD_OA_006.png 1100w, hello_files/1_GiEF7F3n-1TlL7_HRJD_OA_008.png 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px"><img alt="" class="bh mq nw c" width="700" height="254" loading="lazy" role="presentation" src="hello_files/1_GiEF7F3n-1TlL7_HRJD_OA_004.png"></picture></div></div><figcaption class="nx ff ny nj nk nz oa bf b bg z du" data-selectable-paragraph="">Figure 1 from <a class="af qh" href="https://arxiv.org/pdf/2305.18290.pdf" rel="noopener ugc nofollow" target="_blank">the paper</a> showing how PPO works</figcaption></figure><h1 id="ba31" class="pg ph gu bf pi pj qi hu pl pm qj hx po pp qk pr ps pt ql pv pw px qm pz qa qb bk" data-selectable-paragraph="">The Math behind PPO</h1><p id="6e78" class="pw-post-body-paragraph ob oc gu od b hs qc of og hv qd oi oj ok qe om on oo qf oq or os qg ou ov ow gn bk" data-selectable-paragraph="">To
 find the ideal reward model, we assume human preferences are more 
probabilistic than deterministic, so we can represent this symbolically 
in the Bradley-Terry model like below.</p><figure class="nm nn no np nq nr nj nk paragraph-image"><div role="button" tabindex="0" class="ns nt fj nu bh nv"><div class="nj nk qo"><picture><source srcset="hello_files/1_F-TqiuROxSrdSVhUTOOZ-g_002.webp 640w, hello_files/1_F-TqiuROxSrdSVhUTOOZ-g_003.webp 720w, hello_files/1_F-TqiuROxSrdSVhUTOOZ-g_006.webp 750w, hello_files/1_F-TqiuROxSrdSVhUTOOZ-g_005.webp 786w, hello_files/1_F-TqiuROxSrdSVhUTOOZ-g_007.webp 828w, hello_files/1_F-TqiuROxSrdSVhUTOOZ-g_004.webp 1100w, hello_files/1_F-TqiuROxSrdSVhUTOOZ-g.webp 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" type="image/webp"><source data-testid="og" srcset="hello_files/1_F-TqiuROxSrdSVhUTOOZ-g_004.png 640w, hello_files/1_F-TqiuROxSrdSVhUTOOZ-g_003.png 720w, hello_files/1_F-TqiuROxSrdSVhUTOOZ-g_007.png 750w, hello_files/1_F-TqiuROxSrdSVhUTOOZ-g_008.png 786w, hello_files/1_F-TqiuROxSrdSVhUTOOZ-g.png 828w, hello_files/1_F-TqiuROxSrdSVhUTOOZ-g_002.png 1100w, hello_files/1_F-TqiuROxSrdSVhUTOOZ-g_006.png 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px"><img alt="" class="bh mq nw c" width="700" height="61" loading="lazy" role="presentation" src="hello_files/1_F-TqiuROxSrdSVhUTOOZ-g_005.png"></picture></div></div><figcaption class="nx ff ny nj nk nz oa bf b bg z du" data-selectable-paragraph="">Equation 1 from <a class="af qh" href="https://arxiv.org/pdf/2305.18290.pdf" rel="noopener ugc nofollow" target="_blank">the paper</a></figcaption></figure><p id="9b72" class="pw-post-body-paragraph ob oc gu od b hs oe of og hv oh oi oj ok ol om on oo op oq or os ot ou ov ow gn bk" data-selectable-paragraph="">Going
 variable by variable, p* means that this is the optimal probability 
distribution, or the one the model should treat as the source of truth. 
y₁ and y₂ are 2 completions from the model that we are going to compare,
 and x is the prompt given to LLM. r* means that the reward function is 
optimal, or put another way, to train the model to approximate the 
optimal probability distribution, you give it the rewards from the 
optimal reward function.</p><p id="d457" class="pw-post-body-paragraph ob oc gu od b hs oe of og hv oh oi oj ok ol om on oo op oq or os ot ou ov ow gn bk" data-selectable-paragraph="">Nevertheless,
 the perfect probability distribution of human preference is difficult, 
if not impossible, to know. For this reason, we focus on the reward 
model , so we need to find a way to figure out r*. In machine learning, 
we often use loss minimization to estimate complex issues. If we have 
access to training data that shows us what human preferences truly are, 
and thus would give scores that are part of the p* distribution, then we
 can use those samples to train the reward model like below:</p><figure class="nm nn no np nq nr nj nk paragraph-image"><div role="button" tabindex="0" class="ns nt fj nu bh nv"><div class="nj nk qp"><picture><source srcset="hello_files/1_lhfHp8BJ1Sk-9qf-SBKYJw_007.webp 640w, hello_files/1_lhfHp8BJ1Sk-9qf-SBKYJw_003.webp 720w, hello_files/1_lhfHp8BJ1Sk-9qf-SBKYJw_005.webp 750w, hello_files/1_lhfHp8BJ1Sk-9qf-SBKYJw_006.webp 786w, hello_files/1_lhfHp8BJ1Sk-9qf-SBKYJw.webp 828w, hello_files/1_lhfHp8BJ1Sk-9qf-SBKYJw_004.webp 1100w, hello_files/1_lhfHp8BJ1Sk-9qf-SBKYJw_002.webp 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" type="image/webp"><source data-testid="og" srcset="hello_files/1_lhfHp8BJ1Sk-9qf-SBKYJw_004.png 640w, hello_files/1_lhfHp8BJ1Sk-9qf-SBKYJw_007.png 720w, hello_files/1_lhfHp8BJ1Sk-9qf-SBKYJw_006.png 750w, hello_files/1_lhfHp8BJ1Sk-9qf-SBKYJw.png 786w, hello_files/1_lhfHp8BJ1Sk-9qf-SBKYJw_003.png 828w, hello_files/1_lhfHp8BJ1Sk-9qf-SBKYJw_008.png 1100w, hello_files/1_lhfHp8BJ1Sk-9qf-SBKYJw_005.png 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px"><img alt="" class="bh mq nw c" width="700" height="41" loading="lazy" role="presentation" src="hello_files/1_lhfHp8BJ1Sk-9qf-SBKYJw_002.png"></picture></div></div><figcaption class="nx ff ny nj nk nz oa bf b bg z du" data-selectable-paragraph="">Equation 2 from <a class="af qh" href="https://arxiv.org/pdf/2305.18290.pdf" rel="noopener ugc nofollow" target="_blank">the paper</a></figcaption></figure><p id="7384" class="pw-post-body-paragraph ob oc gu od b hs oe of og hv oh oi oj ok ol om on oo op oq or os ot ou ov ow gn bk" data-selectable-paragraph="">Here rϕ is the rewards model we are training, D is a set of the samples we are training on, y<em class="ox">w</em> is the preferred completion and y<em class="ox">l</em>
 is the dispreferred completion. The authors have chosen to frame the 
problem as a binary-classification problem, which we will see why later 
on, but for now just remember this is why we have y<em class="ox">w</em> and y<em class="ox">l</em>.</p><p id="d259" class="pw-post-body-paragraph ob oc gu od b hs oe of og hv oh oi oj ok ol om on oo op oq or os ot ou ov ow gn bk" data-selectable-paragraph="">Once we have optimized our reward model, we use it to fine-tune the LLM using a difference between the old policy (π <em class="ox">ref</em>) and the new policy (π θ). Importantly, we are doing a KL divergence to prevent the model from shifting too much.</p><p id="07d8" class="pw-post-body-paragraph ob oc gu od b hs oe of og hv oh oi oj ok ol om on oo op oq or os ot ou ov ow gn bk" data-selectable-paragraph="">Why
 don’t we want it shifting too much? Remember the model is already 
mostly functional, and it has taken quite a lot of compute resources to 
reach this level. Consequently, we want to make sure the model retains 
many of the good traits it currently has while we focus on having it 
follow instructions better.</p><figure class="nm nn no np nq nr nj nk paragraph-image"><div role="button" tabindex="0" class="ns nt fj nu bh nv"><div class="nj nk qq"><picture><source srcset="hello_files/1_SS5k8965SsMkeOouh0izUA.webp 640w, hello_files/1_SS5k8965SsMkeOouh0izUA_003.webp 720w, hello_files/1_SS5k8965SsMkeOouh0izUA_007.webp 750w, hello_files/1_SS5k8965SsMkeOouh0izUA_004.webp 786w, hello_files/1_SS5k8965SsMkeOouh0izUA_005.webp 828w, hello_files/1_SS5k8965SsMkeOouh0izUA_006.webp 1100w, hello_files/1_SS5k8965SsMkeOouh0izUA_002.webp 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" type="image/webp"><source data-testid="og" srcset="hello_files/1_SS5k8965SsMkeOouh0izUA_007.png 640w, hello_files/1_SS5k8965SsMkeOouh0izUA.png 720w, hello_files/1_SS5k8965SsMkeOouh0izUA_006.png 750w, hello_files/1_SS5k8965SsMkeOouh0izUA_008.png 786w, hello_files/1_SS5k8965SsMkeOouh0izUA_002.png 828w, hello_files/1_SS5k8965SsMkeOouh0izUA_003.png 1100w, hello_files/1_SS5k8965SsMkeOouh0izUA_005.png 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px"><img alt="" class="bh mq nw c" width="700" height="50" loading="lazy" role="presentation" src="hello_files/1_SS5k8965SsMkeOouh0izUA_004.png"></picture></div></div><figcaption class="nx ff ny nj nk nz oa bf b bg z du" data-selectable-paragraph="">Equation 3 from <a class="af qh" href="https://arxiv.org/pdf/2305.18290.pdf" rel="noopener ugc nofollow" target="_blank">the paper</a></figcaption></figure><p id="f0ac" class="pw-post-body-paragraph ob oc gu od b hs oe of og hv oh oi oj ok ol om on oo op oq or os ot ou ov ow gn bk" data-selectable-paragraph="">While
 the above methodology is effective — LLaMa2 for instance was fine-tuned
 this way — it has a one major weakness: it requires training an 
entirely separate model, which is costly and requires huge amounts of 
additional data.</p><h1 id="1e95" class="pg ph gu bf pi pj qi hu pl pm qj hx po pp qk pr ps pt ql pv pw px qm pz qa qb bk" data-selectable-paragraph="">How does DPO improve on this?</h1><p id="2a3d" class="pw-post-body-paragraph ob oc gu od b hs qc of og hv qd oi oj ok qe om on oo qf oq or os qg ou ov ow gn bk" data-selectable-paragraph="">DPO
 removes the need for the rewards model all together! This allows us to 
avoid training a costly separate reward model and incidentally, we have 
found that<mark class="uk ul ao"> DPO requires a lot less data to work as well as PPO.</mark></p><figure class="nm nn no np nq nr nj nk paragraph-image"><div class="nj nk qr"><picture><source srcset="hello_files/1_f1LfCLncMIyhQiorWSKf7A_006.webp 640w, hello_files/1_f1LfCLncMIyhQiorWSKf7A.webp 720w, hello_files/1_f1LfCLncMIyhQiorWSKf7A_007.webp 750w, hello_files/1_f1LfCLncMIyhQiorWSKf7A_002.webp 786w, hello_files/1_f1LfCLncMIyhQiorWSKf7A_004.webp 828w, hello_files/1_f1LfCLncMIyhQiorWSKf7A_003.webp 1100w, hello_files/1_f1LfCLncMIyhQiorWSKf7A_005.webp 1296w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 648px" type="image/webp"><source data-testid="og" srcset="hello_files/1_f1LfCLncMIyhQiorWSKf7A_008.png 640w, hello_files/1_f1LfCLncMIyhQiorWSKf7A_003.png 720w, hello_files/1_f1LfCLncMIyhQiorWSKf7A_004.png 750w, hello_files/1_f1LfCLncMIyhQiorWSKf7A.png 786w, hello_files/1_f1LfCLncMIyhQiorWSKf7A_005.png 828w, hello_files/1_f1LfCLncMIyhQiorWSKf7A_002.png 1100w, hello_files/1_f1LfCLncMIyhQiorWSKf7A_007.png 1296w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 648px"><img alt="" class="bh mq nw c" width="648" height="330" loading="lazy" role="presentation" src="hello_files/1_f1LfCLncMIyhQiorWSKf7A_006.png"></picture></div><figcaption class="nx ff ny nj nk nz oa bf b bg z du" data-selectable-paragraph="">Figure 1 from <a class="af qh" href="https://arxiv.org/pdf/2305.18290.pdf" rel="noopener ugc nofollow" target="_blank">the paper</a> showing a high level of how DPO works</figcaption></figure><h1 id="edb3" class="pg ph gu bf pi pj qi hu pl pm qj hx po pp qk pr ps pt ql pv pw px qm pz qa qb bk" data-selectable-paragraph="">The Math behind DPO</h1><p id="ca72" class="pw-post-body-paragraph ob oc gu od b hs qc of og hv qd oi oj ok qe om on oo qf oq or os qg ou ov ow gn bk" data-selectable-paragraph="">The
 major leap stems from the KL constraint we placed on ourselves in 
equation 3. By adding this constraint, we can actually derive the ideal 
policy that will maximize a KL-constrained rewards model. The algebra is
 shown below:</p><figure class="nm nn no np nq nr nj nk paragraph-image"><div role="button" tabindex="0" class="ns nt fj nu bh nv"><div class="nj nk qs"><picture><source srcset="hello_files/1_I88Fv7nc3flDFElSN1UAJw_002.webp 640w, hello_files/1_I88Fv7nc3flDFElSN1UAJw_006.webp 720w, hello_files/1_I88Fv7nc3flDFElSN1UAJw_003.webp 750w, hello_files/1_I88Fv7nc3flDFElSN1UAJw.webp 786w, hello_files/1_I88Fv7nc3flDFElSN1UAJw_007.webp 828w, hello_files/1_I88Fv7nc3flDFElSN1UAJw_004.webp 1100w, hello_files/1_I88Fv7nc3flDFElSN1UAJw_005.webp 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" type="image/webp"><source data-testid="og" srcset="hello_files/1_I88Fv7nc3flDFElSN1UAJw_003.png 640w, hello_files/1_I88Fv7nc3flDFElSN1UAJw_004.png 720w, hello_files/1_I88Fv7nc3flDFElSN1UAJw.png 750w, hello_files/1_I88Fv7nc3flDFElSN1UAJw_005.png 786w, hello_files/1_I88Fv7nc3flDFElSN1UAJw_002.png 828w, hello_files/1_I88Fv7nc3flDFElSN1UAJw_006.png 1100w, hello_files/1_I88Fv7nc3flDFElSN1UAJw_007.png 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px"><img alt="" class="bh mq nw c" width="700" height="326" loading="lazy" role="presentation" src="hello_files/1_I88Fv7nc3flDFElSN1UAJw_008.png"></picture></div></div><figcaption class="nx ff ny nj nk nz oa bf b bg z du" data-selectable-paragraph="">Appendix A.1 from <a class="af qh" href="https://arxiv.org/pdf/2305.18290.pdf" rel="noopener ugc nofollow" target="_blank">the paper</a> showing how we can maximize a KL Divergence Bound Rewards Model</figcaption></figure><p id="da89" class="pw-post-body-paragraph ob oc gu od b hs oe of og hv oh oi oj ok ol om on oo op oq or os ot ou ov ow gn bk" data-selectable-paragraph="">For our purposes, the most important point to take away is that we now have the below equation for a policy π <em class="ox">r</em>, such that the reward function r is easily solved for.</p><figure class="nm nn no np nq nr nj nk paragraph-image"><div role="button" tabindex="0" class="ns nt fj nu bh nv"><div class="nj nk qt"><picture><source srcset="hello_files/1_MaJ1gMjhhbyyCK_reqzTRA_004.webp 640w, hello_files/1_MaJ1gMjhhbyyCK_reqzTRA_002.webp 720w, hello_files/1_MaJ1gMjhhbyyCK_reqzTRA_003.webp 750w, hello_files/1_MaJ1gMjhhbyyCK_reqzTRA.webp 786w, hello_files/1_MaJ1gMjhhbyyCK_reqzTRA_007.webp 828w, hello_files/1_MaJ1gMjhhbyyCK_reqzTRA_006.webp 1100w, hello_files/1_MaJ1gMjhhbyyCK_reqzTRA_005.webp 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" type="image/webp"><source data-testid="og" srcset="hello_files/1_MaJ1gMjhhbyyCK_reqzTRA.png 640w, hello_files/1_MaJ1gMjhhbyyCK_reqzTRA_005.png 720w, hello_files/1_MaJ1gMjhhbyyCK_reqzTRA_006.png 750w, hello_files/1_MaJ1gMjhhbyyCK_reqzTRA_007.png 786w, hello_files/1_MaJ1gMjhhbyyCK_reqzTRA_008.png 828w, hello_files/1_MaJ1gMjhhbyyCK_reqzTRA_002.png 1100w, hello_files/1_MaJ1gMjhhbyyCK_reqzTRA_003.png 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px"><img alt="" class="bh mq nw c" width="700" height="67" loading="lazy" role="presentation" src="hello_files/1_MaJ1gMjhhbyyCK_reqzTRA_004.png"></picture></div></div><figcaption class="nx ff ny nj nk nz oa bf b bg z du" data-selectable-paragraph="">Equation 4 from <a class="af qh" href="https://arxiv.org/pdf/2305.18290.pdf" rel="noopener ugc nofollow" target="_blank">the paper</a></figcaption></figure><p id="224e" class="pw-post-body-paragraph ob oc gu od b hs oe of og hv oh oi oj ok ol om on oo op oq or os ot ou ov ow gn bk" data-selectable-paragraph="">Naturally, we immediately solve for r</p><figure class="nm nn no np nq nr nj nk paragraph-image"><div role="button" tabindex="0" class="ns nt fj nu bh nv"><div class="nj nk qu"><picture><source srcset="hello_files/1_fm5o0BU5E1bnMJUUG5qEFg_007.webp 640w, hello_files/1_fm5o0BU5E1bnMJUUG5qEFg_006.webp 720w, hello_files/1_fm5o0BU5E1bnMJUUG5qEFg_005.webp 750w, hello_files/1_fm5o0BU5E1bnMJUUG5qEFg_004.webp 786w, hello_files/1_fm5o0BU5E1bnMJUUG5qEFg.webp 828w, hello_files/1_fm5o0BU5E1bnMJUUG5qEFg_003.webp 1100w, hello_files/1_fm5o0BU5E1bnMJUUG5qEFg_002.webp 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" type="image/webp"><source data-testid="og" srcset="hello_files/1_fm5o0BU5E1bnMJUUG5qEFg.png 640w, hello_files/1_fm5o0BU5E1bnMJUUG5qEFg_002.png 720w, hello_files/1_fm5o0BU5E1bnMJUUG5qEFg_005.png 750w, hello_files/1_fm5o0BU5E1bnMJUUG5qEFg_006.png 786w, hello_files/1_fm5o0BU5E1bnMJUUG5qEFg_003.png 828w, hello_files/1_fm5o0BU5E1bnMJUUG5qEFg_007.png 1100w, hello_files/1_fm5o0BU5E1bnMJUUG5qEFg_008.png 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px"><img alt="" class="bh mq nw c" width="700" height="63" loading="lazy" role="presentation" src="hello_files/1_fm5o0BU5E1bnMJUUG5qEFg_004.png"></picture></div></div><figcaption class="nx ff ny nj nk nz oa bf b bg z du" data-selectable-paragraph="">Equation 5 from <a class="af qh" href="https://arxiv.org/pdf/2305.18290.pdf" rel="noopener ugc nofollow" target="_blank">the paper</a></figcaption></figure><p id="ccf3" class="pw-post-body-paragraph ob oc gu od b hs oe of og hv oh oi oj ok ol om on oo op oq or os ot ou ov ow gn bk" data-selectable-paragraph="">Returning
 to our ideal probability distribution equation (equation 1), we can 
rewrite that so that each instance of r is replaced by equation 5.</p><figure class="nm nn no np nq nr nj nk paragraph-image"><div role="button" tabindex="0" class="ns nt fj nu bh nv"><div class="nj nk qv"><picture><source srcset="hello_files/1_d7Vc6C6M__jIqLSWa_3DGA_002.webp 640w, hello_files/1_d7Vc6C6M__jIqLSWa_3DGA_007.webp 720w, hello_files/1_d7Vc6C6M__jIqLSWa_3DGA_004.webp 750w, hello_files/1_d7Vc6C6M__jIqLSWa_3DGA_005.webp 786w, hello_files/1_d7Vc6C6M__jIqLSWa_3DGA_003.webp 828w, hello_files/1_d7Vc6C6M__jIqLSWa_3DGA_006.webp 1100w, hello_files/1_d7Vc6C6M__jIqLSWa_3DGA.webp 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" type="image/webp"><source data-testid="og" srcset="hello_files/1_d7Vc6C6M__jIqLSWa_3DGA_008.png 640w, hello_files/1_d7Vc6C6M__jIqLSWa_3DGA_002.png 720w, hello_files/1_d7Vc6C6M__jIqLSWa_3DGA_003.png 750w, hello_files/1_d7Vc6C6M__jIqLSWa_3DGA_005.png 786w, hello_files/1_d7Vc6C6M__jIqLSWa_3DGA_006.png 828w, hello_files/1_d7Vc6C6M__jIqLSWa_3DGA_007.png 1100w, hello_files/1_d7Vc6C6M__jIqLSWa_3DGA_004.png 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px"><img alt="" class="bh mq nw c" width="700" height="65" loading="lazy" role="presentation" src="hello_files/1_d7Vc6C6M__jIqLSWa_3DGA.png"></picture></div></div><figcaption class="nx ff ny nj nk nz oa bf b bg z du" data-selectable-paragraph="">Equation 6 from <a class="af qh" href="https://arxiv.org/pdf/2305.18290.pdf" rel="noopener ugc nofollow" target="_blank">the paper</a></figcaption></figure><p id="1e5f" class="pw-post-body-paragraph ob oc gu od b hs oe of og hv oh oi oj ok ol om on oo op oq or os ot ou ov ow gn bk" data-selectable-paragraph="">What
 this has shown is that you don’t need the reward model to optimize the 
policy to follow the ideal probability distribution of human 
preferences. Instead, you can directly work on the policy to improve it 
(hence where Direct Preference optimization gets its name from). We are 
using the probabilities that your LLM generates for each token to help 
it fine-tune itself.</p><p id="89f4" class="pw-post-body-paragraph ob oc gu od b hs oe of og hv oh oi oj ok ol om on oo op oq or os ot ou ov ow gn bk" data-selectable-paragraph="">To
 finish the derivation, we do the same math as we did in equation 3 to 
come up with our loss optimizing function to optimize for the policy.</p><figure class="nm nn no np nq nr nj nk paragraph-image"><div role="button" tabindex="0" class="ns nt fj nu bh nv"><div class="nj nk qw"><picture><source srcset="hello_files/1_5XIK0ex5X0alf0S04hVSQA_002.webp 640w, hello_files/1_5XIK0ex5X0alf0S04hVSQA_006.webp 720w, hello_files/1_5XIK0ex5X0alf0S04hVSQA_005.webp 750w, hello_files/1_5XIK0ex5X0alf0S04hVSQA.webp 786w, hello_files/1_5XIK0ex5X0alf0S04hVSQA_004.webp 828w, hello_files/1_5XIK0ex5X0alf0S04hVSQA_007.webp 1100w, hello_files/1_5XIK0ex5X0alf0S04hVSQA_003.webp 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" type="image/webp"><source data-testid="og" srcset="hello_files/1_5XIK0ex5X0alf0S04hVSQA_002.png 640w, hello_files/1_5XIK0ex5X0alf0S04hVSQA_007.png 720w, hello_files/1_5XIK0ex5X0alf0S04hVSQA_004.png 750w, hello_files/1_5XIK0ex5X0alf0S04hVSQA_003.png 786w, hello_files/1_5XIK0ex5X0alf0S04hVSQA.png 828w, hello_files/1_5XIK0ex5X0alf0S04hVSQA_008.png 1100w, hello_files/1_5XIK0ex5X0alf0S04hVSQA_005.png 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px"><img alt="" class="bh mq nw c" width="700" height="67" loading="lazy" role="presentation" src="hello_files/1_5XIK0ex5X0alf0S04hVSQA_006.png"></picture></div></div><figcaption class="nx ff ny nj nk nz oa bf b bg z du" data-selectable-paragraph="">Equation 7 from <a class="af qh" href="https://arxiv.org/pdf/2305.18290.pdf" rel="noopener ugc nofollow" target="_blank">the paper</a></figcaption></figure><p id="cb9d" class="pw-post-body-paragraph ob oc gu od b hs oe of og hv oh oi oj ok ol om on oo op oq or os ot ou ov ow gn bk" data-selectable-paragraph="">That
 was a lot of algebra, but equation 7 is the most important one to 
understand, so I’ll break down the most important pieces. We now have an
 equation which will compare the policy probabilities of the old policy 
(π <em class="ox">ref</em>) and the new policy (π θ) for a winning completion (y<em class="ox">w</em>) and a losing completion (y<em class="ox">l</em>). When we compare these, we are optimizing so that that y<em class="ox">w</em> is bigger, as this would mean that the policies are getting better at giving winning responses than losing responses.</p><h1 id="3b9f" class="pg ph gu bf pi pj qi hu pl pm qj hx po pp qk pr ps pt ql pv pw px qm pz qa qb bk" data-selectable-paragraph="">Consequences</h1><p id="f055" class="pw-post-body-paragraph ob oc gu od b hs qc of og hv qd oi oj ok qe om on oo qf oq or os qg ou ov ow gn bk" data-selectable-paragraph="">First,
 DPO does not require a reward model! You simply need high quality data 
so that the model has a clear direction of what is good and bad, and it 
will improve.</p><p id="c894" class="pw-post-body-paragraph ob oc gu od b hs oe of og hv oh oi oj ok ol om on oo op oq or os ot ou ov ow gn bk" data-selectable-paragraph="">Second,
 DPO is dynamic. Every time you use new data, it is going to adapt 
immediately thanks to the way it figures out the right direction to go. 
Compared to PPO, where you have to retrain your reward model each time 
you have new data, this is a big win.</p><p id="7120" class="pw-post-body-paragraph ob oc gu od b hs oe of og hv oh oi oj ok ol om on oo op oq or os ot ou ov ow gn bk" data-selectable-paragraph="">Third,
 DPO allows you to train a model to avoid certain topics just as much as
 it will learn to give good answers for others. One way to conceptualize
 the new loss equation is as a signal that points our training in the 
right direction. By using both a good and bad example, we are teaching 
the model to avoid certain responses as much as we tell them to go 
towards others. As a large part of fine-tuning involves the model 
ignoring certain subjects, this feature is very valuable.</p><h1 id="958b" class="pg ph gu bf pi pj qi hu pl pm qj hx po pp qk pr ps pt ql pv pw px qm pz qa qb bk" data-selectable-paragraph="">Closing Thoughts</h1><figure class="nm nn no np nq nr nj nk paragraph-image"><div role="button" tabindex="0" class="ns nt fj nu bh nv"><div class="nj nk qx"><picture><source srcset="hello_files/1_esscG9r1ErfEgThyDE8JHQ_006.webp 640w, hello_files/1_esscG9r1ErfEgThyDE8JHQ_003.webp 720w, hello_files/1_esscG9r1ErfEgThyDE8JHQ.webp 750w, hello_files/1_esscG9r1ErfEgThyDE8JHQ_002.webp 786w, hello_files/1_esscG9r1ErfEgThyDE8JHQ_004.webp 828w, hello_files/1_esscG9r1ErfEgThyDE8JHQ_007.webp 1100w, hello_files/1_esscG9r1ErfEgThyDE8JHQ_005.webp 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" type="image/webp"><source data-testid="og" srcset="hello_files/1_esscG9r1ErfEgThyDE8JHQ_004.png 640w, hello_files/1_esscG9r1ErfEgThyDE8JHQ_007.png 720w, hello_files/1_esscG9r1ErfEgThyDE8JHQ.png 750w, hello_files/1_esscG9r1ErfEgThyDE8JHQ_008.png 786w, hello_files/1_esscG9r1ErfEgThyDE8JHQ_002.png 828w, hello_files/1_esscG9r1ErfEgThyDE8JHQ_005.png 1100w, hello_files/1_esscG9r1ErfEgThyDE8JHQ_003.png 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px"><img alt="" class="bh mq nw c" width="700" height="342" loading="lazy" role="presentation" src="hello_files/1_esscG9r1ErfEgThyDE8JHQ_006.png"></picture></div></div><figcaption class="nx ff ny nj nk nz oa bf b bg z du" data-selectable-paragraph="">Figure 2 from <a class="af qh" href="https://arxiv.org/pdf/2305.18290.pdf" rel="noopener ugc nofollow" target="_blank">the paper</a> showing comparative performance between DPO, PPO, and other methodologies</figcaption></figure><p id="8f5f" class="pw-post-body-paragraph ob oc gu od b hs oe of og hv oh oi oj ok ol om on oo op oq or os ot ou ov ow gn bk" data-selectable-paragraph="">Understanding the consequences of DPO’s math make me more optimistic about the future of LLMs.</p><p id="4ce1" class="pw-post-body-paragraph ob oc gu od b hs oe of og hv oh oi oj ok ol om on oo op oq or os ot ou ov ow gn bk" data-selectable-paragraph="">DPO
 requires less data and compute than PPO, both of which are major 
contributors to the cost of making your own model. With this cost 
reduction, more people will be able to fine-tune their own models, 
potentially giving society access to more specialized LLMs.</p><p id="f4fb" class="pw-post-body-paragraph ob oc gu od b hs oe of og hv oh oi oj ok ol om on oo op oq or os ot ou ov ow gn bk" data-selectable-paragraph="">Moreover,
 as DPO explicitly requires good and bad examples, while PPO only asks 
for good ones, it is much better at restricting behavior. This means 
that LLMs can be made far safer, another piece that will allow them to 
help out society.</p><p id="3046" class="pw-post-body-paragraph ob oc gu od b hs oe of og hv oh oi oj ok ol om on oo op oq or os ot ou ov ow gn bk" data-selectable-paragraph="">With
 forces like DPO giving us access to better quality LLMs that can be 
more easily trained, it is an incredibly exciting time for this field.</p><p id="efa4" class="pw-post-body-paragraph ob oc gu od b hs oe of og hv oh oi oj ok ol om on oo op oq or os ot ou ov ow gn bk" data-selectable-paragraph="">[1] R. Rafailov, et al., <a class="af qh" href="https://arxiv.org/pdf/2305.18290.pdf" rel="noopener ugc nofollow" target="_blank">Direct Preference Optimization: Your Language Model is Secretly a Reward Mode</a> (2023), arXiv</p><p id="5c8f" class="pw-post-body-paragraph ob oc gu od b hs oe of og hv oh oi oj ok ol om on oo op oq or os ot ou ov ow gn bk" data-selectable-paragraph="">[2] A. Jiang, et al., <a class="af qh" href="https://arxiv.org/pdf/2401.04088.pdf" rel="noopener ugc nofollow" target="_blank">Mixtral of Experts (2024)</a>, ArXiv</p></div></div></div></div></section></div></div></article></div><div class="ab cb"><div class="ci bh fz ga gb gc"><div class="qy qz ab jm"><div class="ra ab"><a class="rb ay am ao" href="https://medium.com/tag/fine-tuning?source=post_page-----a4bbd2d85841---------------fine_tuning-----------------" rel="noopener follow"><div class="rc fj cx rd ge re rf bf b bg z bk rg">Fine Tuning</div></a></div><div class="ra ab"><a class="rb ay am ao" href="https://medium.com/tag/llm?source=post_page-----a4bbd2d85841---------------llm-----------------" rel="noopener follow"><div class="rc fj cx rd ge re rf bf b bg z bk rg">Llm</div></a></div><div class="ra ab"><a class="rb ay am ao" href="https://medium.com/tag/mixtral-8x7b?source=post_page-----a4bbd2d85841---------------mixtral_8x7b-----------------" rel="noopener follow"><div class="rc fj cx rd ge re rf bf b bg z bk rg">Mixtral 8x7b</div></a></div><div class="ra ab"><a class="rb ay am ao" href="https://medium.com/tag/ai?source=post_page-----a4bbd2d85841---------------ai-----------------" rel="noopener follow"><div class="rc fj cx rd ge re rf bf b bg z bk rg">AI</div></a></div><div class="ra ab"><a class="rb ay am ao" href="https://medium.com/tag/machine-learning?source=post_page-----a4bbd2d85841---------------machine_learning-----------------" rel="noopener follow"><div class="rc fj cx rd ge re rf bf b bg z bk rg">Machine Learning</div></a></div></div></div></div><div class="l"></div><footer class="rh ri rj rk rl rm rn ro rp ab q rq iw c"><div class="l ae"><div class="ab cb"><div class="ci bh fz ga gb gc"><div class="ab cp rr"><div class="ab q lh"><div class="rs l"><span class="l rt ru rv e d"><div class="ab q lh li"><div class="pw-multi-vote-icon fj jq lj lk ll"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" data-testid="footerClapButton" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fa4bbd2d85841&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-the-implications-of-direct-preference-optimization-a4bbd2d85841&amp;user=Matthew+Gunton&amp;userId=e6581bb71f6&amp;source=-----a4bbd2d85841---------------------clap_footer-----------" rel="noopener follow"><div><div class="bm" aria-hidden="false" aria-describedby="10" aria-labelledby="10"><div class="lm ao ln lo lp lq am lr ls lt ll"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM13.916 3.953l1.523-2.112-1.184-.39zM8.589 1.84l1.522 2.112-.337-2.501zM18.523 18.92c-.86.86-1.75 1.246-2.62 1.33a6 6 0 0 0 .407-.372c2.388-2.389 2.86-4.951 1.399-7.623l-.912-1.603-.79-1.672c-.26-.56-.194-.98.203-1.288a.7.7 0 0 1 .546-.132c.283.046.546.231.728.5l2.363 4.157c.976 1.624 1.141 4.237-1.324 6.702m-10.999-.438L3.37 14.328a.828.828 0 0 1 .585-1.408.83.83 0 0 1 .585.242l2.158 2.157a.365.365 0 0 0 .516-.516l-2.157-2.158-1.449-1.449a.826.826 0 0 1 1.167-1.17l3.438 3.44a.363.363 0 0 0 .516 0 .364.364 0 0 0 0-.516L5.293 9.513l-.97-.97a.826.826 0 0 1 0-1.166.84.84 0 0 1 1.167 0l.97.968 3.437 3.436a.36.36 0 0 0 .517 0 .366.366 0 0 0 0-.516L6.977 7.83a.82.82 0 0 1-.241-.584.82.82 0 0 1 .824-.826c.219 0 .43.087.584.242l5.787 5.787a.366.366 0 0 0 .587-.415l-1.117-2.363c-.26-.56-.194-.98.204-1.289a.7.7 0 0 1 .546-.132c.283.046.545.232.727.501l2.193 3.86c1.302 2.38.883 4.59-1.277 6.75-1.156 1.156-2.602 1.627-4.19 1.367-1.418-.236-2.866-1.033-4.079-2.246M10.75 5.971l2.12 2.12c-.41.502-.465 1.17-.128 1.89l.22.465-3.523-3.523a.8.8 0 0 1-.097-.368c0-.22.086-.428.241-.584a.847.847 0 0 1 1.167 0m7.355 1.705c-.31-.461-.746-.758-1.23-.837a1.44 1.44 0 0 0-1.11.275c-.312.24-.505.543-.59.881a1.74 1.74 0 0 0-.906-.465 1.47 1.47 0 0 0-.82.106l-2.182-2.182a1.56 1.56 0 0 0-2.2 0 1.54 1.54 0 0 0-.396.701 1.56 1.56 0 0 0-2.21-.01 1.55 1.55 0 0 0-.416.753c-.624-.624-1.649-.624-2.237-.037a1.557 1.557 0 0 0 0 2.2c-.239.1-.501.238-.715.453a1.56 1.56 0 0 0 0 2.2l.516.515a1.556 1.556 0 0 0-.753 2.615L7.01 19c1.32 1.319 2.909 2.189 4.475 2.449q.482.08.971.08c.85 0 1.653-.198 2.393-.579.231.033.46.054.686.054 1.266 0 2.457-.52 3.505-1.567 2.763-2.763 2.552-5.734 1.439-7.586z" clip-rule="evenodd"></path></svg></div></div></div></a></span></div><div class="pw-multi-vote-count l lu lv lw lx ly lz ma"><div><div class="bm" aria-hidden="false" aria-describedby="102" aria-labelledby="102"><p class="bf b dv z du"><button class="af ag ah ai aj ak al am an ao ap aq ar as at uj mj">283<span class="l h g f rw rx"></span></button></p></div></div></div></div></span><span class="l h g f rw rx"><div class="ab q lh li"><div class="pw-multi-vote-icon fj jq lj lk ll"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" data-testid="footerClapButton" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fa4bbd2d85841&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-the-implications-of-direct-preference-optimization-a4bbd2d85841&amp;user=Matthew+Gunton&amp;userId=e6581bb71f6&amp;source=-----a4bbd2d85841---------------------clap_footer-----------" rel="noopener follow"><div><div class="bm" aria-hidden="false" aria-describedby="11" aria-labelledby="11"><div class="lm ao ln lo lp lq am lr ls lt ll"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM13.916 3.953l1.523-2.112-1.184-.39zM8.589 1.84l1.522 2.112-.337-2.501zM18.523 18.92c-.86.86-1.75 1.246-2.62 1.33a6 6 0 0 0 .407-.372c2.388-2.389 2.86-4.951 1.399-7.623l-.912-1.603-.79-1.672c-.26-.56-.194-.98.203-1.288a.7.7 0 0 1 .546-.132c.283.046.546.231.728.5l2.363 4.157c.976 1.624 1.141 4.237-1.324 6.702m-10.999-.438L3.37 14.328a.828.828 0 0 1 .585-1.408.83.83 0 0 1 .585.242l2.158 2.157a.365.365 0 0 0 .516-.516l-2.157-2.158-1.449-1.449a.826.826 0 0 1 1.167-1.17l3.438 3.44a.363.363 0 0 0 .516 0 .364.364 0 0 0 0-.516L5.293 9.513l-.97-.97a.826.826 0 0 1 0-1.166.84.84 0 0 1 1.167 0l.97.968 3.437 3.436a.36.36 0 0 0 .517 0 .366.366 0 0 0 0-.516L6.977 7.83a.82.82 0 0 1-.241-.584.82.82 0 0 1 .824-.826c.219 0 .43.087.584.242l5.787 5.787a.366.366 0 0 0 .587-.415l-1.117-2.363c-.26-.56-.194-.98.204-1.289a.7.7 0 0 1 .546-.132c.283.046.545.232.727.501l2.193 3.86c1.302 2.38.883 4.59-1.277 6.75-1.156 1.156-2.602 1.627-4.19 1.367-1.418-.236-2.866-1.033-4.079-2.246M10.75 5.971l2.12 2.12c-.41.502-.465 1.17-.128 1.89l.22.465-3.523-3.523a.8.8 0 0 1-.097-.368c0-.22.086-.428.241-.584a.847.847 0 0 1 1.167 0m7.355 1.705c-.31-.461-.746-.758-1.23-.837a1.44 1.44 0 0 0-1.11.275c-.312.24-.505.543-.59.881a1.74 1.74 0 0 0-.906-.465 1.47 1.47 0 0 0-.82.106l-2.182-2.182a1.56 1.56 0 0 0-2.2 0 1.54 1.54 0 0 0-.396.701 1.56 1.56 0 0 0-2.21-.01 1.55 1.55 0 0 0-.416.753c-.624-.624-1.649-.624-2.237-.037a1.557 1.557 0 0 0 0 2.2c-.239.1-.501.238-.715.453a1.56 1.56 0 0 0 0 2.2l.516.515a1.556 1.556 0 0 0-.753 2.615L7.01 19c1.32 1.319 2.909 2.189 4.475 2.449q.482.08.971.08c.85 0 1.653-.198 2.393-.579.231.033.46.054.686.054 1.266 0 2.457-.52 3.505-1.567 2.763-2.763 2.552-5.734 1.439-7.586z" clip-rule="evenodd"></path></svg></div></div></div></a></span></div><div class="pw-multi-vote-count l lu lv lw lx ly lz ma"><div><div class="bm" aria-hidden="false" aria-describedby="104" aria-labelledby="104"><p class="bf b dv z du"><button class="af ag ah ai aj ak al am an ao ap aq ar as at uj mj">283</button></p></div></div></div></div></span></div><div class="bq ab"><div><div class="bm" aria-hidden="false" aria-describedby="12" aria-labelledby="12"><button class="ao lm me mf ab q fk mg mh" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" class="md"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"></path></svg><p class="bf b bg z du"><span class="pw-responses-count mc md">5</span></p></button></div></div></div></div><div class="ab q"><div class="pf l jj"><div><div class="bm" aria-hidden="false" aria-describedby="13" aria-labelledby="13"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" data-testid="footerBookmarkButton" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa4bbd2d85841&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-the-implications-of-direct-preference-optimization-a4bbd2d85841&amp;source=--------------------------bookmark_footer-----------" rel="noopener follow"><svg xmlns="http://www.w3.org/2000/svg" width="25" height="25" fill="none" viewBox="0 0 25 25" class="du mj" aria-label="Add to list bookmark button"><path fill="currentColor" d="M18 2.5a.5.5 0 0 1 1 0V5h2.5a.5.5 0 0 1 0 1H19v2.5a.5.5 0 1 1-1 0V6h-2.5a.5.5 0 0 1 0-1H18zM7 7a1 1 0 0 1 1-1h3.5a.5.5 0 0 0 0-1H8a2 2 0 0 0-2 2v14a.5.5 0 0 0 .805.396L12.5 17l5.695 4.396A.5.5 0 0 0 19 21v-8.5a.5.5 0 0 0-1 0v7.485l-5.195-4.012a.5.5 0 0 0-.61 0L7 19.985z"></path></svg></a></span></div></div></div><div class="pf l jj"><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false" aria-describedby="14" aria-labelledby="14"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="footerSocialShareButton" class="af fk ah ai aj ak al mr an ao ap ex ms mt mh mu"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"></path></svg></button></div></div></div></div></div></div></div></div></div></footer><div class="ry rz sa sb sc l bx"><div class="ab cb"><div class="ci bh fz ga gb gc"><div class="cl ab sd cp"><div class="ab im"><a href="https://medium.com/@mgunton7?source=post_page-----a4bbd2d85841--------------------------------" rel="noopener follow"><div class="l se sf by sg iq"><div class="l fj"><img alt="Matthew Gunton" class="l fd by sh si cx" src="hello_files/1_F8sHS2ai6w95qbGIZ9qM_g_002.png" width="72" height="72" loading="lazy"><div class="ir by l sh si fs n is ft"></div></div></div></a><a href="https://towardsdatascience.com/?source=post_page-----a4bbd2d85841--------------------------------" rel="noopener follow"><div class="sj ab fj"><div><div class="bm" aria-hidden="false" aria-describedby="15" aria-labelledby="15"><div class="l sk sl by sg iw"><div class="l fj"><img alt="Towards Data Science" class="l fd by bz ca cx" src="hello_files/1_CJe3891yB1A1mzMdqemkdg_002.jpg" width="32" height="32" loading="lazy"><div class="ir by l bz ca fs n is ft"></div></div></div></div></div></div></a></div><div class="j i d"><div class="ab"><span><a class="bf b bg z ep rc eq er es et eu ev ew ex ey ez fa au fb fc fd bm fe ff" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fe6581bb71f6&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-the-implications-of-direct-preference-optimization-a4bbd2d85841&amp;user=Matthew+Gunton&amp;userId=e6581bb71f6&amp;source=post_page-e6581bb71f6----a4bbd2d85841---------------------follow_profile-----------" rel="noopener follow">Follow</a></span><div class="dt l"><div><div><div class="bm" aria-hidden="false" aria-describedby="130" aria-labelledby="130"><div class="l"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F6176bdb04479&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-the-implications-of-direct-preference-optimization-a4bbd2d85841&amp;newsletterV3=e6581bb71f6&amp;newsletterV3Id=6176bdb04479&amp;user=Matthew+Gunton&amp;userId=e6581bb71f6&amp;source=-----a4bbd2d85841---------------------subscribe_user-----------" rel="noopener follow"><button class="bf b bg z ep am eq er es et eu ev ew ex ey ez fa fb fc fd bm fe ff" aria-label="Subscribe"><svg xmlns="http://www.w3.org/2000/svg" width="38" height="38" fill="none" viewBox="0 0 38 38" class="un sl sk"><rect width="0.5" height="6.5" x="26.25" y="9.25" rx="0.25"></rect><rect width="0.5" height="6.5" x="29.75" y="12.25" rx="0.25" transform="rotate(90 29.75 12.25)"></rect><path d="M19.5 12.5h-7a1 1 0 0 0-1 1v11a1 1 0 0 0 1 1h13a1 1 0 0 0 1-1v-5"></path><path d="M11.5 14.5 19 20l4-3"></path></svg></button></a></span></div></div></div></div></div></div></div></div><div class="ab cn cp"><div class="l"><div class="ab q"><a class="af ag ah ai aj ak al am an ao ap aq ar as at ab q" href="https://medium.com/@mgunton7?source=post_page-----a4bbd2d85841--------------------------------" rel="noopener follow"><h2 class="pw-author-name bf sw sx sy sz bk"><span class="gn ka">Written by <!-- -->Matthew Gunton</span></h2></a></div><div class="ra ab"><div class="l jj"><span class="pw-follower-count bf b bg z bk"><a class="af ag ah ai aj ak al am an ao ap aq ar jc" href="https://medium.com/@mgunton7/followers?source=post_page-----a4bbd2d85841--------------------------------" rel="noopener follow">338 Followers</a></span></div><div class="bf b bg z jr js jt ab jv jw jx jy du jp"><span class="jd l" aria-hidden="true"><span class="bf b bg z du">·</span></span><span class="l jj">Writer for </span><div><div class="l" aria-hidden="false" aria-describedby="17" aria-labelledby="17"><a class="af ag ah ai aj ak al am an ao ap aq ar jc ab q" href="https://towardsdatascience.com/?source=post_page-----a4bbd2d85841--------------------------------" rel="noopener follow"><p class="bf b bg z jr js jt ju jv jw jx jy bk">Towards Data Science</p></a></div></div></div></div><div class="ta l"><p class="bf b bg z bk"><span class="gn">Hi, my name is Matthew Gunton. I like talking about the latest ways technology can be used to improve the world</span></p></div></div><div class="h k"><div class="ab"><span><a class="bf b bg z ep rc eq er es et eu ev ew ex ey ez fa au fb fc fd bm fe ff" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fe6581bb71f6&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-the-implications-of-direct-preference-optimization-a4bbd2d85841&amp;user=Matthew+Gunton&amp;userId=e6581bb71f6&amp;source=post_page-e6581bb71f6----a4bbd2d85841---------------------follow_profile-----------" rel="noopener follow">Follow</a></span><div class="dt l"><div><div><div class="bm" aria-hidden="false" aria-describedby="132" aria-labelledby="132"><div class="l"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F6176bdb04479&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-the-implications-of-direct-preference-optimization-a4bbd2d85841&amp;newsletterV3=e6581bb71f6&amp;newsletterV3Id=6176bdb04479&amp;user=Matthew+Gunton&amp;userId=e6581bb71f6&amp;source=-----a4bbd2d85841---------------------subscribe_user-----------" rel="noopener follow"><button class="bf b bg z ep am eq er es et eu ev ew ex ey ez fa fb fc fd bm fe ff" aria-label="Subscribe"><svg xmlns="http://www.w3.org/2000/svg" width="38" height="38" fill="none" viewBox="0 0 38 38" class="un sl sk"><rect width="0.5" height="6.5" x="26.25" y="9.25" rx="0.25"></rect><rect width="0.5" height="6.5" x="29.75" y="12.25" rx="0.25" transform="rotate(90 29.75 12.25)"></rect><path d="M19.5 12.5h-7a1 1 0 0 0-1 1v11a1 1 0 0 0 1 1h13a1 1 0 0 0 1-1v-5"></path><path d="M11.5 14.5 19 20l4-3"></path></svg></button></a></span></div></div></div></div></div></div></div></div><div class="tb bh tc td te tf tg th"></div></div></div><div class="ab cb"><div class="ci bh fz ga gb gc"><div class="up uq l"><h2 class="bf sw ja z gt bk">More from Matthew Gunton and Towards Data Science</h2></div><div class="ur ab lh jm us ut uu uv uw ux uy uz va vb vc vd ve vf vg"><div class="vh vi vj vk vl vm vn vo vp vq vr vs vt vu vv vw vx vy vz wa wb"><div class="wc wd we wf wg dw l"><article class="dw"><div class="dw rp l"><div class="bh dw"><div class="dw l"><div class="fj dw wh wi wj wk wl wm wn wo wp wq wr ws wt" role="link" data-href="https://towardsdatascience.com/diving-deep-into-autogen-and-agentic-frameworks-3e161fa3c086" tabindex="0"><div class="wu"><div aria-label="Diving Deep into AutoGen and Agentic Frameworks"><div class="ww wx wy wz xa"><img alt="Diving Deep into AutoGen and Agentic Frameworks" class="bh xb xc xd xe bx" src="hello_files/1_UPH5xLXulgoCRNCKURR7cw.png" loading="lazy"></div></div></div><div class="wv ab cb co"><div class="ab co xf bh xg xh xi xj"><div class="xk xl xm xn xo ab q"><div class="rb l"><div><div class="l" aria-hidden="false" aria-describedby="133" aria-labelledby="133"><a tabindex="-1" href="https://medium.com/@mgunton7?source=author_recirc-----a4bbd2d85841----0---------------------cf007650_fe00_46bc_903e_ce2cd5a60089-------" rel="noopener follow"><div class="l fj"><img alt="Matthew Gunton" class="l fd by xp xq cx" src="hello_files/1_F8sHS2ai6w95qbGIZ9qM_g.png" width="20" height="20" loading="lazy"><div class="fr by l xp xq fs n ay ft"></div></div></a></div></div></div><div class="xr l"><div><div class="l" aria-hidden="false" aria-describedby="134" aria-labelledby="134"><a class="af ag ah ai aj ak al am an ao ap aq ar jc ab q" href="https://medium.com/@mgunton7?source=author_recirc-----a4bbd2d85841----0---------------------cf007650_fe00_46bc_903e_ce2cd5a60089-------" rel="noopener follow"><p class="bf b dv z jr js jt ju jv jw jx jy bk">Matthew Gunton</p></a></div></div></div><div class="xr l"><p class="bf b dv z du">in</p></div><div class="l"><div><div class="l" aria-hidden="false" aria-describedby="135" aria-labelledby="135"><a class="af ag ah ai aj ak al am an ao ap aq ar jc ab q" href="https://towardsdatascience.com/?source=author_recirc-----a4bbd2d85841----0---------------------cf007650_fe00_46bc_903e_ce2cd5a60089-------" rel="noopener follow"><p class="bf b dv z jr js jt ju jv jw jx jy bk">Towards Data Science</p></a></div></div></div></div><div class="xs l xt xu xv xw xx gn"><div class="xy xz ya yb yc yd ye yf"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" rel="noopener follow" href="https://towardsdatascience.com/diving-deep-into-autogen-and-agentic-frameworks-3e161fa3c086?source=author_recirc-----a4bbd2d85841----0---------------------cf007650_fe00_46bc_903e_ce2cd5a60089-------"><div title=""><h2 class="bf gv pj hu yg yh pl pm hx yi yj po ok yk yl ym yn oo yo yp yq yr os ys yt yu yv jr jt ju jw jy bk">Diving Deep into AutoGen and Agentic Frameworks</h2></div><div class="yw l"><h3 class="bf b ja z jr yx jt ju yy jw jy du">This blog post will go into the details of the “AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation” paper</h3></div></a></div></div><span class="bf b dv z du"><div class="io ab cp ae"><div class="ab q"><span>Jun 28</span><div class=""><div class="fj yz dh ab q"><div class="fs tr za ab q"><div class="ax dh dj l cx"></div></div><a class="fs me za ab q" tabindex="-1" rel="noopener follow" href="https://towardsdatascience.com/diving-deep-into-autogen-and-agentic-frameworks-3e161fa3c086?source=author_recirc-----a4bbd2d85841----0---------------------cf007650_fe00_46bc_903e_ce2cd5a60089-------"><div class="ax l"><div><div class="ab" aria-hidden="false" aria-describedby="206" aria-labelledby="206"><div class="ab q fj"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="none" viewBox="0 0 16 16"><path fill="#6B6B6B" fill-rule="evenodd" d="m3.672 10.167 2.138 2.14h-.002c1.726 1.722 4.337 2.436 5.96.81 1.472-1.45 1.806-3.68.76-5.388l-1.815-3.484c-.353-.524-.849-1.22-1.337-.958-.49.261 0 1.56 0 1.56l.78 1.932L6.43 2.866c-.837-.958-1.467-1.108-1.928-.647-.33.33-.266.856.477 1.598.501.503 1.888 1.957 1.888 1.957.17.174.083.485-.093.655a.56.56 0 0 1-.34.163.43.43 0 0 1-.317-.135s-2.4-2.469-2.803-2.87c-.344-.346-.803-.54-1.194-.15-.408.406-.273 1.065.11 1.447.345.346 2.31 2.297 2.685 2.67l.062.06c.17.175.269.628.093.8-.193.188-.453.33-.678.273a.9.9 0 0 1-.446-.273S2.501 6.84 1.892 6.23c-.407-.406-.899-.333-1.229 0-.525.524.263 1.28 1.73 2.691.384.368.814.781 1.279 1.246m8.472-7.219c.372-.29.95-.28 1.303.244V3.19l1.563 3.006.036.074c.885 1.87.346 4.093-.512 5.159l-.035.044c-.211.264-.344.43-.74.61 1.382-1.855.963-3.478-.248-5.456L11.943 3.88l-.002-.037c-.017-.3-.039-.71.203-.895" clip-rule="evenodd"></path></svg><span style="margin-left: 4px;">241</span></div></div></div></div></a></div></div></div><div class="ab q zb zc"><div class=""><div><div class="bm" aria-hidden="false" aria-describedby="136" aria-labelledby="136"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F3e161fa3c086&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdiving-deep-into-autogen-and-agentic-frameworks-3e161fa3c086&amp;source=-----a4bbd2d85841----0-----------------bookmark_preview----cf007650_fe00_46bc_903e_ce2cd5a60089-------" rel="noopener follow"><svg xmlns="http://www.w3.org/2000/svg" width="25" height="25" fill="none" viewBox="0 0 25 25" class="du mj zd" aria-label="Add to list bookmark button"><path fill="currentColor" d="M18 2.5a.5.5 0 0 1 1 0V5h2.5a.5.5 0 0 1 0 1H19v2.5a.5.5 0 1 1-1 0V6h-2.5a.5.5 0 0 1 0-1H18zM7 7a1 1 0 0 1 1-1h3.5a.5.5 0 0 0 0-1H8a2 2 0 0 0-2 2v14a.5.5 0 0 0 .805.396L12.5 17l5.695 4.396A.5.5 0 0 0 19 21v-8.5a.5.5 0 0 0-1 0v7.485l-5.195-4.012a.5.5 0 0 0-.61 0L7 19.985z"></path></svg></a></span></div></div></div></div></div></span><div class="j i d"><div class="tb bh tc md"></div></div></div></div></div></div></div></div></article></div></div><div class="vh vi vj vk vl vm vn vo vp vq vr vs vt vu vv vw vx vy vz wa wb"><div class="wc wd we wf wg dw l"><article class="dw"><div class="dw rp l"><div class="bh dw"><div class="dw l"><div class="fj dw wh wi wj wk wl wm wn wo wp wq wr ws wt" role="link" data-href="https://towardsdatascience.com/17-advanced-rag-techniques-to-turn-your-rag-app-prototype-into-a-production-ready-solution-5a048e36cdc8" tabindex="0"><div class="wu"><div aria-label="17 (Advanced) RAG Techniques to Turn Your LLM App Prototype into a Production-Ready Solution"><div class="ww wx wy wz xa"><img alt="17 (Advanced) RAG Techniques to Turn Your LLM App Prototype into a Production-Ready Solution" class="bh xb xc xd xe bx" src="hello_files/1_DaXfsffAhnAzQMHH7nZ4ng.png" loading="lazy"></div></div></div><div class="wv ab cb co"><div class="ab co xf bh xg xh xi xj"><div class="xk xl xm xn xo ab q"><div class="rb l"><div><div class="l" aria-hidden="false" aria-describedby="137" aria-labelledby="137"><a tabindex="-1" href="https://dmnkplzr.medium.com/?source=author_recirc-----a4bbd2d85841----1---------------------cf007650_fe00_46bc_903e_ce2cd5a60089-------" rel="noopener follow"><div class="l fj"><img alt="Dominik Polzer" class="l fd by xp xq cx" src="hello_files/1_KqpicOFO7jh7FXGjoJ2Bcg.jpg" width="20" height="20" loading="lazy"><div class="fr by l xp xq fs n ay ft"></div></div></a></div></div></div><div class="xr l"><div><div class="l" aria-hidden="false" aria-describedby="138" aria-labelledby="138"><a class="af ag ah ai aj ak al am an ao ap aq ar jc ab q" href="https://dmnkplzr.medium.com/?source=author_recirc-----a4bbd2d85841----1---------------------cf007650_fe00_46bc_903e_ce2cd5a60089-------" rel="noopener follow"><p class="bf b dv z jr js jt ju jv jw jx jy bk">Dominik Polzer</p></a></div></div></div><div class="xr l"><p class="bf b dv z du">in</p></div><div class="l"><div><div class="l" aria-hidden="false" aria-describedby="139" aria-labelledby="139"><a class="af ag ah ai aj ak al am an ao ap aq ar jc ab q" href="https://towardsdatascience.com/?source=author_recirc-----a4bbd2d85841----1---------------------cf007650_fe00_46bc_903e_ce2cd5a60089-------" rel="noopener follow"><p class="bf b dv z jr js jt ju jv jw jx jy bk">Towards Data Science</p></a></div></div></div></div><div class="xs l xt xu xv xw xx gn"><div class="xy xz ya yb yc yd ye yf"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" rel="noopener follow" href="https://towardsdatascience.com/17-advanced-rag-techniques-to-turn-your-rag-app-prototype-into-a-production-ready-solution-5a048e36cdc8?source=author_recirc-----a4bbd2d85841----1---------------------cf007650_fe00_46bc_903e_ce2cd5a60089-------"><div title="17 (Advanced) RAG Techniques to Turn Your LLM App Prototype into a Production-Ready Solution"><h2 class="bf gv pj hu yg yh pl pm hx yi yj po ok yk yl ym yn oo yo yp yq yr os ys yt yu yv jr jt ju jw jy bk">17 (Advanced) RAG Techniques to Turn Your LLM App Prototype into a Production-Ready Solution</h2></div><div class="yw l"><h3 class="bf b ja z jr yx jt ju yy jw jy du">A collection of RAG techniques to help you develop your RAG app into something robust that will last</h3></div></a></div></div><span class="bf b dv z du"><div class="io ab cp ae"><div class="ab q"><div class="ze rp ab"><div class="bm" aria-hidden="false" aria-describedby="140" aria-labelledby="140"><button class="l ay ao am" aria-label="Member-only story"><div class=""><div><div class="bm" aria-hidden="false" aria-describedby="141" aria-labelledby="141"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="none" viewBox="0 0 64 64"><path fill="#FFC017" d="m39.637 40.831-5.771 15.871a1.99 1.99 0 0 1-3.732 0l-5.771-15.87a2.02 2.02 0 0 0-1.194-1.195L7.298 33.866a1.99 1.99 0 0 1 0-3.732l15.87-5.771a2.02 2.02 0 0 0 1.195-1.194l5.771-15.871a1.99 1.99 0 0 1 3.732 0l5.771 15.87a2.02 2.02 0 0 0 1.194 1.195l15.871 5.771a1.99 1.99 0 0 1 0 3.732l-15.87 5.771a2.02 2.02 0 0 0-1.195 1.194"></path></svg></div></div></div></button></div></div><span>Jun 26</span><div class=""><div class="fj yz dh ab q"><div class="fs tr za ab q"><div class="ax dh dj l cx"></div></div><a class="fs me za ab q" tabindex="-1" rel="noopener follow" href="https://towardsdatascience.com/17-advanced-rag-techniques-to-turn-your-rag-app-prototype-into-a-production-ready-solution-5a048e36cdc8?source=author_recirc-----a4bbd2d85841----1---------------------cf007650_fe00_46bc_903e_ce2cd5a60089-------"><div class="ax l"><div><div class="ab" aria-hidden="false" aria-describedby="207" aria-labelledby="207"><div class="ab q fj"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="none" viewBox="0 0 16 16"><path fill="#6B6B6B" fill-rule="evenodd" d="m3.672 10.167 2.138 2.14h-.002c1.726 1.722 4.337 2.436 5.96.81 1.472-1.45 1.806-3.68.76-5.388l-1.815-3.484c-.353-.524-.849-1.22-1.337-.958-.49.261 0 1.56 0 1.56l.78 1.932L6.43 2.866c-.837-.958-1.467-1.108-1.928-.647-.33.33-.266.856.477 1.598.501.503 1.888 1.957 1.888 1.957.17.174.083.485-.093.655a.56.56 0 0 1-.34.163.43.43 0 0 1-.317-.135s-2.4-2.469-2.803-2.87c-.344-.346-.803-.54-1.194-.15-.408.406-.273 1.065.11 1.447.345.346 2.31 2.297 2.685 2.67l.062.06c.17.175.269.628.093.8-.193.188-.453.33-.678.273a.9.9 0 0 1-.446-.273S2.501 6.84 1.892 6.23c-.407-.406-.899-.333-1.229 0-.525.524.263 1.28 1.73 2.691.384.368.814.781 1.279 1.246m8.472-7.219c.372-.29.95-.28 1.303.244V3.19l1.563 3.006.036.074c.885 1.87.346 4.093-.512 5.159l-.035.044c-.211.264-.344.43-.74.61 1.382-1.855.963-3.478-.248-5.456L11.943 3.88l-.002-.037c-.017-.3-.039-.71.203-.895" clip-rule="evenodd"></path></svg><span style="margin-left: 4px;">2.4K</span></div></div></div></div><div class="ax l"><div><div class="ab" aria-hidden="false" aria-describedby="142" aria-labelledby="142"><div class="ab q fj"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="#6B6B6B" viewBox="0 0 16 16"><path fill="#6B6B6B" d="M12.344 11.458A5.28 5.28 0 0 0 14 7.526C14 4.483 11.391 2 8.051 2S2 4.483 2 7.527c0 3.051 2.712 5.526 6.059 5.526a6.6 6.6 0 0 0 1.758-.236q.255.223.554.414c.784.51 1.626.768 2.512.768a.37.37 0 0 0 .355-.214.37.37 0 0 0-.03-.384 4.7 4.7 0 0 1-.857-1.958v.014z"></path></svg><span style="margin-left: 4px;">22</span></div></div></div></div></a></div></div></div><div class="ab q zb zc"><div class=""><div><div class="bm" aria-hidden="false" aria-describedby="143" aria-labelledby="143"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F5a048e36cdc8&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2F17-advanced-rag-techniques-to-turn-your-rag-app-prototype-into-a-production-ready-solution-5a048e36cdc8&amp;source=-----a4bbd2d85841----1-----------------bookmark_preview----cf007650_fe00_46bc_903e_ce2cd5a60089-------" rel="noopener follow"><svg xmlns="http://www.w3.org/2000/svg" width="25" height="25" fill="none" viewBox="0 0 25 25" class="du mj zd" aria-label="Add to list bookmark button"><path fill="currentColor" d="M18 2.5a.5.5 0 0 1 1 0V5h2.5a.5.5 0 0 1 0 1H19v2.5a.5.5 0 1 1-1 0V6h-2.5a.5.5 0 0 1 0-1H18zM7 7a1 1 0 0 1 1-1h3.5a.5.5 0 0 0 0-1H8a2 2 0 0 0-2 2v14a.5.5 0 0 0 .805.396L12.5 17l5.695 4.396A.5.5 0 0 0 19 21v-8.5a.5.5 0 0 0-1 0v7.485l-5.195-4.012a.5.5 0 0 0-.61 0L7 19.985z"></path></svg></a></span></div></div></div></div></div></span><div class="j i d"><div class="tb bh tc md"></div></div></div></div></div></div></div></div></article></div></div><div class="vh vi vj vk vl vm vn vo vp vq vr vs vt vu vv vw vx vy vz wa wb"><div class="wc wd we wf wg dw l"><article class="dw"><div class="dw rp l"><div class="bh dw"><div class="dw l"><div class="fj dw wh wi wj wk wl wm wn wo wp wq wr ws wt" role="link" data-href="https://towardsdatascience.com/document-parsing-using-large-language-models-with-code-9229fda09cdf" tabindex="0"><div class="wu"><div aria-label="Document Parsing Using Large Language Models — With Code"><div class="ww wx wy wz xa"><img alt="Document Parsing Using Large Language Models — With Code" class="bh xb xc xd xe bx" src="hello_files/1_ZZR9KMsYHkZdbdoXe-e3bQ.png" loading="lazy"></div></div></div><div class="wv ab cb co"><div class="ab co xf bh xg xh xi xj"><div class="xk xl xm xn xo ab q"><div class="rb l"><div><div class="l" aria-hidden="false" aria-describedby="144" aria-labelledby="144"><a tabindex="-1" href="https://zoumanakeita.medium.com/?source=author_recirc-----a4bbd2d85841----2---------------------cf007650_fe00_46bc_903e_ce2cd5a60089-------" rel="noopener follow"><div class="l fj"><img alt="Zoumana Keita" class="l fd by xp xq cx" src="hello_files/1_Se9SLHlvVxMoYooDaI91uA.png" width="20" height="20" loading="lazy"><div class="fr by l xp xq fs n ay ft"></div></div></a></div></div></div><div class="xr l"><div><div class="l" aria-hidden="false" aria-describedby="145" aria-labelledby="145"><a class="af ag ah ai aj ak al am an ao ap aq ar jc ab q" href="https://zoumanakeita.medium.com/?source=author_recirc-----a4bbd2d85841----2---------------------cf007650_fe00_46bc_903e_ce2cd5a60089-------" rel="noopener follow"><p class="bf b dv z jr js jt ju jv jw jx jy bk">Zoumana Keita</p></a></div></div></div><div class="xr l"><p class="bf b dv z du">in</p></div><div class="l"><div><div class="l" aria-hidden="false" aria-describedby="146" aria-labelledby="146"><a class="af ag ah ai aj ak al am an ao ap aq ar jc ab q" href="https://towardsdatascience.com/?source=author_recirc-----a4bbd2d85841----2---------------------cf007650_fe00_46bc_903e_ce2cd5a60089-------" rel="noopener follow"><p class="bf b dv z jr js jt ju jv jw jx jy bk">Towards Data Science</p></a></div></div></div></div><div class="xs l xt xu xv xw xx gn"><div class="xy xz ya yb yc yd ye yf"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" rel="noopener follow" href="https://towardsdatascience.com/document-parsing-using-large-language-models-with-code-9229fda09cdf?source=author_recirc-----a4bbd2d85841----2---------------------cf007650_fe00_46bc_903e_ce2cd5a60089-------"><div title=""><h2 class="bf gv pj hu yg yh pl pm hx yi yj po ok yk yl ym yn oo yo yp yq yr os ys yt yu yv jr jt ju jw jy bk">Document Parsing Using Large Language Models — With Code</h2></div><div class="yw l"><h3 class="bf b ja z jr yx jt ju yy jw jy du">You will not think about using Regular Expressions anymore.</h3></div></a></div></div><span class="bf b dv z du"><div class="io ab cp ae"><div class="ab q"><div class="ze rp ab"><div class="bm" aria-hidden="false" aria-describedby="147" aria-labelledby="147"><button class="l ay ao am" aria-label="Member-only story"><div class=""><div><div class="bm" aria-hidden="false" aria-describedby="148" aria-labelledby="148"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="none" viewBox="0 0 64 64"><path fill="#FFC017" d="m39.637 40.831-5.771 15.871a1.99 1.99 0 0 1-3.732 0l-5.771-15.87a2.02 2.02 0 0 0-1.194-1.195L7.298 33.866a1.99 1.99 0 0 1 0-3.732l15.87-5.771a2.02 2.02 0 0 0 1.195-1.194l5.771-15.871a1.99 1.99 0 0 1 3.732 0l5.771 15.87a2.02 2.02 0 0 0 1.194 1.195l15.871 5.771a1.99 1.99 0 0 1 0 3.732l-15.87 5.771a2.02 2.02 0 0 0-1.195 1.194"></path></svg></div></div></div></button></div></div><span>Jul 25</span><div class=""><div class="fj yz dh ab q"><div class="fs tr za ab q"><div class="ax dh dj l cx"></div></div><a class="fs me za ab q" tabindex="-1" rel="noopener follow" href="https://towardsdatascience.com/document-parsing-using-large-language-models-with-code-9229fda09cdf?source=author_recirc-----a4bbd2d85841----2---------------------cf007650_fe00_46bc_903e_ce2cd5a60089-------"><div class="ax l"><div><div class="ab" aria-hidden="false" aria-describedby="209" aria-labelledby="209"><div class="ab q fj"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="none" viewBox="0 0 16 16"><path fill="#6B6B6B" fill-rule="evenodd" d="m3.672 10.167 2.138 2.14h-.002c1.726 1.722 4.337 2.436 5.96.81 1.472-1.45 1.806-3.68.76-5.388l-1.815-3.484c-.353-.524-.849-1.22-1.337-.958-.49.261 0 1.56 0 1.56l.78 1.932L6.43 2.866c-.837-.958-1.467-1.108-1.928-.647-.33.33-.266.856.477 1.598.501.503 1.888 1.957 1.888 1.957.17.174.083.485-.093.655a.56.56 0 0 1-.34.163.43.43 0 0 1-.317-.135s-2.4-2.469-2.803-2.87c-.344-.346-.803-.54-1.194-.15-.408.406-.273 1.065.11 1.447.345.346 2.31 2.297 2.685 2.67l.062.06c.17.175.269.628.093.8-.193.188-.453.33-.678.273a.9.9 0 0 1-.446-.273S2.501 6.84 1.892 6.23c-.407-.406-.899-.333-1.229 0-.525.524.263 1.28 1.73 2.691.384.368.814.781 1.279 1.246m8.472-7.219c.372-.29.95-.28 1.303.244V3.19l1.563 3.006.036.074c.885 1.87.346 4.093-.512 5.159l-.035.044c-.211.264-.344.43-.74.61 1.382-1.855.963-3.478-.248-5.456L11.943 3.88l-.002-.037c-.017-.3-.039-.71.203-.895" clip-rule="evenodd"></path></svg><span style="margin-left: 4px;">744</span></div></div></div></div><div class="ax l"><div><div class="ab" aria-hidden="false" aria-describedby="149" aria-labelledby="149"><div class="ab q fj"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="#6B6B6B" viewBox="0 0 16 16"><path fill="#6B6B6B" d="M12.344 11.458A5.28 5.28 0 0 0 14 7.526C14 4.483 11.391 2 8.051 2S2 4.483 2 7.527c0 3.051 2.712 5.526 6.059 5.526a6.6 6.6 0 0 0 1.758-.236q.255.223.554.414c.784.51 1.626.768 2.512.768a.37.37 0 0 0 .355-.214.37.37 0 0 0-.03-.384 4.7 4.7 0 0 1-.857-1.958v.014z"></path></svg><span style="margin-left: 4px;">5</span></div></div></div></div></a></div></div></div><div class="ab q zb zc"><div class=""><div><div class="bm" aria-hidden="false" aria-describedby="150" aria-labelledby="150"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F9229fda09cdf&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdocument-parsing-using-large-language-models-with-code-9229fda09cdf&amp;source=-----a4bbd2d85841----2-----------------bookmark_preview----cf007650_fe00_46bc_903e_ce2cd5a60089-------" rel="noopener follow"><svg xmlns="http://www.w3.org/2000/svg" width="25" height="25" fill="none" viewBox="0 0 25 25" class="du mj zd" aria-label="Add to list bookmark button"><path fill="currentColor" d="M18 2.5a.5.5 0 0 1 1 0V5h2.5a.5.5 0 0 1 0 1H19v2.5a.5.5 0 1 1-1 0V6h-2.5a.5.5 0 0 1 0-1H18zM7 7a1 1 0 0 1 1-1h3.5a.5.5 0 0 0 0-1H8a2 2 0 0 0-2 2v14a.5.5 0 0 0 .805.396L12.5 17l5.695 4.396A.5.5 0 0 0 19 21v-8.5a.5.5 0 0 0-1 0v7.485l-5.195-4.012a.5.5 0 0 0-.61 0L7 19.985z"></path></svg></a></span></div></div></div></div></div></span><div class="j i d"><div class="tb bh tc md"></div></div></div></div></div></div></div></div></article></div></div><div class="vh vi vj vk vl vm vn vo vp vq vr vs vt vu vv vw vx vy vz wa wb"><div class="wc wd we wf wg dw l"><article class="dw"><div class="dw rp l"><div class="bh dw"><div class="dw l"><div class="fj dw wh wi wj wk wl wm wn wo wp wq wr ws wt" role="link" data-href="https://towardsdatascience.com/line-by-line-lets-reproduce-gpt-2-section-1-b26684f98492" tabindex="0"><div class="wu"><div aria-label="Line By Line, Let’s Reproduce GPT-2: Section 1"><div class="ww wx wy wz xa"><img alt="Line By Line, Let’s Reproduce GPT-2: Section 1" class="bh xb xc xd xe bx" src="hello_files/1_rSIqu7ZQVFjHFL66tQgCjA.png" loading="lazy"></div></div></div><div class="wv ab cb co"><div class="ab co xf bh xg xh xi xj"><div class="xk xl xm xn xo ab q"><div class="rb l"><div><div class="l" aria-hidden="false" aria-describedby="151" aria-labelledby="151"><a tabindex="-1" href="https://medium.com/@mgunton7?source=author_recirc-----a4bbd2d85841----3---------------------cf007650_fe00_46bc_903e_ce2cd5a60089-------" rel="noopener follow"><div class="l fj"><img alt="Matthew Gunton" class="l fd by xp xq cx" src="hello_files/1_F8sHS2ai6w95qbGIZ9qM_g.png" width="20" height="20" loading="lazy"><div class="fr by l xp xq fs n ay ft"></div></div></a></div></div></div><div class="xr l"><div><div class="l" aria-hidden="false" aria-describedby="152" aria-labelledby="152"><a class="af ag ah ai aj ak al am an ao ap aq ar jc ab q" href="https://medium.com/@mgunton7?source=author_recirc-----a4bbd2d85841----3---------------------cf007650_fe00_46bc_903e_ce2cd5a60089-------" rel="noopener follow"><p class="bf b dv z jr js jt ju jv jw jx jy bk">Matthew Gunton</p></a></div></div></div><div class="xr l"><p class="bf b dv z du">in</p></div><div class="l"><div><div class="l" aria-hidden="false" aria-describedby="153" aria-labelledby="153"><a class="af ag ah ai aj ak al am an ao ap aq ar jc ab q" href="https://towardsdatascience.com/?source=author_recirc-----a4bbd2d85841----3---------------------cf007650_fe00_46bc_903e_ce2cd5a60089-------" rel="noopener follow"><p class="bf b dv z jr js jt ju jv jw jx jy bk">Towards Data Science</p></a></div></div></div></div><div class="xs l xt xu xv xw xx gn"><div class="xy xz ya yb yc yd ye yf"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" rel="noopener follow" href="https://towardsdatascience.com/line-by-line-lets-reproduce-gpt-2-section-1-b26684f98492?source=author_recirc-----a4bbd2d85841----3---------------------cf007650_fe00_46bc_903e_ce2cd5a60089-------"><div title=""><h2 class="bf gv pj hu yg yh pl pm hx yi yj po ok yk yl ym yn oo yo yp yq yr os ys yt yu yv jr jt ju jw jy bk">Line By Line, Let’s Reproduce GPT-2: Section 1</h2></div><div class="yw l"><h3 class="bf b ja z jr yx jt ju yy jw jy du">This blog post will go line-by-line through the code in Section 1 of Andrej Karpathy’s “Let’s reproduce GPT-2 (124M)”</h3></div></a></div></div><span class="bf b dv z du"><div class="io ab cp ae"><div class="ab q"><span>Jul 23</span><div class=""><div class="fj yz dh ab q"><div class="fs tr za ab q"><div class="ax dh dj l cx"></div></div><a class="fs me za ab q" tabindex="-1" rel="noopener follow" href="https://towardsdatascience.com/line-by-line-lets-reproduce-gpt-2-section-1-b26684f98492?source=author_recirc-----a4bbd2d85841----3---------------------cf007650_fe00_46bc_903e_ce2cd5a60089-------"><div class="ax l"><div><div class="ab" aria-hidden="false" aria-describedby="211" aria-labelledby="211"><div class="ab q fj"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="none" viewBox="0 0 16 16"><path fill="#6B6B6B" fill-rule="evenodd" d="m3.672 10.167 2.138 2.14h-.002c1.726 1.722 4.337 2.436 5.96.81 1.472-1.45 1.806-3.68.76-5.388l-1.815-3.484c-.353-.524-.849-1.22-1.337-.958-.49.261 0 1.56 0 1.56l.78 1.932L6.43 2.866c-.837-.958-1.467-1.108-1.928-.647-.33.33-.266.856.477 1.598.501.503 1.888 1.957 1.888 1.957.17.174.083.485-.093.655a.56.56 0 0 1-.34.163.43.43 0 0 1-.317-.135s-2.4-2.469-2.803-2.87c-.344-.346-.803-.54-1.194-.15-.408.406-.273 1.065.11 1.447.345.346 2.31 2.297 2.685 2.67l.062.06c.17.175.269.628.093.8-.193.188-.453.33-.678.273a.9.9 0 0 1-.446-.273S2.501 6.84 1.892 6.23c-.407-.406-.899-.333-1.229 0-.525.524.263 1.28 1.73 2.691.384.368.814.781 1.279 1.246m8.472-7.219c.372-.29.95-.28 1.303.244V3.19l1.563 3.006.036.074c.885 1.87.346 4.093-.512 5.159l-.035.044c-.211.264-.344.43-.74.61 1.382-1.855.963-3.478-.248-5.456L11.943 3.88l-.002-.037c-.017-.3-.039-.71.203-.895" clip-rule="evenodd"></path></svg><span style="margin-left: 4px;">121</span></div></div></div></div></a></div></div></div><div class="ab q zb zc"><div class=""><div><div class="bm" aria-hidden="false" aria-describedby="154" aria-labelledby="154"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fb26684f98492&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fline-by-line-lets-reproduce-gpt-2-section-1-b26684f98492&amp;source=-----a4bbd2d85841----3-----------------bookmark_preview----cf007650_fe00_46bc_903e_ce2cd5a60089-------" rel="noopener follow"><svg xmlns="http://www.w3.org/2000/svg" width="25" height="25" fill="none" viewBox="0 0 25 25" class="du mj zd" aria-label="Add to list bookmark button"><path fill="currentColor" d="M18 2.5a.5.5 0 0 1 1 0V5h2.5a.5.5 0 0 1 0 1H19v2.5a.5.5 0 1 1-1 0V6h-2.5a.5.5 0 0 1 0-1H18zM7 7a1 1 0 0 1 1-1h3.5a.5.5 0 0 0 0-1H8a2 2 0 0 0-2 2v14a.5.5 0 0 0 .805.396L12.5 17l5.695 4.396A.5.5 0 0 0 19 21v-8.5a.5.5 0 0 0-1 0v7.485l-5.195-4.012a.5.5 0 0 0-.61 0L7 19.985z"></path></svg></a></span></div></div></div></div></div></span></div></div></div></div></div></div></article></div></div></div><div class="tb bh tc dk dl zf zg zh"></div><div class="ab jk jl zi zj zk"><a class="bf b bg z bk rc zl zm zn mj mg zo ev ew ex zp zq zr fa zs zt zu zv zw fb fc fd bm fe ff" href="https://medium.com/@mgunton7?source=post_page-----a4bbd2d85841--------------------------------" rel="noopener follow"><div class="l ff">See all from Matthew Gunton</div></a><div class="zx zy zz aba abb abc abd abe abf ma l"><a class="bf b bg z bk rc zl zm zn mj mg zo ev ew ex zp zq zr fa zs zt zu zv zw fb fc fd bm fe ff" href="https://towardsdatascience.com/?source=post_page-----a4bbd2d85841--------------------------------" rel="noopener follow"><div class="l ff">See all from Towards Data Science</div></a></div></div></div></div><div class="tb bh tc abg abh abi abj abk"></div><div class="ab cb"><div class="ci bh fz ga gb gc"><div class="abl abm l"><h2 class="bf sw pj hu pl pm hx po pp pr ps pt pv pw px pz qa bk">Recommended from Medium</h2><div class="nm nn no np nq l"><div class="ur ab lh jm us ut uu uv uw ux uy uz va vb vc vd ve vf vg"><div class="vh vi vj vk vl vm vn vo vp vq vr vs vt vu vv vw vx vy vz wa wb"><div class="wc wd we wf wg dw l"><article class="dw"><div class="dw rp l"><div class="bh dw"><div class="dw l"><div class="fj dw wh wi wj wk wl wm wn wo wp wq wr ws wt" role="link" data-href="https://medium.com/@bavalpreetsinghh/rlhf-ppo-vs-dpo-26b1438cf22b" tabindex="0"><div class="wu"><div aria-label="RLHF(PPO) vs DPO"><div class="ww wx wy wz xa"><img alt="RLHF(PPO) vs DPO" class="bh xb xc xd xe bx" src="hello_files/1_yH5LMT75KG1LFd1P11IfxA.png" loading="lazy"></div></div></div><div class="wv ab cb co"><div class="ab co xf bh xg xh xi xj"><div class="xk xl xm xn xo ab q"><div class="rb l"><div><div class="l" aria-hidden="false" aria-describedby="155" aria-labelledby="155"><a tabindex="-1" href="https://medium.com/@bavalpreetsinghh?source=read_next_recirc-----a4bbd2d85841----0---------------------4533891d_492e_419c_9f18_f15a7b08be12-------" rel="noopener follow"><div class="l fj"><img alt="BavalpreetSinghh" class="l fd by xp xq cx" src="hello_files/2_g1IaDJK2TrKljHYvbp9C0w.jpg" width="20" height="20" loading="lazy"><div class="fr by l xp xq fs n ay ft"></div></div></a></div></div></div><div class="xr l"><div><div class="l" aria-hidden="false" aria-describedby="156" aria-labelledby="156"><a class="af ag ah ai aj ak al am an ao ap aq ar jc ab q" href="https://medium.com/@bavalpreetsinghh?source=read_next_recirc-----a4bbd2d85841----0---------------------4533891d_492e_419c_9f18_f15a7b08be12-------" rel="noopener follow"><p class="bf b dv z jr js jt ju jv jw jx jy bk">BavalpreetSinghh</p></a></div></div></div></div><div class="xs l xt xu xv xw xx gn"><div class="xy xz ya yb yc yd ye yf"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/@bavalpreetsinghh/rlhf-ppo-vs-dpo-26b1438cf22b?source=read_next_recirc-----a4bbd2d85841----0---------------------4533891d_492e_419c_9f18_f15a7b08be12-------" rel="noopener follow"><div title=""><h2 class="bf gv pj hu yg yh pl pm hx yi yj po ok yk yl ym yn oo yo yp yq yr os ys yt yu yv jr jt ju jw jy bk">RLHF(PPO) vs DPO</h2></div><div class="yw l"><h3 class="bf b ja z jr yx jt ju yy jw jy du">Although
 large-scale unsupervisly trained language models (LLMs) gain broad 
world knowledge and some reasoning abilities, precisely…</h3></div></a></div></div><span class="bf b dv z du"><div class="io ab cp ae"><div class="ab q"><span>Jun 8</span><div class=""><div class="fj yz dh ab q"><div class="fs tr za ab q"><div class="ax dh dj l cx"></div></div><a class="fs me za ab q" tabindex="-1" href="https://medium.com/@bavalpreetsinghh/rlhf-ppo-vs-dpo-26b1438cf22b?source=read_next_recirc-----a4bbd2d85841----0---------------------4533891d_492e_419c_9f18_f15a7b08be12-------" rel="noopener follow"><div class="ax l"><div><div class="ab" aria-hidden="false" aria-describedby="212" aria-labelledby="212"><div class="ab q fj"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="none" viewBox="0 0 16 16"><path fill="#6B6B6B" fill-rule="evenodd" d="m3.672 10.167 2.138 2.14h-.002c1.726 1.722 4.337 2.436 5.96.81 1.472-1.45 1.806-3.68.76-5.388l-1.815-3.484c-.353-.524-.849-1.22-1.337-.958-.49.261 0 1.56 0 1.56l.78 1.932L6.43 2.866c-.837-.958-1.467-1.108-1.928-.647-.33.33-.266.856.477 1.598.501.503 1.888 1.957 1.888 1.957.17.174.083.485-.093.655a.56.56 0 0 1-.34.163.43.43 0 0 1-.317-.135s-2.4-2.469-2.803-2.87c-.344-.346-.803-.54-1.194-.15-.408.406-.273 1.065.11 1.447.345.346 2.31 2.297 2.685 2.67l.062.06c.17.175.269.628.093.8-.193.188-.453.33-.678.273a.9.9 0 0 1-.446-.273S2.501 6.84 1.892 6.23c-.407-.406-.899-.333-1.229 0-.525.524.263 1.28 1.73 2.691.384.368.814.781 1.279 1.246m8.472-7.219c.372-.29.95-.28 1.303.244V3.19l1.563 3.006.036.074c.885 1.87.346 4.093-.512 5.159l-.035.044c-.211.264-.344.43-.74.61 1.382-1.855.963-3.478-.248-5.456L11.943 3.88l-.002-.037c-.017-.3-.039-.71.203-.895" clip-rule="evenodd"></path></svg><span style="margin-left: 4px;">96</span></div></div></div></div></a></div></div></div><div class="ab q zb zc"><div class=""><div><div class="bm" aria-hidden="false" aria-describedby="157" aria-labelledby="157"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F26b1438cf22b&amp;operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2F%40bavalpreetsinghh%2Frlhf-ppo-vs-dpo-26b1438cf22b&amp;source=-----a4bbd2d85841----0-----------------bookmark_preview----4533891d_492e_419c_9f18_f15a7b08be12-------" rel="noopener follow"><svg xmlns="http://www.w3.org/2000/svg" width="25" height="25" fill="none" viewBox="0 0 25 25" class="du mj zd" aria-label="Add to list bookmark button"><path fill="currentColor" d="M18 2.5a.5.5 0 0 1 1 0V5h2.5a.5.5 0 0 1 0 1H19v2.5a.5.5 0 1 1-1 0V6h-2.5a.5.5 0 0 1 0-1H18zM7 7a1 1 0 0 1 1-1h3.5a.5.5 0 0 0 0-1H8a2 2 0 0 0-2 2v14a.5.5 0 0 0 .805.396L12.5 17l5.695 4.396A.5.5 0 0 0 19 21v-8.5a.5.5 0 0 0-1 0v7.485l-5.195-4.012a.5.5 0 0 0-.61 0L7 19.985z"></path></svg></a></span></div></div></div></div></div></span><div class="j i d"><div class="tb bh tc md"></div></div></div></div></div></div></div></div></article></div></div><div class="vh vi vj vk vl vm vn vo vp vq vr vs vt vu vv vw vx vy vz wa wb"><div class="wc wd we wf wg dw l"><article class="dw"><div class="dw rp l"><div class="bh dw"><div class="dw l"><div class="fj dw wh wi wj wk wl wm wn wo wp wq wr ws wt" role="link" data-href="https://towardsdatascience.com/rlhf-reinforcement-learning-from-human-feedback-faa5ff4761d1" tabindex="0"><div class="wu"><div aria-label="RLHF: Reinforcement Learning from Human Feedback"><div class="ww wx wy wz xa"><img alt="RLHF: Reinforcement Learning from Human Feedback" class="bh xb xc xd xe bx" src="hello_files/1_U78S24NyShQ97Ur9AORHoQ.png" loading="lazy"></div></div></div><div class="wv ab cb co"><div class="ab co xf bh xg xh xi xj"><div class="xk xl xm xn xo ab q"><div class="rb l"><div><div class="l" aria-hidden="false" aria-describedby="158" aria-labelledby="158"><a tabindex="-1" href="https://automata88.medium.com/?source=read_next_recirc-----a4bbd2d85841----1---------------------4533891d_492e_419c_9f18_f15a7b08be12-------" rel="noopener follow"><div class="l fj"><img alt="Ms Aerin" class="l fd by xp xq cx" src="hello_files/2_XK92LT9AOyjhhUazl1Gejw.png" width="20" height="20" loading="lazy"><div class="fr by l xp xq fs n ay ft"></div></div></a></div></div></div><div class="xr l"><div><div class="l" aria-hidden="false" aria-describedby="159" aria-labelledby="159"><a class="af ag ah ai aj ak al am an ao ap aq ar jc ab q" href="https://automata88.medium.com/?source=read_next_recirc-----a4bbd2d85841----1---------------------4533891d_492e_419c_9f18_f15a7b08be12-------" rel="noopener follow"><p class="bf b dv z jr js jt ju jv jw jx jy bk">Ms Aerin</p></a></div></div></div><div class="xr l"><p class="bf b dv z du">in</p></div><div class="l"><div><div class="l" aria-hidden="false" aria-describedby="160" aria-labelledby="160"><a class="af ag ah ai aj ak al am an ao ap aq ar jc ab q" href="https://towardsdatascience.com/?source=read_next_recirc-----a4bbd2d85841----1---------------------4533891d_492e_419c_9f18_f15a7b08be12-------" rel="noopener follow"><p class="bf b dv z jr js jt ju jv jw jx jy bk">Towards Data Science</p></a></div></div></div></div><div class="xs l xt xu xv xw xx gn"><div class="xy xz ya yb yc yd ye yf"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" rel="noopener follow" href="https://towardsdatascience.com/rlhf-reinforcement-learning-from-human-feedback-faa5ff4761d1?source=read_next_recirc-----a4bbd2d85841----1---------------------4533891d_492e_419c_9f18_f15a7b08be12-------"><div title=""><h2 class="bf gv pj hu yg yh pl pm hx yi yj po ok yk yl ym yn oo yo yp yq yr os ys yt yu yv jr jt ju jw jy bk">RLHF: Reinforcement Learning from Human Feedback</h2></div><div class="yw l"><h3 class="bf b ja z jr yx jt ju yy jw jy du">ChatGPT’s success ingredient: The Instruction Data.</h3></div></a></div></div><span class="bf b dv z du"><div class="io ab cp ae"><div class="ab q"><div class="ze rp ab"><div class="bm" aria-hidden="false" aria-describedby="161" aria-labelledby="161"><button class="l ay ao am" aria-label="Member-only story"><div class=""><div><div class="bm" aria-hidden="false" aria-describedby="162" aria-labelledby="162"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="none" viewBox="0 0 64 64"><path fill="#FFC017" d="m39.637 40.831-5.771 15.871a1.99 1.99 0 0 1-3.732 0l-5.771-15.87a2.02 2.02 0 0 0-1.194-1.195L7.298 33.866a1.99 1.99 0 0 1 0-3.732l15.87-5.771a2.02 2.02 0 0 0 1.195-1.194l5.771-15.871a1.99 1.99 0 0 1 3.732 0l5.771 15.87a2.02 2.02 0 0 0 1.194 1.195l15.871 5.771a1.99 1.99 0 0 1 0 3.732l-15.87 5.771a2.02 2.02 0 0 0-1.195 1.194"></path></svg></div></div></div></button></div></div><span>Oct 11, 2023</span><div class=""><div class="fj yz dh ab q"><div class="fs tr za ab q"><div class="ax dh dj l cx"></div></div><a class="fs me za ab q" tabindex="-1" rel="noopener follow" href="https://towardsdatascience.com/rlhf-reinforcement-learning-from-human-feedback-faa5ff4761d1?source=read_next_recirc-----a4bbd2d85841----1---------------------4533891d_492e_419c_9f18_f15a7b08be12-------"><div class="ax l"><div><div class="ab" aria-hidden="false" aria-describedby="213" aria-labelledby="213"><div class="ab q fj"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="none" viewBox="0 0 16 16"><path fill="#6B6B6B" fill-rule="evenodd" d="m3.672 10.167 2.138 2.14h-.002c1.726 1.722 4.337 2.436 5.96.81 1.472-1.45 1.806-3.68.76-5.388l-1.815-3.484c-.353-.524-.849-1.22-1.337-.958-.49.261 0 1.56 0 1.56l.78 1.932L6.43 2.866c-.837-.958-1.467-1.108-1.928-.647-.33.33-.266.856.477 1.598.501.503 1.888 1.957 1.888 1.957.17.174.083.485-.093.655a.56.56 0 0 1-.34.163.43.43 0 0 1-.317-.135s-2.4-2.469-2.803-2.87c-.344-.346-.803-.54-1.194-.15-.408.406-.273 1.065.11 1.447.345.346 2.31 2.297 2.685 2.67l.062.06c.17.175.269.628.093.8-.193.188-.453.33-.678.273a.9.9 0 0 1-.446-.273S2.501 6.84 1.892 6.23c-.407-.406-.899-.333-1.229 0-.525.524.263 1.28 1.73 2.691.384.368.814.781 1.279 1.246m8.472-7.219c.372-.29.95-.28 1.303.244V3.19l1.563 3.006.036.074c.885 1.87.346 4.093-.512 5.159l-.035.044c-.211.264-.344.43-.74.61 1.382-1.855.963-3.478-.248-5.456L11.943 3.88l-.002-.037c-.017-.3-.039-.71.203-.895" clip-rule="evenodd"></path></svg><span style="margin-left: 4px;">730</span></div></div></div></div><div class="ax l"><div><div class="ab" aria-hidden="false" aria-describedby="163" aria-labelledby="163"><div class="ab q fj"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="#6B6B6B" viewBox="0 0 16 16"><path fill="#6B6B6B" d="M12.344 11.458A5.28 5.28 0 0 0 14 7.526C14 4.483 11.391 2 8.051 2S2 4.483 2 7.527c0 3.051 2.712 5.526 6.059 5.526a6.6 6.6 0 0 0 1.758-.236q.255.223.554.414c.784.51 1.626.768 2.512.768a.37.37 0 0 0 .355-.214.37.37 0 0 0-.03-.384 4.7 4.7 0 0 1-.857-1.958v.014z"></path></svg><span style="margin-left: 4px;">10</span></div></div></div></div></a></div></div></div><div class="ab q zb zc"><div class=""><div><div class="bm" aria-hidden="false" aria-describedby="164" aria-labelledby="164"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ffaa5ff4761d1&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Frlhf-reinforcement-learning-from-human-feedback-faa5ff4761d1&amp;source=-----a4bbd2d85841----1-----------------bookmark_preview----4533891d_492e_419c_9f18_f15a7b08be12-------" rel="noopener follow"><svg xmlns="http://www.w3.org/2000/svg" width="25" height="25" fill="none" viewBox="0 0 25 25" class="du mj zd" aria-label="Add to list bookmark button"><path fill="currentColor" d="M18 2.5a.5.5 0 0 1 1 0V5h2.5a.5.5 0 0 1 0 1H19v2.5a.5.5 0 1 1-1 0V6h-2.5a.5.5 0 0 1 0-1H18zM7 7a1 1 0 0 1 1-1h3.5a.5.5 0 0 0 0-1H8a2 2 0 0 0-2 2v14a.5.5 0 0 0 .805.396L12.5 17l5.695 4.396A.5.5 0 0 0 19 21v-8.5a.5.5 0 0 0-1 0v7.485l-5.195-4.012a.5.5 0 0 0-.61 0L7 19.985z"></path></svg></a></span></div></div></div></div></div></span></div></div></div></div></div></div></article></div></div></div></div><div class="tb bh tc abn"></div><h2 class="bf sw ja z gt bk">Lists</h2><div class="oy l"><div class="cn ab lh jm us ut uu uv uw ux uy uz va vb vc vd ve vf vg"><div class="vh vi vj vk vl vm vn vo vp vq vr vs vt vu vv vw vx vy vz wa wb"><a class="af ag ah ai aj ak al am an ao ap aq ar as at ab cl cn" href="https://medium.com/@AMGAS14/list/natural-language-processing-0a856388a93a?source=read_next_recirc-----a4bbd2d85841--------------------------------" rel="noopener follow"><div class="abt abu jr ab jj fj"><div class="fj xb abp bx abq"><div class="xb io jr l"><img alt="Title image of “Towards Mamba State Space Models for Images, Videos and Time Series” by Sascha Kirch" class="" src="hello_files/1_IGhsnp6ALHeBjFMVnOJ36Q.png" width="48" height="48" loading="lazy"></div></div><div class="fj xb abp bx li abr"><div class="xb io jr l"><img alt="" class="" src="hello_files/0_F2pCtf9vMWmdro1c.jpg" width="48" height="48" loading="lazy" role="presentation"></div></div><div class="fj xb bx iw abs"><div class="xb io jr l"><img alt="" class="" src="hello_files/1_hfurC-8quUf3NPuArjchmQ.png" width="48" height="48" loading="lazy" role="presentation"></div></div></div><div class="ax l"><h2 class="bf sw ja z jr yx jt ju yy jw jy gt bk">Natural Language Processing</h2><div class="bf b dv z du ab abo">1649 stories<span class="jd l" aria-hidden="true"><span class="bf b bg z du">·</span></span>1222 saves</div></div></a></div><div class="vh vi vj vk vl vm vn vo vp vq vr vs vt vu vv vw vx vy vz wa wb"><a class="af ag ah ai aj ak al am an ao ap aq ar as at ab cl cn" href="https://medium.com/@ben.putney/list/predictive-modeling-w-python-e3668ea008e1?source=read_next_recirc-----a4bbd2d85841--------------------------------" rel="noopener follow"><div class="abt abu jr ab jj fj"><div class="fj xb abp bx abq"><div class="xb io jr l"><img alt="" class="" src="hello_files/0_r4yjMpEmqzHCUvWC.jpg" width="48" height="48" loading="lazy" role="presentation"></div></div><div class="fj xb abp bx li abr"><div class="xb io jr l"><img alt="" class="" src="hello_files/1_bv2KUVNLi2sFNjBTdoBmWw.png" width="48" height="48" loading="lazy" role="presentation"></div></div><div class="fj xb bx iw abs"><div class="xb io jr l"><img alt="" class="" src="hello_files/0_zsngbTOmFCy6sUCx.jpg" width="48" height="48" loading="lazy" role="presentation"></div></div></div><div class="ax l"><h2 class="bf sw ja z jr yx jt ju yy jw jy gt bk">Predictive Modeling w/ Python</h2><div class="bf b dv z du ab abo">20 stories<span class="jd l" aria-hidden="true"><span class="bf b bg z du">·</span></span>1452 saves</div></div></a></div><div class="vh vi vj vk vl vm vn vo vp vq vr vs vt vu vv vw vx vy vz wa wb"><a class="af ag ah ai aj ak al am an ao ap aq ar as at ab cl cn" href="https://medium.com/@MediumStaff/list/the-new-chatbots-chatgpt-bard-and-beyond-5969c7449b7f?source=read_next_recirc-----a4bbd2d85841--------------------------------" rel="noopener follow"><div class="abt abu jr ab jj fj"><div class="fj xb abp bx abq"><div class="xb io jr l"><img alt="Image by vectorjuice on FreePik" class="" src="hello_files/0_3OsUtsnlTx9Svm4c.jpg" width="48" height="48" loading="lazy"></div></div><div class="fj xb abp bx li abr"><div class="xb io jr l"><img alt="" class="" src="hello_files/1_IPZF1hcDWwpPqOz2vL7NxQ.png" width="48" height="48" loading="lazy" role="presentation"></div></div><div class="fj xb bx iw abs"><div class="xb io jr l"><img alt="" class="" src="hello_files/1_0fHUKyg3xtpNWpop35PR4g.png" width="48" height="48" loading="lazy" role="presentation"></div></div></div><div class="ax l"><h2 class="bf sw ja z jr yx jt ju yy jw jy gt bk">The New Chatbots: ChatGPT, Bard, and Beyond</h2><div class="bf b dv z du ab abo">12 stories<span class="jd l" aria-hidden="true"><span class="bf b bg z du">·</span></span>442 saves</div></div></a></div><div class="vh vi vj vk vl vm vn vo vp vq vr vs vt vu vv vw vx vy vz wa wb"><a class="af ag ah ai aj ak al am an ao ap aq ar as at ab cl cn" href="https://destingong.medium.com/list/practical-guides-to-machine-learning-a877c2a39884?source=read_next_recirc-----a4bbd2d85841--------------------------------" rel="noopener follow"><div class="abt abu jr ab jj fj"><div class="fj xb abp bx abq"><div class="xb io jr l"><img alt="Principal Component Analysis for ML" class="" src="hello_files/1_swd_PY6vTCyPnsgBYoFZfA.png" width="48" height="48" loading="lazy"></div></div><div class="fj xb abp bx li abr"><div class="xb io jr l"><img alt="Time Series Analysis" class="" src="hello_files/1_8sSAHftNwd_RNJ3k4VA0pA.png" width="48" height="48" loading="lazy"></div></div><div class="fj xb bx iw abs"><div class="xb io jr l"><img alt="deep learning cheatsheet for beginner" class="" src="hello_files/1_uNyD4yNMH-DnOel1wzxOOA.png" width="48" height="48" loading="lazy"></div></div></div><div class="ax l"><h2 class="bf sw ja z jr yx jt ju yy jw jy gt bk">Practical Guides to Machine Learning</h2><div class="bf b dv z du ab abo">10 stories<span class="jd l" aria-hidden="true"><span class="bf b bg z du">·</span></span>1766 saves</div></div></a></div></div></div><div class="tb bh tc zy dk aba dl abv abw abx aby abz aca"></div><div class="ur ab lh jm us ut uu uv uw ux uy uz va vb vc vd ve vf vg"><div class="vh vi vj vk vl vm vn vo vp vq vr vs vt vu vv vw vx vy vz wa wb"><div class="wc wd we wf wg dw l"><article class="dw"><div class="dw rp l"><div class="bh dw"><div class="dw l"><div class="fj dw wh wi wj wk wl wm wn wo wp wq wr ws wt" role="link" data-href="https://medium.com/@danushidk507/ppo-algorithm-3b33195de14a" tabindex="0"><div class="wu"><div aria-label="PPO Algorithm"><div class="ww wx wy wz xa"><img alt="PPO Algorithm" class="bh xb xc xd xe bx" src="hello_files/0_6AKHU5297QgZr3Mz.png" loading="lazy"></div></div></div><div class="wv ab cb co"><div class="ab co xf bh xg xh xi xj"><div class="xk xl xm xn xo ab q"><div class="rb l"><div><div class="l" aria-hidden="false" aria-describedby="165" aria-labelledby="165"><a tabindex="-1" href="https://medium.com/@danushidk507?source=read_next_recirc-----a4bbd2d85841----0---------------------4533891d_492e_419c_9f18_f15a7b08be12-------" rel="noopener follow"><div class="l fj"><img alt="DhanushKumar" class="l fd by xp xq cx" src="hello_files/1_nV_t7yjnnON8MBQAh4VeeQ.jpg" width="20" height="20" loading="lazy"><div class="fr by l xp xq fs n ay ft"></div></div></a></div></div></div><div class="xr l"><div><div class="l" aria-hidden="false" aria-describedby="166" aria-labelledby="166"><a class="af ag ah ai aj ak al am an ao ap aq ar jc ab q" href="https://medium.com/@danushidk507?source=read_next_recirc-----a4bbd2d85841----0---------------------4533891d_492e_419c_9f18_f15a7b08be12-------" rel="noopener follow"><p class="bf b dv z jr js jt ju jv jw jx jy bk">DhanushKumar</p></a></div></div></div></div><div class="xs l xt xu xv xw xx gn"><div class="xy xz ya yb yc yd ye yf"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/@danushidk507/ppo-algorithm-3b33195de14a?source=read_next_recirc-----a4bbd2d85841----0---------------------4533891d_492e_419c_9f18_f15a7b08be12-------" rel="noopener follow"><div title=""><h2 class="bf gv pj hu yg yh pl pm hx yi yj po ok yk yl ym yn oo yo yp yq yr os ys yt yu yv jr jt ju jw jy bk">PPO Algorithm</h2></div><div class="yw l"><h3 class="bf b ja z jr yx jt ju yy jw jy du">Proximal
 Policy Optimization (PPO) is an algorithm in the field of reinforcement
 learning that trains a computer agent’s decision function…</h3></div></a></div></div><span class="bf b dv z du"><div class="io ab cp ae"><div class="ab q"><span>Feb 21</span><div class=""><div class="fj yz dh ab q"><div class="fs tr za ab q"><div class="ax dh dj l cx"></div></div><a class="fs me za ab q" tabindex="-1" href="https://medium.com/@danushidk507/ppo-algorithm-3b33195de14a?source=read_next_recirc-----a4bbd2d85841----0---------------------4533891d_492e_419c_9f18_f15a7b08be12-------" rel="noopener follow"><div class="ax l"><div><div class="ab" aria-hidden="false" aria-describedby="215" aria-labelledby="215"><div class="ab q fj"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="none" viewBox="0 0 16 16"><path fill="#6B6B6B" fill-rule="evenodd" d="m3.672 10.167 2.138 2.14h-.002c1.726 1.722 4.337 2.436 5.96.81 1.472-1.45 1.806-3.68.76-5.388l-1.815-3.484c-.353-.524-.849-1.22-1.337-.958-.49.261 0 1.56 0 1.56l.78 1.932L6.43 2.866c-.837-.958-1.467-1.108-1.928-.647-.33.33-.266.856.477 1.598.501.503 1.888 1.957 1.888 1.957.17.174.083.485-.093.655a.56.56 0 0 1-.34.163.43.43 0 0 1-.317-.135s-2.4-2.469-2.803-2.87c-.344-.346-.803-.54-1.194-.15-.408.406-.273 1.065.11 1.447.345.346 2.31 2.297 2.685 2.67l.062.06c.17.175.269.628.093.8-.193.188-.453.33-.678.273a.9.9 0 0 1-.446-.273S2.501 6.84 1.892 6.23c-.407-.406-.899-.333-1.229 0-.525.524.263 1.28 1.73 2.691.384.368.814.781 1.279 1.246m8.472-7.219c.372-.29.95-.28 1.303.244V3.19l1.563 3.006.036.074c.885 1.87.346 4.093-.512 5.159l-.035.044c-.211.264-.344.43-.74.61 1.382-1.855.963-3.478-.248-5.456L11.943 3.88l-.002-.037c-.017-.3-.039-.71.203-.895" clip-rule="evenodd"></path></svg><span style="margin-left: 4px;">185</span></div></div></div></div><div class="ax l"><div><div class="ab" aria-hidden="false" aria-describedby="167" aria-labelledby="167"><div class="ab q fj"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="#6B6B6B" viewBox="0 0 16 16"><path fill="#6B6B6B" d="M12.344 11.458A5.28 5.28 0 0 0 14 7.526C14 4.483 11.391 2 8.051 2S2 4.483 2 7.527c0 3.051 2.712 5.526 6.059 5.526a6.6 6.6 0 0 0 1.758-.236q.255.223.554.414c.784.51 1.626.768 2.512.768a.37.37 0 0 0 .355-.214.37.37 0 0 0-.03-.384 4.7 4.7 0 0 1-.857-1.958v.014z"></path></svg><span style="margin-left: 4px;">1</span></div></div></div></div></a></div></div></div><div class="ab q zb zc"><div class=""><div><div class="bm" aria-hidden="false" aria-describedby="168" aria-labelledby="168"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F3b33195de14a&amp;operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2F%40danushidk507%2Fppo-algorithm-3b33195de14a&amp;source=-----a4bbd2d85841----0-----------------bookmark_preview----4533891d_492e_419c_9f18_f15a7b08be12-------" rel="noopener follow"><svg xmlns="http://www.w3.org/2000/svg" width="25" height="25" fill="none" viewBox="0 0 25 25" class="du mj zd" aria-label="Add to list bookmark button"><path fill="currentColor" d="M18 2.5a.5.5 0 0 1 1 0V5h2.5a.5.5 0 0 1 0 1H19v2.5a.5.5 0 1 1-1 0V6h-2.5a.5.5 0 0 1 0-1H18zM7 7a1 1 0 0 1 1-1h3.5a.5.5 0 0 0 0-1H8a2 2 0 0 0-2 2v14a.5.5 0 0 0 .805.396L12.5 17l5.695 4.396A.5.5 0 0 0 19 21v-8.5a.5.5 0 0 0-1 0v7.485l-5.195-4.012a.5.5 0 0 0-.61 0L7 19.985z"></path></svg></a></span></div></div></div></div></div></span><div class="j i d"><div class="tb bh tc md"></div></div></div></div></div></div></div></div></article></div></div><div class="vh vi vj vk vl vm vn vo vp vq vr vs vt vu vv vw vx vy vz wa wb"><div class="wc wd we wf wg dw l"><article class="dw"><div class="dw rp l"><div class="bh dw"><div class="dw l"><div class="fj dw wh wi wj wk wl wm wn wo wp wq wr ws wt" role="link" data-href="https://medium.com/@vi.ai_/exploring-and-building-the-llama-3-architecture-a-deep-dive-into-components-coding-and-43d4097cfbbb" tabindex="0"><div class="wu"><div aria-label="Exploring and building the LLaMA 3 Architecture&nbsp;: A Deep Dive into Components, Coding, and…"><div class="ww wx wy wz xa"><img alt="Exploring and building the LLaMA 3 Architecture&nbsp;: A Deep Dive into Components, Coding, and…" class="bh xb xc xd xe bx" src="hello_files/1_CQs4ceLpN8tIN8QyezL2Ag.png" loading="lazy"></div></div></div><div class="wv ab cb co"><div class="ab co xf bh xg xh xi xj"><div class="xk xl xm xn xo ab q"><div class="rb l"><div><div class="l" aria-hidden="false" aria-describedby="169" aria-labelledby="169"><a tabindex="-1" href="https://medium.com/@vi.ai_?source=read_next_recirc-----a4bbd2d85841----1---------------------4533891d_492e_419c_9f18_f15a7b08be12-------" rel="noopener follow"><div class="l fj"><img alt="vignesh yaadav" class="l fd by xp xq cx" src="hello_files/1_BVyuyXkv9sHhVycc1mW04w@2x.jpg" width="20" height="20" loading="lazy"><div class="fr by l xp xq fs n ay ft"></div></div></a></div></div></div><div class="xr l"><div><div class="l" aria-hidden="false" aria-describedby="170" aria-labelledby="170"><a class="af ag ah ai aj ak al am an ao ap aq ar jc ab q" href="https://medium.com/@vi.ai_?source=read_next_recirc-----a4bbd2d85841----1---------------------4533891d_492e_419c_9f18_f15a7b08be12-------" rel="noopener follow"><p class="bf b dv z jr js jt ju jv jw jx jy bk">vignesh yaadav</p></a></div></div></div></div><div class="xs l xt xu xv xw xx gn"><div class="xy xz ya yb yc yd ye yf"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/@vi.ai_/exploring-and-building-the-llama-3-architecture-a-deep-dive-into-components-coding-and-43d4097cfbbb?source=read_next_recirc-----a4bbd2d85841----1---------------------4533891d_492e_419c_9f18_f15a7b08be12-------" rel="noopener follow"><div title="Exploring and building the LLaMA 3 Architecture&nbsp;: A Deep Dive into Components, Coding, and…"><h2 class="bf gv pj hu yg yh pl pm hx yi yj po ok yk yl ym yn oo yo yp yq yr os ys yt yu yv jr jt ju jw jy bk">Exploring and building the LLaMA 3 Architecture&nbsp;: A Deep Dive into Components, Coding, and…</h2></div><div class="yw l"><h3 class="bf b ja z jr yx jt ju yy jw jy du">Meta
 is stepping up its game in the artificial intelligence (AI) race with 
the introduction of its new open-source AI model, Llama 3…</h3></div></a></div></div><span class="bf b dv z du"><div class="io ab cp ae"><div class="ab q"><div class="ze rp ab"><div class="bm" aria-hidden="false" aria-describedby="171" aria-labelledby="171"><button class="l ay ao am" aria-label="Member-only story"><div class=""><div><div class="bm" aria-hidden="false" aria-describedby="172" aria-labelledby="172"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="none" viewBox="0 0 64 64"><path fill="#FFC017" d="m39.637 40.831-5.771 15.871a1.99 1.99 0 0 1-3.732 0l-5.771-15.87a2.02 2.02 0 0 0-1.194-1.195L7.298 33.866a1.99 1.99 0 0 1 0-3.732l15.87-5.771a2.02 2.02 0 0 0 1.195-1.194l5.771-15.871a1.99 1.99 0 0 1 3.732 0l5.771 15.87a2.02 2.02 0 0 0 1.194 1.195l15.871 5.771a1.99 1.99 0 0 1 0 3.732l-15.87 5.771a2.02 2.02 0 0 0-1.195 1.194"></path></svg></div></div></div></button></div></div><span>Apr 19</span><div class=""><div class="fj yz dh ab q"><div class="fs tr za ab q"><div class="ax dh dj l cx"></div></div><a class="fs me za ab q" tabindex="-1" href="https://medium.com/@vi.ai_/exploring-and-building-the-llama-3-architecture-a-deep-dive-into-components-coding-and-43d4097cfbbb?source=read_next_recirc-----a4bbd2d85841----1---------------------4533891d_492e_419c_9f18_f15a7b08be12-------" rel="noopener follow"><div class="ax l"><div><div class="ab" aria-hidden="false" aria-describedby="217" aria-labelledby="217"><div class="ab q fj"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="none" viewBox="0 0 16 16"><path fill="#6B6B6B" fill-rule="evenodd" d="m3.672 10.167 2.138 2.14h-.002c1.726 1.722 4.337 2.436 5.96.81 1.472-1.45 1.806-3.68.76-5.388l-1.815-3.484c-.353-.524-.849-1.22-1.337-.958-.49.261 0 1.56 0 1.56l.78 1.932L6.43 2.866c-.837-.958-1.467-1.108-1.928-.647-.33.33-.266.856.477 1.598.501.503 1.888 1.957 1.888 1.957.17.174.083.485-.093.655a.56.56 0 0 1-.34.163.43.43 0 0 1-.317-.135s-2.4-2.469-2.803-2.87c-.344-.346-.803-.54-1.194-.15-.408.406-.273 1.065.11 1.447.345.346 2.31 2.297 2.685 2.67l.062.06c.17.175.269.628.093.8-.193.188-.453.33-.678.273a.9.9 0 0 1-.446-.273S2.501 6.84 1.892 6.23c-.407-.406-.899-.333-1.229 0-.525.524.263 1.28 1.73 2.691.384.368.814.781 1.279 1.246m8.472-7.219c.372-.29.95-.28 1.303.244V3.19l1.563 3.006.036.074c.885 1.87.346 4.093-.512 5.159l-.035.044c-.211.264-.344.43-.74.61 1.382-1.855.963-3.478-.248-5.456L11.943 3.88l-.002-.037c-.017-.3-.039-.71.203-.895" clip-rule="evenodd"></path></svg><span style="margin-left: 4px;">180</span></div></div></div></div><div class="ax l"><div><div class="ab" aria-hidden="false" aria-describedby="173" aria-labelledby="173"><div class="ab q fj"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="#6B6B6B" viewBox="0 0 16 16"><path fill="#6B6B6B" d="M12.344 11.458A5.28 5.28 0 0 0 14 7.526C14 4.483 11.391 2 8.051 2S2 4.483 2 7.527c0 3.051 2.712 5.526 6.059 5.526a6.6 6.6 0 0 0 1.758-.236q.255.223.554.414c.784.51 1.626.768 2.512.768a.37.37 0 0 0 .355-.214.37.37 0 0 0-.03-.384 4.7 4.7 0 0 1-.857-1.958v.014z"></path></svg><span style="margin-left: 4px;">5</span></div></div></div></div></a></div></div></div><div class="ab q zb zc"><div class=""><div><div class="bm" aria-hidden="false" aria-describedby="174" aria-labelledby="174"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F43d4097cfbbb&amp;operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2F%40vi.ai_%2Fexploring-and-building-the-llama-3-architecture-a-deep-dive-into-components-coding-and-43d4097cfbbb&amp;source=-----a4bbd2d85841----1-----------------bookmark_preview----4533891d_492e_419c_9f18_f15a7b08be12-------" rel="noopener follow"><svg xmlns="http://www.w3.org/2000/svg" width="25" height="25" fill="none" viewBox="0 0 25 25" class="du mj zd" aria-label="Add to list bookmark button"><path fill="currentColor" d="M18 2.5a.5.5 0 0 1 1 0V5h2.5a.5.5 0 0 1 0 1H19v2.5a.5.5 0 1 1-1 0V6h-2.5a.5.5 0 0 1 0-1H18zM7 7a1 1 0 0 1 1-1h3.5a.5.5 0 0 0 0-1H8a2 2 0 0 0-2 2v14a.5.5 0 0 0 .805.396L12.5 17l5.695 4.396A.5.5 0 0 0 19 21v-8.5a.5.5 0 0 0-1 0v7.485l-5.195-4.012a.5.5 0 0 0-.61 0L7 19.985z"></path></svg></a></span></div></div></div></div></div></span><div class="j i d"><div class="tb bh tc md"></div></div></div></div></div></div></div></div></article></div></div><div class="vh vi vj vk vl vm vn vo vp vq vr vs vt vu vv vw vx vy vz wa wb"><div class="wc wd we wf wg dw l"><article class="dw"><div class="dw rp l"><div class="bh dw"><div class="dw l"><div class="fj dw wh wi wj wk wl wm wn wo wp wq wr ws wt" role="link" data-href="https://medium.com/aiguys/prompt-engineering-is-dead-dspy-is-new-paradigm-for-prompting-c80ba3fc4896" tabindex="0"><div class="wu"><div aria-label="Prompt Engineering Is Dead: DSPy Is New Paradigm For Prompting"><div class="ww wx wy wz xa"><img alt="Prompt Engineering Is Dead: DSPy Is New Paradigm For Prompting" class="bh xb xc xd xe bx" src="hello_files/1_ICsY1ih79_x7_VD8Qvtm1Q.png" loading="lazy"></div></div></div><div class="wv ab cb co"><div class="ab co xf bh xg xh xi xj"><div class="xk xl xm xn xo ab q"><div class="rb l"><div><div class="l" aria-hidden="false" aria-describedby="175" aria-labelledby="175"><a tabindex="-1" href="https://vishal-ai.medium.com/?source=read_next_recirc-----a4bbd2d85841----2---------------------4533891d_492e_419c_9f18_f15a7b08be12-------" rel="noopener follow"><div class="l fj"><img alt="Vishal Rajput" class="l fd by xp xq cx" src="hello_files/1__SakCsysMdqdt--RikCQnw.jpg" width="20" height="20" loading="lazy"><div class="fr by l xp xq fs n ay ft"></div></div></a></div></div></div><div class="xr l"><div><div class="l" aria-hidden="false" aria-describedby="176" aria-labelledby="176"><a class="af ag ah ai aj ak al am an ao ap aq ar jc ab q" href="https://vishal-ai.medium.com/?source=read_next_recirc-----a4bbd2d85841----2---------------------4533891d_492e_419c_9f18_f15a7b08be12-------" rel="noopener follow"><p class="bf b dv z jr js jt ju jv jw jx jy bk">Vishal Rajput</p><div class="acb acc l"><div class="ab acd"><div class="ab"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="none" viewBox="0 0 16 16"><path fill="#437AFF" d="M15.163 8c0 .65-.459 1.144-.863 1.575-.232.244-.471.5-.563.719s-.086.543-.092.875c-.006.606-.018 1.3-.49 1.781-.47.481-1.15.494-1.744.5-.324.006-.655.013-.857.094s-.465.337-.704.575c-.422.412-.906.881-1.542.881-.637 0-1.12-.469-1.543-.881-.239-.238-.49-.482-.704-.575-.214-.094-.532-.088-.857-.094-.593-.006-1.273-.019-1.744-.5s-.484-1.175-.49-1.781c-.006-.332-.012-.669-.092-.875-.08-.207-.33-.475-.563-.719-.404-.431-.863-.925-.863-1.575s.46-1.144.863-1.575c.233-.244.472-.5.563-.719.092-.219.086-.544.092-.875.006-.606.019-1.3.49-1.781s1.15-.494 1.744-.5c.325-.006.655-.012.857-.094.202-.081.465-.337.704-.575C7.188 1.47 7.671 1 8.308 1s1.12.469 1.542.881c.239.238.49.481.704.575s.533.088.857.094c.594.006 1.273.019 1.745.5.47.481.483 1.175.49 1.781.005.331.011.669.091.875s.33.475.563.719c.404.431.863.925.863 1.575"></path><path fill="#fff" d="M7.328 10.5c.195 0 .381.08.519.22.137.141.215.331.216.53 0 .066.026.13.072.177a.24.24 0 0 0 .346 0 .25.25 0 0 0 .071-.177c.001-.199.079-.389.216-.53a.73.73 0 0 1 .519-.22h1.959c.13 0 .254-.053.346-.146a.5.5 0 0 0 .143-.354V6a.5.5 0 0 0-.143-.354.49.49 0 0 0-.346-.146h-1.47c-.324 0-.635.132-.865.366-.23.235-.359.552-.359.884v2.5c0 .066-.025.13-.071.177a.24.24 0 0 1-.346 0 .25.25 0 0 1-.072-.177v-2.5c0-.332-.13-.65-.359-.884A1.21 1.21 0 0 0 6.84 5.5h-1.47a.49.49 0 0 0-.346.146A.5.5 0 0 0 4.88 6v4c0 .133.051.26.143.354a.49.49 0 0 0 .347.146z"></path></svg></div></div></div></a></div></div></div><div class="xr l"><p class="bf b dv z du">in</p></div><div class="l"><div><div class="l" aria-hidden="false" aria-describedby="177" aria-labelledby="177"><a class="af ag ah ai aj ak al am an ao ap aq ar jc ab q" href="https://medium.com/aiguys?source=read_next_recirc-----a4bbd2d85841----2---------------------4533891d_492e_419c_9f18_f15a7b08be12-------" rel="noopener follow"><p class="bf b dv z jr js jt ju jv jw jx jy bk">AIGuys</p></a></div></div></div></div><div class="xs l xt xu xv xw xx gn"><div class="xy xz ya yb yc yd ye yf"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/aiguys/prompt-engineering-is-dead-dspy-is-new-paradigm-for-prompting-c80ba3fc4896?source=read_next_recirc-----a4bbd2d85841----2---------------------4533891d_492e_419c_9f18_f15a7b08be12-------" rel="noopener follow"><div title=""><h2 class="bf gv pj hu yg yh pl pm hx yi yj po ok yk yl ym yn oo yo yp yq yr os ys yt yu yv jr jt ju jw jy bk">Prompt Engineering Is Dead: DSPy Is New Paradigm For Prompting</h2></div><div class="yw l"><h3 class="bf b ja z jr yx jt ju yy jw jy du">DSPy Paradigm: Let’s program — not prompt — LLMs</h3></div></a></div></div><span class="bf b dv z du"><div class="io ab cp ae"><div class="ab q"><div class="ze rp ab"><div class="bm" aria-hidden="false" aria-describedby="178" aria-labelledby="178"><button class="l ay ao am" aria-label="Member-only story"><div class=""><div><div class="bm" aria-hidden="false" aria-describedby="179" aria-labelledby="179"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="none" viewBox="0 0 64 64"><path fill="#FFC017" d="m39.637 40.831-5.771 15.871a1.99 1.99 0 0 1-3.732 0l-5.771-15.87a2.02 2.02 0 0 0-1.194-1.195L7.298 33.866a1.99 1.99 0 0 1 0-3.732l15.87-5.771a2.02 2.02 0 0 0 1.195-1.194l5.771-15.871a1.99 1.99 0 0 1 3.732 0l5.771 15.87a2.02 2.02 0 0 0 1.194 1.195l15.871 5.771a1.99 1.99 0 0 1 0 3.732l-15.87 5.771a2.02 2.02 0 0 0-1.195 1.194"></path></svg></div></div></div></button></div></div><span>May 29</span><div class=""><div class="fj yz dh ab q"><div class="fs tr za ab q"><div class="ax dh dj l cx"></div></div><a class="fs me za ab q" tabindex="-1" href="https://medium.com/aiguys/prompt-engineering-is-dead-dspy-is-new-paradigm-for-prompting-c80ba3fc4896?source=read_next_recirc-----a4bbd2d85841----2---------------------4533891d_492e_419c_9f18_f15a7b08be12-------" rel="noopener follow"><div class="ax l"><div><div class="ab" aria-hidden="false" aria-describedby="219" aria-labelledby="219"><div class="ab q fj"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="none" viewBox="0 0 16 16"><path fill="#6B6B6B" fill-rule="evenodd" d="m3.672 10.167 2.138 2.14h-.002c1.726 1.722 4.337 2.436 5.96.81 1.472-1.45 1.806-3.68.76-5.388l-1.815-3.484c-.353-.524-.849-1.22-1.337-.958-.49.261 0 1.56 0 1.56l.78 1.932L6.43 2.866c-.837-.958-1.467-1.108-1.928-.647-.33.33-.266.856.477 1.598.501.503 1.888 1.957 1.888 1.957.17.174.083.485-.093.655a.56.56 0 0 1-.34.163.43.43 0 0 1-.317-.135s-2.4-2.469-2.803-2.87c-.344-.346-.803-.54-1.194-.15-.408.406-.273 1.065.11 1.447.345.346 2.31 2.297 2.685 2.67l.062.06c.17.175.269.628.093.8-.193.188-.453.33-.678.273a.9.9 0 0 1-.446-.273S2.501 6.84 1.892 6.23c-.407-.406-.899-.333-1.229 0-.525.524.263 1.28 1.73 2.691.384.368.814.781 1.279 1.246m8.472-7.219c.372-.29.95-.28 1.303.244V3.19l1.563 3.006.036.074c.885 1.87.346 4.093-.512 5.159l-.035.044c-.211.264-.344.43-.74.61 1.382-1.855.963-3.478-.248-5.456L11.943 3.88l-.002-.037c-.017-.3-.039-.71.203-.895" clip-rule="evenodd"></path></svg><span style="margin-left: 4px;">4.4K</span></div></div></div></div><div class="ax l"><div><div class="ab" aria-hidden="false" aria-describedby="180" aria-labelledby="180"><div class="ab q fj"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="#6B6B6B" viewBox="0 0 16 16"><path fill="#6B6B6B" d="M12.344 11.458A5.28 5.28 0 0 0 14 7.526C14 4.483 11.391 2 8.051 2S2 4.483 2 7.527c0 3.051 2.712 5.526 6.059 5.526a6.6 6.6 0 0 0 1.758-.236q.255.223.554.414c.784.51 1.626.768 2.512.768a.37.37 0 0 0 .355-.214.37.37 0 0 0-.03-.384 4.7 4.7 0 0 1-.857-1.958v.014z"></path></svg><span style="margin-left: 4px;">45</span></div></div></div></div></a></div></div></div><div class="ab q zb zc"><div class=""><div><div class="bm" aria-hidden="false" aria-describedby="181" aria-labelledby="181"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc80ba3fc4896&amp;operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2Faiguys%2Fprompt-engineering-is-dead-dspy-is-new-paradigm-for-prompting-c80ba3fc4896&amp;source=-----a4bbd2d85841----2-----------------bookmark_preview----4533891d_492e_419c_9f18_f15a7b08be12-------" rel="noopener follow"><svg xmlns="http://www.w3.org/2000/svg" width="25" height="25" fill="none" viewBox="0 0 25 25" class="du mj zd" aria-label="Add to list bookmark button"><path fill="currentColor" d="M18 2.5a.5.5 0 0 1 1 0V5h2.5a.5.5 0 0 1 0 1H19v2.5a.5.5 0 1 1-1 0V6h-2.5a.5.5 0 0 1 0-1H18zM7 7a1 1 0 0 1 1-1h3.5a.5.5 0 0 0 0-1H8a2 2 0 0 0-2 2v14a.5.5 0 0 0 .805.396L12.5 17l5.695 4.396A.5.5 0 0 0 19 21v-8.5a.5.5 0 0 0-1 0v7.485l-5.195-4.012a.5.5 0 0 0-.61 0L7 19.985z"></path></svg></a></span></div></div></div></div></div></span><div class="j i d"><div class="tb bh tc md"></div></div></div></div></div></div></div></div></article></div></div><div class="vh vi vj vk vl vm vn vo vp vq vr vs vt vu vv vw vx vy vz wa wb"><div class="wc wd we wf wg dw l"><article class="dw"><div class="dw rp l"><div class="bh dw"><div class="dw l"><div class="fj dw wh wi wj wk wl wm wn wo wp wq wr ws wt" role="link" data-href="https://ai.gopubby.com/will-long-context-llms-cause-the-extinction-of-rag-de41ca5ddfc6" tabindex="0"><div class="wu"><div aria-label="Will Long-Context LLMs Cause the Extinction of RAG"><div class="ww wx wy wz xa"><img alt="Will Long-Context LLMs Cause the Extinction of RAG" class="bh xb xc xd xe bx" src="hello_files/1_EYpZNFpZ3XvKTqzrTDxGfg.png" loading="lazy"></div></div></div><div class="wv ab cb co"><div class="ab co xf bh xg xh xi xj"><div class="xk xl xm xn xo ab q"><div class="rb l"><div><div class="l" aria-hidden="false" aria-describedby="182" aria-labelledby="182"><a tabindex="-1" href="https://medium.com/@florian_algo?source=read_next_recirc-----a4bbd2d85841----3---------------------4533891d_492e_419c_9f18_f15a7b08be12-------" rel="noopener follow"><div class="l fj"><img alt="Florian June" class="l fd by xp xq cx" src="hello_files/1_DmQ3DH2JeAJquvhT_tjVCw.jpg" width="20" height="20" loading="lazy"><div class="fr by l xp xq fs n ay ft"></div></div></a></div></div></div><div class="xr l"><div><div class="l" aria-hidden="false" aria-describedby="183" aria-labelledby="183"><a class="af ag ah ai aj ak al am an ao ap aq ar jc ab q" href="https://medium.com/@florian_algo?source=read_next_recirc-----a4bbd2d85841----3---------------------4533891d_492e_419c_9f18_f15a7b08be12-------" rel="noopener follow"><p class="bf b dv z jr js jt ju jv jw jx jy bk">Florian June</p></a></div></div></div><div class="xr l"><p class="bf b dv z du">in</p></div><div class="l"><div><div class="l" aria-hidden="false" aria-describedby="184" aria-labelledby="184"><a class="af ag ah ai aj ak al am an ao ap aq ar jc ab q" href="https://ai.gopubby.com/?source=read_next_recirc-----a4bbd2d85841----3---------------------4533891d_492e_419c_9f18_f15a7b08be12-------" rel="noopener follow"><p class="bf b dv z jr js jt ju jv jw jx jy bk">AI Advances</p></a></div></div></div></div><div class="xs l xt xu xv xw xx gn"><div class="xy xz ya yb yc yd ye yf"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://ai.gopubby.com/will-long-context-llms-cause-the-extinction-of-rag-de41ca5ddfc6?source=read_next_recirc-----a4bbd2d85841----3---------------------4533891d_492e_419c_9f18_f15a7b08be12-------" rel="noopener follow"><div title=""><h2 class="bf gv pj hu yg yh pl pm hx yi yj po ok yk yl ym yn oo yo yp yq yr os ys yt yu yv jr jt ju jw jy bk">Will Long-Context LLMs Cause the Extinction of RAG</h2></div><div class="yw l"><h3 class="bf b ja z jr yx jt ju yy jw jy du">Intuitive Perspective, Academic Research, and Insights</h3></div></a></div></div><span class="bf b dv z du"><div class="io ab cp ae"><div class="ab q"><div class="ze rp ab"><div class="bm" aria-hidden="false" aria-describedby="185" aria-labelledby="185"><button class="l ay ao am" aria-label="Member-only story"><div class=""><div><div class="bm" aria-hidden="false" aria-describedby="186" aria-labelledby="186"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="none" viewBox="0 0 64 64"><path fill="#FFC017" d="m39.637 40.831-5.771 15.871a1.99 1.99 0 0 1-3.732 0l-5.771-15.87a2.02 2.02 0 0 0-1.194-1.195L7.298 33.866a1.99 1.99 0 0 1 0-3.732l15.87-5.771a2.02 2.02 0 0 0 1.195-1.194l5.771-15.871a1.99 1.99 0 0 1 3.732 0l5.771 15.87a2.02 2.02 0 0 0 1.194 1.195l15.871 5.771a1.99 1.99 0 0 1 0 3.732l-15.87 5.771a2.02 2.02 0 0 0-1.195 1.194"></path></svg></div></div></div></button></div></div><span>Aug 1</span><div class=""><div class="fj yz dh ab q"><div class="fs tr za ab q"><div class="ax dh dj l cx"></div></div><a class="fs me za ab q" tabindex="-1" href="https://ai.gopubby.com/will-long-context-llms-cause-the-extinction-of-rag-de41ca5ddfc6?source=read_next_recirc-----a4bbd2d85841----3---------------------4533891d_492e_419c_9f18_f15a7b08be12-------" rel="noopener follow"><div class="ax l"><div><div class="ab" aria-hidden="false" aria-describedby="221" aria-labelledby="221"><div class="ab q fj"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="none" viewBox="0 0 16 16"><path fill="#6B6B6B" fill-rule="evenodd" d="m3.672 10.167 2.138 2.14h-.002c1.726 1.722 4.337 2.436 5.96.81 1.472-1.45 1.806-3.68.76-5.388l-1.815-3.484c-.353-.524-.849-1.22-1.337-.958-.49.261 0 1.56 0 1.56l.78 1.932L6.43 2.866c-.837-.958-1.467-1.108-1.928-.647-.33.33-.266.856.477 1.598.501.503 1.888 1.957 1.888 1.957.17.174.083.485-.093.655a.56.56 0 0 1-.34.163.43.43 0 0 1-.317-.135s-2.4-2.469-2.803-2.87c-.344-.346-.803-.54-1.194-.15-.408.406-.273 1.065.11 1.447.345.346 2.31 2.297 2.685 2.67l.062.06c.17.175.269.628.093.8-.193.188-.453.33-.678.273a.9.9 0 0 1-.446-.273S2.501 6.84 1.892 6.23c-.407-.406-.899-.333-1.229 0-.525.524.263 1.28 1.73 2.691.384.368.814.781 1.279 1.246m8.472-7.219c.372-.29.95-.28 1.303.244V3.19l1.563 3.006.036.074c.885 1.87.346 4.093-.512 5.159l-.035.044c-.211.264-.344.43-.74.61 1.382-1.855.963-3.478-.248-5.456L11.943 3.88l-.002-.037c-.017-.3-.039-.71.203-.895" clip-rule="evenodd"></path></svg><span style="margin-left: 4px;">416</span></div></div></div></div><div class="ax l"><div><div class="ab" aria-hidden="false" aria-describedby="187" aria-labelledby="187"><div class="ab q fj"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="#6B6B6B" viewBox="0 0 16 16"><path fill="#6B6B6B" d="M12.344 11.458A5.28 5.28 0 0 0 14 7.526C14 4.483 11.391 2 8.051 2S2 4.483 2 7.527c0 3.051 2.712 5.526 6.059 5.526a6.6 6.6 0 0 0 1.758-.236q.255.223.554.414c.784.51 1.626.768 2.512.768a.37.37 0 0 0 .355-.214.37.37 0 0 0-.03-.384 4.7 4.7 0 0 1-.857-1.958v.014z"></path></svg><span style="margin-left: 4px;">6</span></div></div></div></div></a></div></div></div><div class="ab q zb zc"><div class=""><div><div class="bm" aria-hidden="false" aria-describedby="188" aria-labelledby="188"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fde41ca5ddfc6&amp;operation=register&amp;redirect=https%3A%2F%2Fai.gopubby.com%2Fwill-long-context-llms-cause-the-extinction-of-rag-de41ca5ddfc6&amp;source=-----a4bbd2d85841----3-----------------bookmark_preview----4533891d_492e_419c_9f18_f15a7b08be12-------" rel="noopener follow"><svg xmlns="http://www.w3.org/2000/svg" width="25" height="25" fill="none" viewBox="0 0 25 25" class="du mj zd" aria-label="Add to list bookmark button"><path fill="currentColor" d="M18 2.5a.5.5 0 0 1 1 0V5h2.5a.5.5 0 0 1 0 1H19v2.5a.5.5 0 1 1-1 0V6h-2.5a.5.5 0 0 1 0-1H18zM7 7a1 1 0 0 1 1-1h3.5a.5.5 0 0 0 0-1H8a2 2 0 0 0-2 2v14a.5.5 0 0 0 .805.396L12.5 17l5.695 4.396A.5.5 0 0 0 19 21v-8.5a.5.5 0 0 0-1 0v7.485l-5.195-4.012a.5.5 0 0 0-.61 0L7 19.985z"></path></svg></a></span></div></div></div></div></div></span></div></div></div></div></div></div></article></div></div></div><div class="tb bh tc dk dl zf zg zh"></div><a class="bf b bg z bk rc zl zm zn mj mg zo ev ew ex zp zq zr fa zs zt zu zv zw fb fc fd bm fe ff" href="https://medium.com/?source=post_page-----a4bbd2d85841--------------------------------" rel="noopener follow"><div class="l ff">See more recommendations</div></a></div></div></div><div class="h k j"><div class="tb bh tc ti"></div><div class="ab cb"><div class="ci bh fz ga gb gc"><div class="tj ab lh jm"><div class="tk tl l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://help.medium.com/hc/en-us?source=post_page-----a4bbd2d85841--------------------------------" rel="noopener follow"><p class="bf b dv z du">Help</p></a></div><div class="tk tl l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.statuspage.io/?source=post_page-----a4bbd2d85841--------------------------------" rel="noopener follow"><p class="bf b dv z du">Status</p></a></div><div class="tk tl l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/about?autoplay=1&amp;source=post_page-----a4bbd2d85841--------------------------------" rel="noopener follow"><p class="bf b dv z du">About</p></a></div><div class="tk tl l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=post_page-----a4bbd2d85841--------------------------------" rel="noopener follow"><p class="bf b dv z du">Careers</p></a></div><div class="tk tl l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://towardsdatascience.com/pressinquiries@medium.com?source=post_page-----a4bbd2d85841--------------------------------" rel="noopener follow"><p class="bf b dv z du">Press</p></a></div><div class="tk tl l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://blog.medium.com/?source=post_page-----a4bbd2d85841--------------------------------" rel="noopener follow"><p class="bf b dv z du">Blog</p></a></div><div class="tk tl l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----a4bbd2d85841--------------------------------" rel="noopener follow"><p class="bf b dv z du">Privacy</p></a></div><div class="tk tl l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----a4bbd2d85841--------------------------------" rel="noopener follow"><p class="bf b dv z du">Terms</p></a></div><div class="tk tl l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://speechify.com/medium?source=post_page-----a4bbd2d85841--------------------------------" rel="noopener follow"><p class="bf b dv z du">Text to speech</p></a></div><div class="tk l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/business?source=post_page-----a4bbd2d85841--------------------------------" rel="noopener follow"><p class="bf b dv z du">Teams</p></a></div></div></div></div></div></div></div></div></div></div><script>window.__BUILD_ID__="main-20240816-213258-037b2e2e42"</script><script>window.__GRAPHQL_URI__ = "https://towardsdatascience.com/_/graphql"</script><script>window.__PRELOADED_STATE__ = {"algolia":{"queries":{}},"cache":{"experimentGroupSet":true,"reason":"","group":"enabled","tags":["group-edgeCachePosts","post-a4bbd2d85841","user-e6581bb71f6","collection-7f60cf5620c9"],"serverVariantState":"44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a","middlewareEnabled":true,"cacheStatus":"DYNAMIC","shouldUseCache":true,"vary":[],"lohpSummerUpsellEnabled":true,"lohpSummerDiscountTakeoverEnabled":true,"logoUpdatePhase2Enabled":true,"logoUpdatePhase3Enabled":false},"client":{"hydrated":false,"isUs":false,"isNativeMedium":false,"isSafariMobile":false,"isSafari":false,"isFirefox":false,"routingEntity":{"type":"COLLECTION","id":"7f60cf5620c9","explicit":true},"viewerIsBot":false},"debug":{"requestId":"cabc25ef-bd9c-4151-85f6-bf9a0c617cd5","hybridDevServices":[],"originalSpanCarrier":{}},"multiVote":{"clapsPerPost":{}},"navigation":{"branch":{"show":null,"hasRendered":null,"blockedByCTA":false},"hideGoogleOneTap":false,"hasRenderedAlternateUserBanner":null,"currentLocation":"https:\u002F\u002Ftowardsdatascience.com\u002Funderstanding-the-implications-of-direct-preference-optimization-a4bbd2d85841","host":"towardsdatascience.com","hostname":"towardsdatascience.com","referrer":"","hasSetReferrer":false,"susiModal":{"step":null,"operation":"register"},"postRead":false,"partnerProgram":{"selectedCountryCode":null},"queryString":"","currentHash":""},"config":{"nodeEnv":"production","version":"main-20240816-213258-037b2e2e42","target":"production","productName":"Medium","publicUrl":"https:\u002F\u002Fcdn-client.medium.com\u002Flite","authDomain":"medium.com","authGoogleClientId":"216296035834-k1k6qe060s2tp2a2jam4ljdcms00sttg.apps.googleusercontent.com","favicon":"production","glyphUrl":"https:\u002F\u002Fglyph.medium.com","branchKey":"key_live_ofxXr2qTrrU9NqURK8ZwEhknBxiI6KBm","algolia":{"appId":"MQ57UUUQZ2","apiKeySearch":"394474ced050e3911ae2249ecc774921","indexPrefix":"medium_","host":"-dsn.algolia.net"},"recaptchaKey":"6Lfc37IUAAAAAKGGtC6rLS13R1Hrw_BqADfS1LRk","recaptcha3Key":"6Lf8R9wUAAAAABMI_85Wb8melS7Zj6ziuf99Yot5","recaptchaEnterpriseKeyId":"6Le-uGgpAAAAAPprRaokM8AKthQ9KNGdoxaGUvVp","datadog":{"applicationId":"6702d87d-a7e0-42fe-bbcb-95b469547ea0","clientToken":"pub853ea8d17ad6821d9f8f11861d23dfed","rumToken":"pubf9cc52896502b9413b68ba36fc0c7162","context":{"deployment":{"target":"production","tag":"main-20240816-213258-037b2e2e42","commit":"037b2e2e42482792172b5f10190c827a20f1fbab"}},"datacenter":"us"},"googleAnalyticsCode":"G-7JY7T788PK","googlePay":{"apiVersion":"2","apiVersionMinor":"0","merchantId":"BCR2DN6TV7EMTGBM","merchantName":"Medium","instanceMerchantId":"13685562959212738550"},"applePay":{"version":3},"signInWallCustomDomainCollectionIds":["3a8144eabfe3","336d898217ee","61061eb0c96b","138adf9c44c","819cc2aaeee0"],"mediumMastodonDomainName":"me.dm","mediumOwnedAndOperatedCollectionIds":["8a9336e5bb4","b7e45b22fec3","193b68bd4fba","8d6b8a439e32","54c98c43354d","3f6ecf56618","d944778ce714","92d2092dc598","ae2a65f35510","1285ba81cada","544c7006046e","fc8964313712","40187e704f1c","88d9857e584e","7b6769f2748b","bcc38c8f6edf","cef6983b292","cb8577c9149e","444d13b52878","713d7dbc99b0","ef8e90590e66","191186aaafa0","55760f21cdc5","9dc80918cc93","bdc4052bbdba","8ccfed20cbb2"],"tierOneDomains":["medium.com","thebolditalic.com","arcdigital.media","towardsdatascience.com","uxdesign.cc","codeburst.io","psiloveyou.xyz","writingcooperative.com","entrepreneurshandbook.co","prototypr.io","betterhumans.coach.me","theascent.pub"],"topicsToFollow":["d61cf867d93f","8a146bc21b28","1eca0103fff3","4d562ee63426","aef1078a3ef5","e15e46793f8d","6158eb913466","55f1c20aba7a","3d18b94f6858","4861fee224fd","63c6f1f93ee","1d98b3a9a871","decb52b64abf","ae5d4995e225","830cded25262"],"topicToTagMappings":{"accessibility":"accessibility","addiction":"addiction","android-development":"android-development","art":"art","artificial-intelligence":"artificial-intelligence","astrology":"astrology","basic-income":"basic-income","beauty":"beauty","biotech":"biotech","blockchain":"blockchain","books":"books","business":"business","cannabis":"cannabis","cities":"cities","climate-change":"climate-change","comics":"comics","coronavirus":"coronavirus","creativity":"creativity","cryptocurrency":"cryptocurrency","culture":"culture","cybersecurity":"cybersecurity","data-science":"data-science","design":"design","digital-life":"digital-life","disability":"disability","economy":"economy","education":"education","equality":"equality","family":"family","feminism":"feminism","fiction":"fiction","film":"film","fitness":"fitness","food":"food","freelancing":"freelancing","future":"future","gadgets":"gadgets","gaming":"gaming","gun-control":"gun-control","health":"health","history":"history","humor":"humor","immigration":"immigration","ios-development":"ios-development","javascript":"javascript","justice":"justice","language":"language","leadership":"leadership","lgbtqia":"lgbtqia","lifestyle":"lifestyle","machine-learning":"machine-learning","makers":"makers","marketing":"marketing","math":"math","media":"media","mental-health":"mental-health","mindfulness":"mindfulness","money":"money","music":"music","neuroscience":"neuroscience","nonfiction":"nonfiction","outdoors":"outdoors","parenting":"parenting","pets":"pets","philosophy":"philosophy","photography":"photography","podcasts":"podcast","poetry":"poetry","politics":"politics","privacy":"privacy","product-management":"product-management","productivity":"productivity","programming":"programming","psychedelics":"psychedelics","psychology":"psychology","race":"race","relationships":"relationships","religion":"religion","remote-work":"remote-work","san-francisco":"san-francisco","science":"science","self":"self","self-driving-cars":"self-driving-cars","sexuality":"sexuality","social-media":"social-media","society":"society","software-engineering":"software-engineering","space":"space","spirituality":"spirituality","sports":"sports","startups":"startup","style":"style","technology":"technology","transportation":"transportation","travel":"travel","true-crime":"true-crime","tv":"tv","ux":"ux","venture-capital":"venture-capital","visual-design":"visual-design","work":"work","world":"world","writing":"writing"},"defaultImages":{"avatar":{"imageId":"1*dmbNkD5D-u45r44go_cf0g.png","height":150,"width":150},"orgLogo":{"imageId":"7*V1_7XP4snlmqrc_0Njontw.png","height":110,"width":500},"postLogo":{"imageId":"bd978bb536350a710e8efb012513429cabdc4c28700604261aeda246d0f980b7","height":810,"width":1440},"postPreviewImage":{"imageId":"1*hn4v1tCaJy7cWMyb0bpNpQ.png","height":386,"width":579}},"collectionStructuredData":{"8d6b8a439e32":{"name":"Elemental","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F980\u002F1*9ygdqoKprhwuTVKUM0DLPA@2x.png","width":980,"height":159}}},"3f6ecf56618":{"name":"Forge","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F596\u002F1*uULpIlImcO5TDuBZ6lm7Lg@2x.png","width":596,"height":183}}},"ae2a65f35510":{"name":"GEN","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fmiro.medium.com\u002Fmax\u002F264\u002F1*RdVZMdvfV3YiZTw6mX7yWA.png","width":264,"height":140}}},"88d9857e584e":{"name":"LEVEL","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fmiro.medium.com\u002Fmax\u002F540\u002F1*JqYMhNX6KNNb2UlqGqO2WQ.png","width":540,"height":108}}},"7b6769f2748b":{"name":"Marker","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F383\u002F1*haCUs0wF6TgOOvfoY-jEoQ@2x.png","width":383,"height":92}}},"444d13b52878":{"name":"OneZero","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fmiro.medium.com\u002Fmax\u002F540\u002F1*cw32fIqCbRWzwJaoQw6BUg.png","width":540,"height":123}}},"8ccfed20cbb2":{"name":"Zora","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fmiro.medium.com\u002Fmax\u002F540\u002F1*tZUQqRcCCZDXjjiZ4bDvgQ.png","width":540,"height":106}}}},"embeddedPostIds":{"coronavirus":"cd3010f9d81f"},"sharedCdcMessaging":{"COVID_APPLICABLE_TAG_SLUGS":[],"COVID_APPLICABLE_TOPIC_NAMES":[],"COVID_APPLICABLE_TOPIC_NAMES_FOR_TOPIC_PAGE":[],"COVID_MESSAGES":{"tierA":{"text":"For more information on the novel coronavirus and Covid-19, visit cdc.gov.","markups":[{"start":66,"end":73,"href":"https:\u002F\u002Fwww.cdc.gov\u002Fcoronavirus\u002F2019-nCoV"}]},"tierB":{"text":"Anyone can publish on Medium per our Policies, but we don’t fact-check every story. For more info about the coronavirus, see cdc.gov.","markups":[{"start":37,"end":45,"href":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Fcategories\u002F201931128-Policies-Safety"},{"start":125,"end":132,"href":"https:\u002F\u002Fwww.cdc.gov\u002Fcoronavirus\u002F2019-nCoV"}]},"paywall":{"text":"This article has been made free for everyone, thanks to Medium Members. For more information on the novel coronavirus and Covid-19, visit cdc.gov.","markups":[{"start":56,"end":70,"href":"https:\u002F\u002Fmedium.com\u002Fmembership"},{"start":138,"end":145,"href":"https:\u002F\u002Fwww.cdc.gov\u002Fcoronavirus\u002F2019-nCoV"}]},"unbound":{"text":"This article is free for everyone, thanks to Medium Members. For more information on the novel coronavirus and Covid-19, visit cdc.gov.","markups":[{"start":45,"end":59,"href":"https:\u002F\u002Fmedium.com\u002Fmembership"},{"start":127,"end":134,"href":"https:\u002F\u002Fwww.cdc.gov\u002Fcoronavirus\u002F2019-nCoV"}]}},"COVID_BANNER_POST_ID_OVERRIDE_WHITELIST":["3b31a67bff4a"]},"sharedVoteMessaging":{"TAGS":["politics","election-2020","government","us-politics","election","2020-presidential-race","trump","donald-trump","democrats","republicans","congress","republican-party","democratic-party","biden","joe-biden","maga"],"TOPICS":["politics","election"],"MESSAGE":{"text":"Find out more about the U.S. election results here.","markups":[{"start":46,"end":50,"href":"https:\u002F\u002Fcookpolitical.com\u002F2020-national-popular-vote-tracker"}]},"EXCLUDE_POSTS":["397ef29e3ca5"]},"embedPostRules":[],"recircOptions":{"v1":{"limit":3},"v2":{"limit":8}},"braintreeClientKey":"production_zjkj96jm_m56f8fqpf7ngnrd4","braintree":{"enabled":true,"merchantId":"m56f8fqpf7ngnrd4","merchantAccountId":{"usd":"AMediumCorporation_instant","eur":"amediumcorporation_EUR","cad":"amediumcorporation_CAD"},"publicKey":"ds2nn34bg2z7j5gd","braintreeEnvironment":"production","dashboardUrl":"https:\u002F\u002Fwww.braintreegateway.com\u002Fmerchants","gracePeriodDurationInDays":14,"mediumMembershipPlanId":{"monthly":"ce105f8c57a3","monthlyV2":"e8a5e126-792b-4ee6-8fba-d574c1b02fc5","monthlyWithTrial":"d5ee3dbe3db8","monthlyPremium":"fa741a9b47a2","yearly":"a40ad4a43185","yearlyV2":"3815d7d6-b8ca-4224-9b8c-182f9047866e","yearlyStaff":"d74fb811198a","yearlyWithTrial":"b3bc7350e5c7","yearlyPremium":"e21bd2c12166","monthlyOneYearFree":"e6c0637a-2bad-4171-ab4f-3c268633d83c","monthly25PercentOffFirstYear":"235ecc62-0cdb-49ae-9378-726cd21c504b","monthly20PercentOffFirstYear":"ba518864-9c13-4a99-91ca-411bf0cac756","monthly15PercentOffFirstYear":"594c029b-9f89-43d5-88f8-8173af4e070e","monthly10PercentOffFirstYear":"c6c7bc9a-40f2-4b51-8126-e28511d5bdb0","monthlyForStudents":"629ebe51-da7d-41fd-8293-34cd2f2030a8","yearlyOneYearFree":"78ba7be9-0d9f-4ece-aa3e-b54b826f2bf1","yearly25PercentOffFirstYear":"2dbb010d-bb8f-4eeb-ad5c-a08509f42d34","yearly20PercentOffFirstYear":"47565488-435b-47f8-bf93-40d5fbe0ebc8","yearly15PercentOffFirstYear":"8259809b-0881-47d9-acf7-6c001c7f720f","yearly10PercentOffFirstYear":"9dd694fb-96e1-472c-8d9e-3c868d5c1506","yearlyForStudents":"e29345ef-ab1c-4234-95c5-70e50fe6bc23","monthlyCad":"p52orjkaceei","yearlyCad":"h4q9g2up9ktt"},"braintreeDiscountId":{"oneMonthFree":"MONTHS_FREE_01","threeMonthsFree":"MONTHS_FREE_03","sixMonthsFree":"MONTHS_FREE_06","fiftyPercentOffOneYear":"FIFTY_PERCENT_OFF_ONE_YEAR"},"3DSecureVersion":"2","defaultCurrency":"usd","providerPlanIdCurrency":{"4ycw":"usd","rz3b":"usd","3kqm":"usd","jzw6":"usd","c2q2":"usd","nnsw":"usd","q8qw":"usd","d9y6":"usd","fx7w":"cad","nwf2":"cad"}},"paypalClientId":"AXj1G4fotC2GE8KzWX9mSxCH1wmPE3nJglf4Z2ig_amnhvlMVX87otaq58niAg9iuLktVNF_1WCMnN7v","paypal":{"host":"https:\u002F\u002Fapi.paypal.com:443","clientMode":"production","serverMode":"live","webhookId":"4G466076A0294510S","monthlyPlan":{"planId":"P-9WR0658853113943TMU5FDQA","name":"Medium Membership (Monthly) with setup fee","description":"Unlimited access to the best and brightest stories on Medium. Membership billed monthly."},"yearlyPlan":{"planId":"P-7N8963881P8875835MU5JOPQ","name":"Medium Membership (Annual) with setup fee","description":"Unlimited access to the best and brightest stories on Medium. Membership billed annually."},"oneYearGift":{"name":"Medium Membership (1 Year, Digital Gift Code)","description":"Unlimited access to the best and brightest stories on Medium. Gift codes can be redeemed at medium.com\u002Fredeem.","price":"50.00","currency":"USD","sku":"membership-gift-1-yr"},"oldMonthlyPlan":{"planId":"P-96U02458LM656772MJZUVH2Y","name":"Medium Membership (Monthly)","description":"Unlimited access to the best and brightest stories on Medium. Membership billed monthly."},"oldYearlyPlan":{"planId":"P-59P80963JF186412JJZU3SMI","name":"Medium Membership (Annual)","description":"Unlimited access to the best and brightest stories on Medium. Membership billed annually."},"monthlyPlanWithTrial":{"planId":"P-66C21969LR178604GJPVKUKY","name":"Medium Membership (Monthly) with setup fee","description":"Unlimited access to the best and brightest stories on Medium. Membership billed monthly."},"yearlyPlanWithTrial":{"planId":"P-6XW32684EX226940VKCT2MFA","name":"Medium Membership (Annual) with setup fee","description":"Unlimited access to the best and brightest stories on Medium. Membership billed annually."},"oldMonthlyPlanNoSetupFee":{"planId":"P-4N046520HR188054PCJC7LJI","name":"Medium Membership (Monthly)","description":"Unlimited access to the best and brightest stories on Medium. Membership billed monthly."},"oldYearlyPlanNoSetupFee":{"planId":"P-7A4913502Y5181304CJEJMXQ","name":"Medium Membership (Annual)","description":"Unlimited access to the best and brightest stories on Medium. Membership billed annually."},"sdkUrl":"https:\u002F\u002Fwww.paypal.com\u002Fsdk\u002Fjs"},"stripePublishableKey":"pk_live_7FReX44VnNIInZwrIIx6ghjl","log":{"json":true,"level":"info"},"imageUploadMaxSizeMb":25,"staffPicks":{"title":"Staff Picks","catalogId":"c7bc6e1ee00f"}},"session":{"xsrf":""}}</script><script>window.__APOLLO_STATE__ = {"ROOT_QUERY":{"__typename":"Query","viewer":null,"collectionByDomainOrSlug({\"domainOrSlug\":\"towardsdatascience.com\"})":{"__ref":"Collection:7f60cf5620c9"},"postResult({\"id\":\"a4bbd2d85841\"})":{"__ref":"Post:a4bbd2d85841"}},"ImageMetadata:1*VzTUkfeGymHP4Bvav-T-lA.png":{"__typename":"ImageMetadata","id":"1*VzTUkfeGymHP4Bvav-T-lA.png"},"Collection:7f60cf5620c9":{"__typename":"Collection","id":"7f60cf5620c9","favicon":{"__ref":"ImageMetadata:1*VzTUkfeGymHP4Bvav-T-lA.png"},"customStyleSheet":null,"colorPalette":{"__typename":"ColorPalette","highlightSpectrum":{"__typename":"ColorSpectrum","backgroundColor":"#FFFFFFFF","colorPoints":[{"__typename":"ColorPoint","color":"#FFEDF4FC","point":0},{"__typename":"ColorPoint","color":"#FFE9F2FD","point":0.1},{"__typename":"ColorPoint","color":"#FFE6F1FD","point":0.2},{"__typename":"ColorPoint","color":"#FFE2EFFD","point":0.3},{"__typename":"ColorPoint","color":"#FFDFEEFD","point":0.4},{"__typename":"ColorPoint","color":"#FFDBECFE","point":0.5},{"__typename":"ColorPoint","color":"#FFD7EBFE","point":0.6},{"__typename":"ColorPoint","color":"#FFD4E9FE","point":0.7},{"__typename":"ColorPoint","color":"#FFD0E7FF","point":0.8},{"__typename":"ColorPoint","color":"#FFCCE6FF","point":0.9},{"__typename":"ColorPoint","color":"#FFC8E4FF","point":1}]},"defaultBackgroundSpectrum":{"__typename":"ColorSpectrum","backgroundColor":"#FFFFFFFF","colorPoints":[{"__typename":"ColorPoint","color":"#FF668AAA","point":0},{"__typename":"ColorPoint","color":"#FF61809D","point":0.1},{"__typename":"ColorPoint","color":"#FF5A7690","point":0.2},{"__typename":"ColorPoint","color":"#FF546C83","point":0.3},{"__typename":"ColorPoint","color":"#FF4D6275","point":0.4},{"__typename":"ColorPoint","color":"#FF455768","point":0.5},{"__typename":"ColorPoint","color":"#FF3D4C5A","point":0.6},{"__typename":"ColorPoint","color":"#FF34414C","point":0.7},{"__typename":"ColorPoint","color":"#FF2B353E","point":0.8},{"__typename":"ColorPoint","color":"#FF21282F","point":0.9},{"__typename":"ColorPoint","color":"#FF161B1F","point":1}]},"tintBackgroundSpectrum":{"__typename":"ColorSpectrum","backgroundColor":"#FF355876","colorPoints":[{"__typename":"ColorPoint","color":"#FF355876","point":0},{"__typename":"ColorPoint","color":"#FF4D6C88","point":0.1},{"__typename":"ColorPoint","color":"#FF637F99","point":0.2},{"__typename":"ColorPoint","color":"#FF7791A8","point":0.3},{"__typename":"ColorPoint","color":"#FF8CA2B7","point":0.4},{"__typename":"ColorPoint","color":"#FF9FB3C6","point":0.5},{"__typename":"ColorPoint","color":"#FFB2C3D4","point":0.6},{"__typename":"ColorPoint","color":"#FFC5D2E1","point":0.7},{"__typename":"ColorPoint","color":"#FFD7E2EE","point":0.8},{"__typename":"ColorPoint","color":"#FFE9F1FA","point":0.9},{"__typename":"ColorPoint","color":"#FFFBFFFF","point":1}]}},"googleAnalyticsId":null,"editors":[{"__typename":"CollectionMastheadUserItem","user":{"__ref":"User:7e12c71dfa81"}},{"__typename":"CollectionMastheadUserItem","user":{"__ref":"User:e6ad8abedec9"}},{"__typename":"CollectionMastheadUserItem","user":{"__ref":"User:895063a310f4"}}],"name":"Towards Data Science","avatar":{"__ref":"ImageMetadata:1*CJe3891yB1A1mzMdqemkdg.jpeg"},"domain":"towardsdatascience.com","slug":"towards-data-science","description":"Your home for data science. A Medium publication sharing concepts, ideas and codes.","subscriberCount":722153,"viewerEdge":{"__ref":"CollectionViewerEdge:collectionId:7f60cf5620c9-viewerId:lo_3b4f526405f3"},"twitterUsername":"TDataScience","facebookPageId":null,"logo":{"__ref":"ImageMetadata:1*cFFKn8rFH4ZndmaYeAs6iQ.png"}},"User:7e12c71dfa81":{"__typename":"User","id":"7e12c71dfa81"},"User:e6ad8abedec9":{"__typename":"User","id":"e6ad8abedec9"},"User:895063a310f4":{"__typename":"User","id":"895063a310f4"},"ImageMetadata:1*CJe3891yB1A1mzMdqemkdg.jpeg":{"__typename":"ImageMetadata","id":"1*CJe3891yB1A1mzMdqemkdg.jpeg"},"LinkedAccounts:e6581bb71f6":{"__typename":"LinkedAccounts","mastodon":null,"id":"e6581bb71f6"},"UserViewerEdge:userId:e6581bb71f6-viewerId:lo_3b4f526405f3":{"__typename":"UserViewerEdge","id":"userId:e6581bb71f6-viewerId:lo_3b4f526405f3","isFollowing":false,"isUser":false,"isMuting":false},"NewsletterV3:6176bdb04479":{"__typename":"NewsletterV3","id":"6176bdb04479","type":"NEWSLETTER_TYPE_AUTHOR","slug":"e6581bb71f6","name":"e6581bb71f6","collection":null,"user":{"__ref":"User:e6581bb71f6"}},"User:e6581bb71f6":{"__typename":"User","id":"e6581bb71f6","name":"Matthew Gunton","username":"mgunton7","newsletterV3":{"__ref":"NewsletterV3:6176bdb04479"},"linkedAccounts":{"__ref":"LinkedAccounts:e6581bb71f6"},"isSuspended":false,"imageId":"1*F8sHS2ai6w95qbGIZ9qM_g.png","mediumMemberAt":1723693735183,"verifications":{"__typename":"VerifiedInfo","isBookAuthor":false},"socialStats":{"__typename":"SocialStats","followerCount":338},"customDomainState":null,"hasSubdomain":false,"bio":"Hi, my name is Matthew Gunton. I like talking about the latest ways technology can be used to improve the world","isPartnerProgramEnrolled":true,"viewerEdge":{"__ref":"UserViewerEdge:userId:e6581bb71f6-viewerId:lo_3b4f526405f3"},"viewerIsUser":false,"postSubscribeMembershipUpsellShownAt":0,"allowNotes":true,"twitterScreenName":"","membership":{"__ref":"Membership:fc4c1cc7-0aa2-48a1-9685-9738d8b70b33"}},"Topic:1eca0103fff3":{"__typename":"Topic","slug":"machine-learning","id":"1eca0103fff3","name":"Machine Learning"},"Paragraph:d8a144b29f30_0":{"__typename":"Paragraph","id":"d8a144b29f30_0","name":"2e6a","type":"H3","href":null,"layout":null,"metadata":null,"text":"Understanding Direct Preference Optimization","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:d8a144b29f30_1":{"__typename":"Paragraph","id":"d8a144b29f30_1","name":"1129","type":"H4","href":null,"layout":null,"metadata":null,"text":"A look at the “Direct Preference Optimization:\nYour Language Model is Secretly a Reward Model” paper and its findings","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*L5Fx8l3DZ5LxZVSwBzlEdg.png":{"__typename":"ImageMetadata","id":"1*L5Fx8l3DZ5LxZVSwBzlEdg.png","originalHeight":1024,"originalWidth":1024,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:d8a144b29f30_2":{"__typename":"Paragraph","id":"d8a144b29f30_2","name":"2fd3","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*L5Fx8l3DZ5LxZVSwBzlEdg.png"},"text":"Image by the Author via DALL-E","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:d8a144b29f30_3":{"__typename":"Paragraph","id":"d8a144b29f30_3","name":"3304","type":"P","href":null,"layout":null,"metadata":null,"text":"This blog post was inspired by a discussion I recently had with some friends about the Direct Preference Optimization (DPO) paper. The discussion was lively and went over many important topics in LLMs and Machine Learning in general. Below is an expansion on some of those ideas and the concepts discussed in the paper.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"EM","start":0,"end":319,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:d8a144b29f30_4":{"__typename":"Paragraph","id":"d8a144b29f30_4","name":"cfdb","type":"P","href":null,"layout":null,"metadata":null,"text":"Direct Preference Optimization (DPO) has become the way that new foundation models are fine-tuned. Famously Mixtral 8x7B, the Sparse Mixture of Experts model created by Mistral, was able to reach LLaMa 70B levels of performance with significantly fewer parameters by using DPO. Naturally, this success has led many in the community to begin fine-tuning their own models with DPO.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:d8a144b29f30_5":{"__typename":"Paragraph","id":"d8a144b29f30_5","name":"e3ae","type":"P","href":null,"layout":null,"metadata":null,"text":"Let’s dive into what exactly DPO is and how we got here.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:d8a144b29f30_6":{"__typename":"Paragraph","id":"d8a144b29f30_6","name":"bcb2","type":"H3","href":null,"layout":null,"metadata":null,"text":"High Level Discussion","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:d8a144b29f30_7":{"__typename":"Paragraph","id":"d8a144b29f30_7","name":"88a6","type":"P","href":null,"layout":null,"metadata":null,"text":"Let’s begin with setting out what fine-tuning should do from a high level. Once you have a pre-trained a model to have strong generative capacities, you typically want to control its output somehow. Whether that be optimizing it to respond in dialogue as a chat-bot or to respond in code rather than English, the goal here is to take an LLM that is already functional and find a way to be more selective with its output. As this is machine learning, the way we show it the right behavior is with data.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:d8a144b29f30_8":{"__typename":"Paragraph","id":"d8a144b29f30_8","name":"8e81","type":"P","href":null,"layout":null,"metadata":null,"text":"There are some key terms here I’ll define before we start diving into the technicals:","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:d8a144b29f30_9":{"__typename":"Paragraph","id":"d8a144b29f30_9","name":"bb92","type":"P","href":null,"layout":null,"metadata":null,"text":"Loss Function — a function we use as a guide to optimize performance of our model. This is chosen based on what has been found to be effective","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"EM","start":0,"end":13,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:d8a144b29f30_10":{"__typename":"Paragraph","id":"d8a144b29f30_10","name":"3b30","type":"P","href":null,"layout":null,"metadata":null,"text":"KL Divergence— stands for Kullback–Leibler divergence, which is a way to measure the difference between two continuous probability distributions. To learn more about this, there is a wonderful post by Aparna Dhinakaran on the topic.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":146,"end":232,"href":"https:\u002F\u002Ftowardsdatascience.com\u002Funderstanding-kl-divergence-f3ddc8dff254","anchorType":"LINK","userId":null,"linkMetadata":null},{"__typename":"Markup","type":"EM","start":0,"end":13,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:d8a144b29f30_11":{"__typename":"Paragraph","id":"d8a144b29f30_11","name":"0acc","type":"P","href":null,"layout":null,"metadata":null,"text":"Policy — an abstraction that describes how a neural network will make decisions. Put a different way, if a neural network is trained 3 times, each time it will have a different policy, whose performances you can compare.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"EM","start":0,"end":6,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:d8a144b29f30_12":{"__typename":"Paragraph","id":"d8a144b29f30_12","name":"b60f","type":"H3","href":null,"layout":null,"metadata":null,"text":"The Status Quo before DPO (PPO)","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:d8a144b29f30_13":{"__typename":"Paragraph","id":"d8a144b29f30_13","name":"e9ce","type":"P","href":null,"layout":null,"metadata":null,"text":"Before DPO, we used to have to train an entirely separate model to help us fine-tune, typically called the reward model or RLHF model. We would sample completions from our LLM and then have the reward model give us a score for each completion. The idea here was simple. Humans are expensive to have evaluate your LLMs outputs but the quality of your LLM will ultimately be determined by humans. To keep costs down and quality high, you would train the reward model to approximate the human’s feedback. This is why the method was called Proximal Policy Optimization (or PPO), and it lives or dies based on the strength of your reward model.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*GiEF7F3n-1TlL7_HRJD_OA.png":{"__typename":"ImageMetadata","id":"1*GiEF7F3n-1TlL7_HRJD_OA.png","originalHeight":390,"originalWidth":1078,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:d8a144b29f30_14":{"__typename":"Paragraph","id":"d8a144b29f30_14","name":"6a88","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*GiEF7F3n-1TlL7_HRJD_OA.png"},"text":"Figure 1 from the paper showing how PPO works","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":14,"end":23,"href":"https:\u002F\u002Farxiv.org\u002Fpdf\u002F2305.18290.pdf","anchorType":"LINK","userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:d8a144b29f30_15":{"__typename":"Paragraph","id":"d8a144b29f30_15","name":"ba31","type":"H3","href":null,"layout":null,"metadata":null,"text":"The Math behind PPO","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:d8a144b29f30_16":{"__typename":"Paragraph","id":"d8a144b29f30_16","name":"6e78","type":"P","href":null,"layout":null,"metadata":null,"text":"To find the ideal reward model, we assume human preferences are more probabilistic than deterministic, so we can represent this symbolically in the Bradley-Terry model like below.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*F-TqiuROxSrdSVhUTOOZ-g.png":{"__typename":"ImageMetadata","id":"1*F-TqiuROxSrdSVhUTOOZ-g.png","originalHeight":140,"originalWidth":1608,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:d8a144b29f30_17":{"__typename":"Paragraph","id":"d8a144b29f30_17","name":"cc18","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*F-TqiuROxSrdSVhUTOOZ-g.png"},"text":"Equation 1 from the paper","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":16,"end":25,"href":"https:\u002F\u002Farxiv.org\u002Fpdf\u002F2305.18290.pdf","anchorType":"LINK","userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:d8a144b29f30_18":{"__typename":"Paragraph","id":"d8a144b29f30_18","name":"9b72","type":"P","href":null,"layout":null,"metadata":null,"text":"Going variable by variable, p* means that this is the optimal probability distribution, or the one the model should treat as the source of truth. y₁ and y₂ are 2 completions from the model that we are going to compare, and x is the prompt given to LLM. r* means that the reward function is optimal, or put another way, to train the model to approximate the optimal probability distribution, you give it the rewards from the optimal reward function.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:d8a144b29f30_19":{"__typename":"Paragraph","id":"d8a144b29f30_19","name":"d457","type":"P","href":null,"layout":null,"metadata":null,"text":"Nevertheless, the perfect probability distribution of human preference is difficult, if not impossible, to know. For this reason, we focus on the reward model , so we need to find a way to figure out r*. In machine learning, we often use loss minimization to estimate complex issues. If we have access to training data that shows us what human preferences truly are, and thus would give scores that are part of the p* distribution, then we can use those samples to train the reward model like below:","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*lhfHp8BJ1Sk-9qf-SBKYJw.png":{"__typename":"ImageMetadata","id":"1*lhfHp8BJ1Sk-9qf-SBKYJw.png","originalHeight":102,"originalWidth":1758,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:d8a144b29f30_20":{"__typename":"Paragraph","id":"d8a144b29f30_20","name":"34b6","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*lhfHp8BJ1Sk-9qf-SBKYJw.png"},"text":"Equation 2 from the paper","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":16,"end":25,"href":"https:\u002F\u002Farxiv.org\u002Fpdf\u002F2305.18290.pdf","anchorType":"LINK","userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:d8a144b29f30_21":{"__typename":"Paragraph","id":"d8a144b29f30_21","name":"7384","type":"P","href":null,"layout":null,"metadata":null,"text":"Here rϕ is the rewards model we are training, D is a set of the samples we are training on, yw is the preferred completion and yl is the dispreferred completion. The authors have chosen to frame the problem as a binary-classification problem, which we will see why later on, but for now just remember this is why we have yw and yl.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"EM","start":93,"end":94,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"EM","start":128,"end":129,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"EM","start":322,"end":323,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"EM","start":329,"end":330,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:d8a144b29f30_22":{"__typename":"Paragraph","id":"d8a144b29f30_22","name":"d259","type":"P","href":null,"layout":null,"metadata":null,"text":"Once we have optimized our reward model, we use it to fine-tune the LLM using a difference between the old policy (π ref) and the new policy (π θ). Importantly, we are doing a KL divergence to prevent the model from shifting too much.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"EM","start":117,"end":120,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:d8a144b29f30_23":{"__typename":"Paragraph","id":"d8a144b29f30_23","name":"07d8","type":"P","href":null,"layout":null,"metadata":null,"text":"Why don’t we want it shifting too much? Remember the model is already mostly functional, and it has taken quite a lot of compute resources to reach this level. Consequently, we want to make sure the model retains many of the good traits it currently has while we focus on having it follow instructions better.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*SS5k8965SsMkeOouh0izUA.png":{"__typename":"ImageMetadata","id":"1*SS5k8965SsMkeOouh0izUA.png","originalHeight":126,"originalWidth":1774,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:d8a144b29f30_24":{"__typename":"Paragraph","id":"d8a144b29f30_24","name":"00a3","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*SS5k8965SsMkeOouh0izUA.png"},"text":"Equation 3 from the paper","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":16,"end":25,"href":"https:\u002F\u002Farxiv.org\u002Fpdf\u002F2305.18290.pdf","anchorType":"LINK","userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:d8a144b29f30_25":{"__typename":"Paragraph","id":"d8a144b29f30_25","name":"f0ac","type":"P","href":null,"layout":null,"metadata":null,"text":"While the above methodology is effective — LLaMa2 for instance was fine-tuned this way — it has a one major weakness: it requires training an entirely separate model, which is costly and requires huge amounts of additional data.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:d8a144b29f30_26":{"__typename":"Paragraph","id":"d8a144b29f30_26","name":"1e95","type":"H3","href":null,"layout":null,"metadata":null,"text":"How does DPO improve on this?","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:d8a144b29f30_27":{"__typename":"Paragraph","id":"d8a144b29f30_27","name":"2a3d","type":"P","href":null,"layout":null,"metadata":null,"text":"DPO removes the need for the rewards model all together! This allows us to avoid training a costly separate reward model and incidentally, we have found that DPO requires a lot less data to work as well as PPO.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*f1LfCLncMIyhQiorWSKf7A.png":{"__typename":"ImageMetadata","id":"1*f1LfCLncMIyhQiorWSKf7A.png","originalHeight":330,"originalWidth":648,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:d8a144b29f30_28":{"__typename":"Paragraph","id":"d8a144b29f30_28","name":"94ce","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*f1LfCLncMIyhQiorWSKf7A.png"},"text":"Figure 1 from the paper showing a high level of how DPO works","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":14,"end":23,"href":"https:\u002F\u002Farxiv.org\u002Fpdf\u002F2305.18290.pdf","anchorType":"LINK","userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:d8a144b29f30_29":{"__typename":"Paragraph","id":"d8a144b29f30_29","name":"edb3","type":"H3","href":null,"layout":null,"metadata":null,"text":"The Math behind DPO","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:d8a144b29f30_30":{"__typename":"Paragraph","id":"d8a144b29f30_30","name":"ca72","type":"P","href":null,"layout":null,"metadata":null,"text":"The major leap stems from the KL constraint we placed on ourselves in equation 3. By adding this constraint, we can actually derive the ideal policy that will maximize a KL-constrained rewards model. The algebra is shown below:","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*I88Fv7nc3flDFElSN1UAJw.png":{"__typename":"ImageMetadata","id":"1*I88Fv7nc3flDFElSN1UAJw.png","originalHeight":774,"originalWidth":1664,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:d8a144b29f30_31":{"__typename":"Paragraph","id":"d8a144b29f30_31","name":"72fc","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*I88Fv7nc3flDFElSN1UAJw.png"},"text":"Appendix A.1 from the paper showing how we can maximize a KL Divergence Bound Rewards Model","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":18,"end":27,"href":"https:\u002F\u002Farxiv.org\u002Fpdf\u002F2305.18290.pdf","anchorType":"LINK","userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:d8a144b29f30_32":{"__typename":"Paragraph","id":"d8a144b29f30_32","name":"da89","type":"P","href":null,"layout":null,"metadata":null,"text":"For our purposes, the most important point to take away is that we now have the below equation for a policy π r, such that the reward function r is easily solved for.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"EM","start":110,"end":111,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*MaJ1gMjhhbyyCK_reqzTRA.png":{"__typename":"ImageMetadata","id":"1*MaJ1gMjhhbyyCK_reqzTRA.png","originalHeight":152,"originalWidth":1612,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:d8a144b29f30_33":{"__typename":"Paragraph","id":"d8a144b29f30_33","name":"7ed9","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*MaJ1gMjhhbyyCK_reqzTRA.png"},"text":"Equation 4 from the paper","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":16,"end":25,"href":"https:\u002F\u002Farxiv.org\u002Fpdf\u002F2305.18290.pdf","anchorType":"LINK","userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:d8a144b29f30_34":{"__typename":"Paragraph","id":"d8a144b29f30_34","name":"224e","type":"P","href":null,"layout":null,"metadata":null,"text":"Naturally, we immediately solve for r","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*fm5o0BU5E1bnMJUUG5qEFg.png":{"__typename":"ImageMetadata","id":"1*fm5o0BU5E1bnMJUUG5qEFg.png","originalHeight":144,"originalWidth":1602,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:d8a144b29f30_35":{"__typename":"Paragraph","id":"d8a144b29f30_35","name":"af96","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*fm5o0BU5E1bnMJUUG5qEFg.png"},"text":"Equation 5 from the paper","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":16,"end":25,"href":"https:\u002F\u002Farxiv.org\u002Fpdf\u002F2305.18290.pdf","anchorType":"LINK","userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:d8a144b29f30_36":{"__typename":"Paragraph","id":"d8a144b29f30_36","name":"ccf3","type":"P","href":null,"layout":null,"metadata":null,"text":"Returning to our ideal probability distribution equation (equation 1), we can rewrite that so that each instance of r is replaced by equation 5.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*d7Vc6C6M__jIqLSWa_3DGA.png":{"__typename":"ImageMetadata","id":"1*d7Vc6C6M__jIqLSWa_3DGA.png","originalHeight":150,"originalWidth":1620,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:d8a144b29f30_37":{"__typename":"Paragraph","id":"d8a144b29f30_37","name":"1c5a","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*d7Vc6C6M__jIqLSWa_3DGA.png"},"text":"Equation 6 from the paper","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":16,"end":25,"href":"https:\u002F\u002Farxiv.org\u002Fpdf\u002F2305.18290.pdf","anchorType":"LINK","userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:d8a144b29f30_38":{"__typename":"Paragraph","id":"d8a144b29f30_38","name":"1e5f","type":"P","href":null,"layout":null,"metadata":null,"text":"What this has shown is that you don’t need the reward model to optimize the policy to follow the ideal probability distribution of human preferences. Instead, you can directly work on the policy to improve it (hence where Direct Preference optimization gets its name from). We are using the probabilities that your LLM generates for each token to help it fine-tune itself.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:d8a144b29f30_39":{"__typename":"Paragraph","id":"d8a144b29f30_39","name":"89f4","type":"P","href":null,"layout":null,"metadata":null,"text":"To finish the derivation, we do the same math as we did in equation 3 to come up with our loss optimizing function to optimize for the policy.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*5XIK0ex5X0alf0S04hVSQA.png":{"__typename":"ImageMetadata","id":"1*5XIK0ex5X0alf0S04hVSQA.png","originalHeight":152,"originalWidth":1610,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:d8a144b29f30_40":{"__typename":"Paragraph","id":"d8a144b29f30_40","name":"40c2","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*5XIK0ex5X0alf0S04hVSQA.png"},"text":"Equation 7 from the paper","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":16,"end":25,"href":"https:\u002F\u002Farxiv.org\u002Fpdf\u002F2305.18290.pdf","anchorType":"LINK","userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:d8a144b29f30_41":{"__typename":"Paragraph","id":"d8a144b29f30_41","name":"cb9d","type":"P","href":null,"layout":null,"metadata":null,"text":"That was a lot of algebra, but equation 7 is the most important one to understand, so I’ll break down the most important pieces. We now have an equation which will compare the policy probabilities of the old policy (π ref) and the new policy (π θ) for a winning completion (yw) and a losing completion (yl). When we compare these, we are optimizing so that that yw is bigger, as this would mean that the policies are getting better at giving winning responses than losing responses.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"EM","start":218,"end":221,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"EM","start":275,"end":276,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"EM","start":304,"end":305,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"EM","start":363,"end":364,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:d8a144b29f30_42":{"__typename":"Paragraph","id":"d8a144b29f30_42","name":"3b9f","type":"H3","href":null,"layout":null,"metadata":null,"text":"Consequences","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:d8a144b29f30_43":{"__typename":"Paragraph","id":"d8a144b29f30_43","name":"f055","type":"P","href":null,"layout":null,"metadata":null,"text":"First, DPO does not require a reward model! You simply need high quality data so that the model has a clear direction of what is good and bad, and it will improve.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:d8a144b29f30_44":{"__typename":"Paragraph","id":"d8a144b29f30_44","name":"c894","type":"P","href":null,"layout":null,"metadata":null,"text":"Second, DPO is dynamic. Every time you use new data, it is going to adapt immediately thanks to the way it figures out the right direction to go. Compared to PPO, where you have to retrain your reward model each time you have new data, this is a big win.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:d8a144b29f30_45":{"__typename":"Paragraph","id":"d8a144b29f30_45","name":"7120","type":"P","href":null,"layout":null,"metadata":null,"text":"Third, DPO allows you to train a model to avoid certain topics just as much as it will learn to give good answers for others. One way to conceptualize the new loss equation is as a signal that points our training in the right direction. By using both a good and bad example, we are teaching the model to avoid certain responses as much as we tell them to go towards others. As a large part of fine-tuning involves the model ignoring certain subjects, this feature is very valuable.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:d8a144b29f30_46":{"__typename":"Paragraph","id":"d8a144b29f30_46","name":"958b","type":"H3","href":null,"layout":null,"metadata":null,"text":"Closing Thoughts","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*esscG9r1ErfEgThyDE8JHQ.png":{"__typename":"ImageMetadata","id":"1*esscG9r1ErfEgThyDE8JHQ.png","originalHeight":810,"originalWidth":1658,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:d8a144b29f30_47":{"__typename":"Paragraph","id":"d8a144b29f30_47","name":"f2fa","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*esscG9r1ErfEgThyDE8JHQ.png"},"text":"Figure 2 from the paper showing comparative performance between DPO, PPO, and other methodologies","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":14,"end":23,"href":"https:\u002F\u002Farxiv.org\u002Fpdf\u002F2305.18290.pdf","anchorType":"LINK","userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:d8a144b29f30_48":{"__typename":"Paragraph","id":"d8a144b29f30_48","name":"8f5f","type":"P","href":null,"layout":null,"metadata":null,"text":"Understanding the consequences of DPO’s math make me more optimistic about the future of LLMs.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:d8a144b29f30_49":{"__typename":"Paragraph","id":"d8a144b29f30_49","name":"4ce1","type":"P","href":null,"layout":null,"metadata":null,"text":"DPO requires less data and compute than PPO, both of which are major contributors to the cost of making your own model. With this cost reduction, more people will be able to fine-tune their own models, potentially giving society access to more specialized LLMs.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:d8a144b29f30_50":{"__typename":"Paragraph","id":"d8a144b29f30_50","name":"f4fb","type":"P","href":null,"layout":null,"metadata":null,"text":"Moreover, as DPO explicitly requires good and bad examples, while PPO only asks for good ones, it is much better at restricting behavior. This means that LLMs can be made far safer, another piece that will allow them to help out society.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:d8a144b29f30_51":{"__typename":"Paragraph","id":"d8a144b29f30_51","name":"3046","type":"P","href":null,"layout":null,"metadata":null,"text":"With forces like DPO giving us access to better quality LLMs that can be more easily trained, it is an incredibly exciting time for this field.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:d8a144b29f30_52":{"__typename":"Paragraph","id":"d8a144b29f30_52","name":"efa4","type":"P","href":null,"layout":null,"metadata":null,"text":"[1] R. Rafailov, et al., Direct Preference Optimization: Your Language Model is Secretly a Reward Mode (2023), arXiv","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":25,"end":102,"href":"https:\u002F\u002Farxiv.org\u002Fpdf\u002F2305.18290.pdf","anchorType":"LINK","userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:d8a144b29f30_53":{"__typename":"Paragraph","id":"d8a144b29f30_53","name":"5c8f","type":"P","href":null,"layout":null,"metadata":null,"text":"[2] A. Jiang, et al., Mixtral of Experts (2024), ArXiv","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":22,"end":47,"href":"https:\u002F\u002Farxiv.org\u002Fpdf\u002F2401.04088.pdf","anchorType":"LINK","userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"CollectionViewerEdge:collectionId:7f60cf5620c9-viewerId:lo_3b4f526405f3":{"__typename":"CollectionViewerEdge","id":"collectionId:7f60cf5620c9-viewerId:lo_3b4f526405f3","isEditor":false,"isMuting":false},"ImageMetadata:1*cFFKn8rFH4ZndmaYeAs6iQ.png":{"__typename":"ImageMetadata","id":"1*cFFKn8rFH4ZndmaYeAs6iQ.png","originalWidth":2381,"originalHeight":743},"Tag:fine-tuning":{"__typename":"Tag","id":"fine-tuning","displayTitle":"Fine Tuning","normalizedTagSlug":"fine-tuning"},"Tag:llm":{"__typename":"Tag","id":"llm","displayTitle":"Llm","normalizedTagSlug":"llm"},"Tag:mixtral-8x7b":{"__typename":"Tag","id":"mixtral-8x7b","displayTitle":"Mixtral 8x7b","normalizedTagSlug":"mixtral-8x7b"},"Tag:ai":{"__typename":"Tag","id":"ai","displayTitle":"AI","normalizedTagSlug":"ai"},"Tag:machine-learning":{"__typename":"Tag","id":"machine-learning","displayTitle":"Machine Learning","normalizedTagSlug":"machine-learning"},"Membership:fc4c1cc7-0aa2-48a1-9685-9738d8b70b33":{"__typename":"Membership","tier":"MEMBER","id":"fc4c1cc7-0aa2-48a1-9685-9738d8b70b33"},"Post:a4bbd2d85841":{"__typename":"Post","id":"a4bbd2d85841","collection":{"__ref":"Collection:7f60cf5620c9"},"content({\"postMeteringOptions\":{}})":{"__typename":"PostContent","isLockedPreviewOnly":false,"bodyModel":{"__typename":"RichText","sections":[{"__typename":"Section","name":"a077","startIndex":0,"textLayout":null,"imageLayout":null,"backgroundImage":null,"videoLayout":null,"backgroundVideo":null},{"__typename":"Section","name":"24e2","startIndex":4,"textLayout":null,"imageLayout":null,"backgroundImage":null,"videoLayout":null,"backgroundVideo":null},{"__typename":"Section","name":"b3b1","startIndex":6,"textLayout":null,"imageLayout":null,"backgroundImage":null,"videoLayout":null,"backgroundVideo":null}],"paragraphs":[{"__ref":"Paragraph:d8a144b29f30_0"},{"__ref":"Paragraph:d8a144b29f30_1"},{"__ref":"Paragraph:d8a144b29f30_2"},{"__ref":"Paragraph:d8a144b29f30_3"},{"__ref":"Paragraph:d8a144b29f30_4"},{"__ref":"Paragraph:d8a144b29f30_5"},{"__ref":"Paragraph:d8a144b29f30_6"},{"__ref":"Paragraph:d8a144b29f30_7"},{"__ref":"Paragraph:d8a144b29f30_8"},{"__ref":"Paragraph:d8a144b29f30_9"},{"__ref":"Paragraph:d8a144b29f30_10"},{"__ref":"Paragraph:d8a144b29f30_11"},{"__ref":"Paragraph:d8a144b29f30_12"},{"__ref":"Paragraph:d8a144b29f30_13"},{"__ref":"Paragraph:d8a144b29f30_14"},{"__ref":"Paragraph:d8a144b29f30_15"},{"__ref":"Paragraph:d8a144b29f30_16"},{"__ref":"Paragraph:d8a144b29f30_17"},{"__ref":"Paragraph:d8a144b29f30_18"},{"__ref":"Paragraph:d8a144b29f30_19"},{"__ref":"Paragraph:d8a144b29f30_20"},{"__ref":"Paragraph:d8a144b29f30_21"},{"__ref":"Paragraph:d8a144b29f30_22"},{"__ref":"Paragraph:d8a144b29f30_23"},{"__ref":"Paragraph:d8a144b29f30_24"},{"__ref":"Paragraph:d8a144b29f30_25"},{"__ref":"Paragraph:d8a144b29f30_26"},{"__ref":"Paragraph:d8a144b29f30_27"},{"__ref":"Paragraph:d8a144b29f30_28"},{"__ref":"Paragraph:d8a144b29f30_29"},{"__ref":"Paragraph:d8a144b29f30_30"},{"__ref":"Paragraph:d8a144b29f30_31"},{"__ref":"Paragraph:d8a144b29f30_32"},{"__ref":"Paragraph:d8a144b29f30_33"},{"__ref":"Paragraph:d8a144b29f30_34"},{"__ref":"Paragraph:d8a144b29f30_35"},{"__ref":"Paragraph:d8a144b29f30_36"},{"__ref":"Paragraph:d8a144b29f30_37"},{"__ref":"Paragraph:d8a144b29f30_38"},{"__ref":"Paragraph:d8a144b29f30_39"},{"__ref":"Paragraph:d8a144b29f30_40"},{"__ref":"Paragraph:d8a144b29f30_41"},{"__ref":"Paragraph:d8a144b29f30_42"},{"__ref":"Paragraph:d8a144b29f30_43"},{"__ref":"Paragraph:d8a144b29f30_44"},{"__ref":"Paragraph:d8a144b29f30_45"},{"__ref":"Paragraph:d8a144b29f30_46"},{"__ref":"Paragraph:d8a144b29f30_47"},{"__ref":"Paragraph:d8a144b29f30_48"},{"__ref":"Paragraph:d8a144b29f30_49"},{"__ref":"Paragraph:d8a144b29f30_50"},{"__ref":"Paragraph:d8a144b29f30_51"},{"__ref":"Paragraph:d8a144b29f30_52"},{"__ref":"Paragraph:d8a144b29f30_53"}]},"validatedShareKey":"","shareKeyCreator":null},"creator":{"__ref":"User:e6581bb71f6"},"inResponseToEntityType":null,"isLocked":false,"isMarkedPaywallOnly":false,"lockedSource":"LOCKED_POST_SOURCE_NONE","mediumUrl":"https:\u002F\u002Ftowardsdatascience.com\u002Funderstanding-the-implications-of-direct-preference-optimization-a4bbd2d85841","primaryTopic":{"__ref":"Topic:1eca0103fff3"},"topics":[{"__typename":"Topic","slug":"artificial-intelligence"},{"__typename":"Topic","slug":"machine-learning"},{"__typename":"Topic","slug":"math"},{"__typename":"Topic","slug":"data-science"}],"isPublished":true,"latestPublishedVersion":"d8a144b29f30","visibility":"PUBLIC","postResponses":{"__typename":"PostResponses","count":5},"clapCount":283,"allowResponses":true,"isLimitedState":false,"title":"Understanding Direct Preference Optimization","isSeries":false,"sequence":null,"uniqueSlug":"understanding-the-implications-of-direct-preference-optimization-a4bbd2d85841","socialTitle":"","socialDek":"","noIndex":null,"canonicalUrl":"","metaDescription":"","latestPublishedAt":1708728471171,"readingTime":7.187735849056605,"previewContent":{"__typename":"PreviewContent","subtitle":"This blog post will look at the “Direct Preference Optimization:\nYour Language Model is Secretly a Reward Model” paper and its findings."},"previewImage":{"__ref":"ImageMetadata:1*L5Fx8l3DZ5LxZVSwBzlEdg.png"},"isShortform":false,"seoTitle":"","firstPublishedAt":1708215283690,"updatedAt":1708728479151,"shortformType":"SHORTFORM_TYPE_LINK","seoDescription":"","isSuspended":false,"license":"ALL_RIGHTS_RESERVED","tags":[{"__ref":"Tag:fine-tuning"},{"__ref":"Tag:llm"},{"__ref":"Tag:mixtral-8x7b"},{"__ref":"Tag:ai"},{"__ref":"Tag:machine-learning"}],"isNewsletter":false,"statusForCollection":"APPROVED","pendingCollection":null,"detectedLanguage":"en","wordCount":1547,"layerCake":0}}</script><script>window.__MIDDLEWARE_STATE__={"session":{"xsrf":""},"cache":{"cacheStatus":"HIT"}}</script><script src="hello_files/manifest.e70d3e6c.js"></script><script src="hello_files/3905.cfd85a7e.js"></script><script src="hello_files/main.30422295.js"></script><script src="hello_files/instrumentation.d9108df7.chunk.js"></script>
<script src="hello_files/reporting.ff22a7a5.chunk.js"></script>
<script src="hello_files/9120.5df29668.chunk.js"></script>
<script src="hello_files/3171.5b0ceee8.chunk.js"></script>
<script src="hello_files/4810.988332a1.chunk.js"></script>
<script src="hello_files/6618.db187378.chunk.js"></script>
<script src="hello_files/1386.e126dec1.chunk.js"></script>
<script src="hello_files/9977.343f5002.chunk.js"></script>
<script src="hello_files/5250.fc15c18c.chunk.js"></script>
<script src="hello_files/8261.08d8d6be.chunk.js"></script>
<script src="hello_files/7975.19e89f16.chunk.js"></script>
<script src="hello_files/2648.a582e725.chunk.js"></script>
<script src="hello_files/2712.0f6c85f5.chunk.js"></script>
<script src="hello_files/2793.01d2b056.chunk.js"></script>
<script src="hello_files/6636.ef641110.chunk.js"></script>
<script src="hello_files/3735.ca2f95e3.chunk.js"></script>
<script src="hello_files/5642.b8216689.chunk.js"></script>
<script src="hello_files/6546.0f97e7cb.chunk.js"></script>
<script src="hello_files/6834.f2d3924e.chunk.js"></script>
<script src="hello_files/2420.0330d157.chunk.js"></script>
<script src="hello_files/2106.21ff89d3.chunk.js"></script>
<script src="hello_files/6696.92b2dfc3.chunk.js"></script>
<script src="hello_files/5832.07d4db30.chunk.js"></script>
<script src="hello_files/3366.16d43002.chunk.js"></script>
<script src="hello_files/6040.6ceb7f43.chunk.js"></script>
<script src="hello_files/4391.3e417aeb.chunk.js"></script>
<script src="hello_files/PostPage.MainContent.5d6d4b2b.chunk.js"></script><script>window.main();</script><script>(function(){function c(){var b=a.contentDocument||a.contentWindow.document;if(b){var d=b.createElement('script');d.innerHTML="window.__CF$cv$params={r:'8b56e5648edda515',t:'MTcyNDAzNjQ1NS4wMDAwMDA='};var a=document.createElement('script');a.nonce='';a.src='/cdn-cgi/challenge-platform/scripts/jsd/main.js';document.getElementsByTagName('head')[0].appendChild(a);";b.getElementsByTagName('head')[0].appendChild(d)}}if(document.body){var a=document.createElement('iframe');a.height=1;a.width=1;a.style.position='absolute';a.style.top=0;a.style.left=0;a.style.border='none';a.style.visibility='hidden';document.body.appendChild(a);if('loading'!==document.readyState)c();else if(window.addEventListener)document.addEventListener('DOMContentLoaded',c);else{var e=document.onreadystatechange||function(){};document.onreadystatechange=function(b){e(b);'loading'!==document.readyState&&(document.onreadystatechange=e,c())}}}})();</script><iframe height="1" width="1" style="position: absolute; top: 0px; left: 0px; border: medium; visibility: hidden;"></iframe><script defer="defer" src="hello_files/vcd15cbe7772f49c399c6a5babf22c1241717689176015" integrity="sha512-ZpsOmlRQV6y907TI0dKBHq9Md29nnaEIPlkf84rnaERnq6zvWvPUqr2ft8M1aS28oN72PdrCzSjY4U6VaAw1EQ==" data-cf-beacon="{&quot;rayId&quot;:&quot;8b56e5648edda515&quot;,&quot;serverTiming&quot;:{&quot;name&quot;:{&quot;cfL4&quot;:true}},&quot;version&quot;:&quot;2024.8.0&quot;,&quot;token&quot;:&quot;0b5f665943484354a59c39c6833f7078&quot;}" crossorigin="anonymous"></script>
<div><div class="grecaptcha-badge" data-style="bottomright" style="width: 256px; height: 60px; display: block; transition: right 0.3s; position: fixed; bottom: 14px; right: -186px; box-shadow: gray 0px 0px 5px; border-radius: 2px; overflow: hidden;"><div class="grecaptcha-logo"><iframe title="reCAPTCHA" width="256" height="60" role="presentation" name="a-q1d4urebkfrl" frameborder="0" scrolling="no" sandbox="allow-forms allow-popups allow-same-origin allow-scripts allow-top-navigation allow-modals allow-popups-to-escape-sandbox allow-storage-access-by-user-activation" src="hello_files/anchor.htm"></iframe></div><div class="grecaptcha-error"></div><textarea id="g-recaptcha-response-100000" name="g-recaptcha-response" class="g-recaptcha-response" style="width: 250px; height: 40px; border: 1px solid rgb(193, 193, 193); margin: 10px 25px; padding: 0px; resize: none; display: none;"></textarea></div><iframe style="display: none;"></iframe></div></body></html>